{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.reset_option('display.max_rows')\n",
    "\n",
    "\n",
    "# Importing the dataset\n",
    "X_dataset = pd.read_csv('X_visit_and_deltas_fours.csv')\n",
    "Y_RNFL = pd.read_csv('Y_visit_fours_RNFL.csv')\n",
    "Y_GCA = pd.read_csv('Y_visit_fours_GCA.csv')\n",
    "Y_VFI = pd.read_csv('Y_visit_fours_VFI.csv')\n",
    "Y_MD = pd.read_csv('Y_visit_fours_MD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "#label encoding dx: 3 total\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X_dataset.iloc[:, 0] = labelencoder_X_1.fit_transform(X_dataset.iloc[:, 0])\n",
    "\n",
    "#label encoding gender: 2 total\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X_dataset.iloc[:, 1] = labelencoder_X_2.fit_transform(X_dataset.iloc[:, 1])\n",
    "\n",
    "#label encoding race: 3 total\n",
    "labelencoder_X_3 = LabelEncoder()\n",
    "X_dataset.iloc[:, 2] = labelencoder_X_3.fit_transform(X_dataset.iloc[:, 2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1765\n",
      "1     646\n",
      "2      10\n",
      "Name: primary_dx, dtype: int64\n",
      "0    1403\n",
      "1    1018\n",
      "Name: gender, dtype: int64\n",
      "white    1844\n",
      "black     456\n",
      "asian     121\n",
      "Name: race, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_dataset['primary_dx'].value_counts())\n",
    "print(X_dataset['gender'].value_counts())\n",
    "print(X_dataset['race'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = pd.get_dummies(X_dataset, columns=['primary_dx', 'race'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    gender\n",
       "1              avg_cd_ratio\n",
       "2               gca_average\n",
       "3               gca_tempsup\n",
       "4                   gca_sup\n",
       "5                gca_nassup\n",
       "6                gca_nasinf\n",
       "7                   gca_inf\n",
       "8               gca_tempinf\n",
       "9              rnfl_average\n",
       "10             rnfl_tempsup\n",
       "11                 rnfl_sup\n",
       "12              rnfl_nassup\n",
       "13              rnfl_nasinf\n",
       "14                 rnfl_inf\n",
       "15             rnfl_tempinf\n",
       "16                       md\n",
       "17                     p_md\n",
       "18                      psd\n",
       "19                    p_psd\n",
       "20                      vfi\n",
       "21                      age\n",
       "22        avg_cd_ratio_twos\n",
       "23         gca_average_twos\n",
       "24         gca_tempsup_twos\n",
       "25             gca_sup_twos\n",
       "26          gca_nassup_twos\n",
       "27          gca_nasinf_twos\n",
       "28             gca_inf_twos\n",
       "29         gca_tempinf_twos\n",
       "               ...         \n",
       "78     rnfl_tempinf_delta_1\n",
       "79               md_delta_1\n",
       "80             p_md_delta_1\n",
       "81              psd_delta_1\n",
       "82            p_psd_delta_1\n",
       "83              vfi_delta_1\n",
       "84     avg_cd_ratio_delta_2\n",
       "85      gca_average_delta_2\n",
       "86      gca_tempsup_delta_2\n",
       "87          gca_sup_delta_2\n",
       "88       gca_nassup_delta_2\n",
       "89       gca_nasinf_delta_2\n",
       "90          gca_inf_delta_2\n",
       "91      gca_tempinf_delta_2\n",
       "92     rnfl_average_delta_2\n",
       "93     rnfl_tempsup_delta_2\n",
       "94         rnfl_sup_delta_2\n",
       "95      rnfl_nassup_delta_2\n",
       "96      rnfl_nasinf_delta_2\n",
       "97         rnfl_inf_delta_2\n",
       "98     rnfl_tempinf_delta_2\n",
       "99               md_delta_2\n",
       "100            p_md_delta_2\n",
       "101             psd_delta_2\n",
       "102           p_psd_delta_2\n",
       "103             vfi_delta_2\n",
       "104                      GS\n",
       "105                    OHTN\n",
       "106              race_black\n",
       "107              race_white\n",
       "Length: 108, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#primary_dx_1 = glaucoma suspect\n",
    "#primary_dx_2 = OHTN\n",
    "#race_1 = black\n",
    "#race_2 = white\n",
    "\n",
    "X_dataset.rename(columns={'race_1':'black', 'race_2':'white', 'primary_dx_1':'GS','primary_dx_2':'OHTN'}, inplace=True)\n",
    "X_dataset\n",
    "\n",
    "X_dataset = X_dataset.iloc[:, 1:]\n",
    "X_dataset\n",
    "Y_RNFL = Y_RNFL.iloc[:, 1:]\n",
    "Y_VFI = Y_VFI.iloc[:, 1:]\n",
    "Y_MD = Y_MD.iloc[:, 1:]\n",
    "Y_GCA = Y_GCA.iloc[:, 1:]\n",
    "\n",
    "listing = pd.Series(X_dataset.columns.values)\n",
    "listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_model():\n",
    "    # Initialising the ANN\n",
    "    classifier = Sequential()\n",
    "    \n",
    "    #Batch normalization\n",
    "#     classifier.add(BatchNormalization(axis = 1))\n",
    "    \n",
    "    # Adding the input layer and the first hidden layer\n",
    "    classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'linear', input_dim = 108))\n",
    "    classifier.add(LeakyReLU(alpha = 0.001))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'linear'))\n",
    "    classifier.add(LeakyReLU(alpha = 0.001))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'linear'))\n",
    "    classifier.add(LeakyReLU(alpha = 0.001))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'linear'))\n",
    "    classifier.add(LeakyReLU(alpha = 0.001))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'linear'))\n",
    "    classifier.add(LeakyReLU(alpha = 0.001))\n",
    "    \n",
    "    #dropout layer\n",
    "    classifier.add(Dropout(0.2))\n",
    "\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'linear'))\n",
    "    classifier.add(LeakyReLU(alpha = 0.1))\n",
    "\n",
    "    # # Adding the input layer and the first hidden layer\n",
    "    # classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', input_dim = 46))\n",
    "\n",
    "    # # Adding the second hidden layer\n",
    "    # classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    # # Adding the third hidden layer\n",
    "    # classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    # # Adding the third hidden layer\n",
    "    # classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    # # # Adding the third hidden layer\n",
    "    # # classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    # # # Adding the third hidden layer\n",
    "    # # classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    # # # Adding the third hidden layer\n",
    "    # # classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    # # Adding the third hidden layer\n",
    "    # classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    # # Adding the output layer\n",
    "    # classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    # Compiling the ANN\n",
    "    classifier.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['MAE', 'accuracy'])\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train_RNFL, X_test_RNFL, y_train_RNFL, y_test_RNFL = train_test_split(X_dataset, Y_RNFL, test_size = 0.2, random_state = 200)\n",
    "# X_train_VFI, X_test_VFI, y_train_VFI, y_test_VFI = train_test_split(X_dataset, Y_VFI, test_size = 0.2, random_state = 200)\n",
    "# X_train_MD, X_test_MD, y_train_MD, y_test_MD = train_test_split(X_dataset, Y_MD, test_size = 0.2, random_state = 200)\n",
    "# X_train_GCA, X_test_GCA, y_train_GCA, y_test_GCA = train_test_split(X_dataset, Y_GCA, test_size = 0.2, random_state = 200)\n",
    "\n",
    "# # Feature Scaling\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc_RNFL = StandardScaler()\n",
    "# X_train_RNFL = sc_RNFL.fit_transform(X_train_RNFL)\n",
    "# X_test_RNFL = sc_RNFL.transform(X_test_RNFL)\n",
    "\n",
    "# sc_VFI = StandardScaler()\n",
    "# X_train_VFI = sc_VFI.fit_transform(X_train_VFI)\n",
    "# X_test_VFI = sc_VFI.transform(X_test_VFI)\n",
    "\n",
    "# sc_MD = StandardScaler()\n",
    "# X_train_MD = sc_MD.fit_transform(X_train_MD)\n",
    "# X_test_MD = sc_MD.transform(X_test_MD)\n",
    "\n",
    "# sc_GCA = StandardScaler()\n",
    "# X_train_GCA = sc_GCA.fit_transform(X_train_GCA)\n",
    "# X_test_GCA = sc_GCA.transform(X_test_GCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "def ANN_baseline(X, y, name):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 200)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 200)\n",
    "    y_train = y_train.ravel()\n",
    "    y_test = y_test.ravel()\n",
    "    y_val = y_val.ravel()\n",
    "    model = ann_model()\n",
    "\n",
    "\n",
    "    weight_path=\"ANN_Interval_best_{}.hdf5\".format(name)\n",
    "    checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "    callbacks_list = [checkpoint, early_stop]\n",
    "        \n",
    "    #fit the model\n",
    "    history = model.fit(X_train, y_train, epochs=500, validation_data=(X_val, y_val), shuffle=False, callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "    # plot train and validation loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model train vs validation loss for {}'.format(name))    \n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.savefig('loss_plot_{}.png'.format(name), dpi = 300)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    model.load_weights(weight_path)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_pred = y_pred.tolist()\n",
    "  \n",
    "    dictionary_DF = {'predicted':y_pred, 'actual':y_test}\n",
    "    data = pd.DataFrame(dictionary_DF)\n",
    "    data.to_csv('Predicted_vs_Actual_of_{}'.format(name))\n",
    "    \n",
    "    mean_absolute_error = abs(data['predicted']-data['actual'])\n",
    "    mean_absolute_error = mean_absolute_error.describe()\n",
    "    mean_absolute_error.to_csv('MAE_of_{}_Predicted_vs_Actual'.format(name))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2421, 108)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X_dataset)\n",
    "y_MD = np.array(Y_MD)\n",
    "y_GCA = np.array(Y_GCA)\n",
    "y_VFI = np.array(Y_VFI)\n",
    "y_RNFL = np.array(Y_RNFL)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1548 samples, validate on 388 samples\n",
      "Epoch 1/500\n",
      "1548/1548 [==============================] - 1s 600us/step - loss: 4227.6877 - mean_absolute_error: 60.1492 - acc: 0.0019 - val_loss: 152.3005 - val_mean_absolute_error: 10.6828 - val_acc: 0.0180\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 152.30054, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 2/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 119.9670 - mean_absolute_error: 8.6245 - acc: 0.0446 - val_loss: 56.1351 - val_mean_absolute_error: 5.7950 - val_acc: 0.0696\n",
      "\n",
      "Epoch 00002: val_loss improved from 152.30054 to 56.13507, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 3/500\n",
      "1548/1548 [==============================] - 0s 84us/step - loss: 63.3167 - mean_absolute_error: 6.2105 - acc: 0.0627 - val_loss: 54.4331 - val_mean_absolute_error: 5.6697 - val_acc: 0.0696\n",
      "\n",
      "Epoch 00003: val_loss improved from 56.13507 to 54.43314, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 4/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 61.3708 - mean_absolute_error: 6.1156 - acc: 0.0588 - val_loss: 53.4392 - val_mean_absolute_error: 5.6142 - val_acc: 0.0696\n",
      "\n",
      "Epoch 00004: val_loss improved from 54.43314 to 53.43922, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 5/500\n",
      "1548/1548 [==============================] - 0s 99us/step - loss: 60.6053 - mean_absolute_error: 6.0758 - acc: 0.0562 - val_loss: 52.3277 - val_mean_absolute_error: 5.5531 - val_acc: 0.0773\n",
      "\n",
      "Epoch 00005: val_loss improved from 53.43922 to 52.32771, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 6/500\n",
      "1548/1548 [==============================] - 0s 128us/step - loss: 59.6692 - mean_absolute_error: 6.0294 - acc: 0.0530 - val_loss: 50.8614 - val_mean_absolute_error: 5.4554 - val_acc: 0.0619\n",
      "\n",
      "Epoch 00006: val_loss improved from 52.32771 to 50.86136, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 7/500\n",
      "1548/1548 [==============================] - 0s 110us/step - loss: 58.3585 - mean_absolute_error: 5.9557 - acc: 0.0543 - val_loss: 49.3739 - val_mean_absolute_error: 5.3339 - val_acc: 0.0799\n",
      "\n",
      "Epoch 00007: val_loss improved from 50.86136 to 49.37394, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 8/500\n",
      "1548/1548 [==============================] - 0s 136us/step - loss: 56.5229 - mean_absolute_error: 5.8421 - acc: 0.0678 - val_loss: 48.7037 - val_mean_absolute_error: 5.2666 - val_acc: 0.0722\n",
      "\n",
      "Epoch 00008: val_loss improved from 49.37394 to 48.70370, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 9/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 54.3146 - mean_absolute_error: 5.7134 - acc: 0.0711 - val_loss: 48.5994 - val_mean_absolute_error: 5.2462 - val_acc: 0.0825\n",
      "\n",
      "Epoch 00009: val_loss improved from 48.70370 to 48.59943, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 10/500\n",
      "1548/1548 [==============================] - 0s 106us/step - loss: 52.0505 - mean_absolute_error: 5.5808 - acc: 0.0775 - val_loss: 48.1542 - val_mean_absolute_error: 5.2240 - val_acc: 0.0722\n",
      "\n",
      "Epoch 00010: val_loss improved from 48.59943 to 48.15418, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 11/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 49.9042 - mean_absolute_error: 5.4605 - acc: 0.0756 - val_loss: 47.1485 - val_mean_absolute_error: 5.1702 - val_acc: 0.0773\n",
      "\n",
      "Epoch 00011: val_loss improved from 48.15418 to 47.14846, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 12/500\n",
      "1548/1548 [==============================] - 0s 88us/step - loss: 47.8621 - mean_absolute_error: 5.3453 - acc: 0.0711 - val_loss: 45.7220 - val_mean_absolute_error: 5.0900 - val_acc: 0.0619\n",
      "\n",
      "Epoch 00012: val_loss improved from 47.14846 to 45.72204, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 13/500\n",
      "1548/1548 [==============================] - 0s 104us/step - loss: 45.8585 - mean_absolute_error: 5.2296 - acc: 0.0730 - val_loss: 43.9881 - val_mean_absolute_error: 4.9877 - val_acc: 0.0593\n",
      "\n",
      "Epoch 00013: val_loss improved from 45.72204 to 43.98811, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 14/500\n",
      "1548/1548 [==============================] - 0s 87us/step - loss: 43.8403 - mean_absolute_error: 5.1102 - acc: 0.0685 - val_loss: 41.9840 - val_mean_absolute_error: 4.8639 - val_acc: 0.0619\n",
      "\n",
      "Epoch 00014: val_loss improved from 43.98811 to 41.98405, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 15/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 41.7709 - mean_absolute_error: 4.9852 - acc: 0.0704 - val_loss: 39.7440 - val_mean_absolute_error: 4.7194 - val_acc: 0.0593\n",
      "\n",
      "Epoch 00015: val_loss improved from 41.98405 to 39.74399, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 16/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 39.6201 - mean_absolute_error: 4.8508 - acc: 0.0749 - val_loss: 37.3259 - val_mean_absolute_error: 4.5587 - val_acc: 0.0670\n",
      "\n",
      "Epoch 00016: val_loss improved from 39.74399 to 37.32595, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 17/500\n",
      "1548/1548 [==============================] - 0s 86us/step - loss: 37.3621 - mean_absolute_error: 4.7089 - acc: 0.0853 - val_loss: 34.8235 - val_mean_absolute_error: 4.3904 - val_acc: 0.0876\n",
      "\n",
      "Epoch 00017: val_loss improved from 37.32595 to 34.82350, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 18/500\n",
      "1548/1548 [==============================] - 0s 89us/step - loss: 34.9733 - mean_absolute_error: 4.5547 - acc: 0.0866 - val_loss: 32.3448 - val_mean_absolute_error: 4.2222 - val_acc: 0.0954\n",
      "\n",
      "Epoch 00018: val_loss improved from 34.82350 to 32.34476, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 19/500\n",
      "1548/1548 [==============================] - 0s 79us/step - loss: 32.4391 - mean_absolute_error: 4.3893 - acc: 0.0898 - val_loss: 29.9557 - val_mean_absolute_error: 4.0555 - val_acc: 0.0954\n",
      "\n",
      "Epoch 00019: val_loss improved from 32.34476 to 29.95572, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 20/500\n",
      "1548/1548 [==============================] - 0s 103us/step - loss: 29.7686 - mean_absolute_error: 4.2097 - acc: 0.0853 - val_loss: 27.6651 - val_mean_absolute_error: 3.8882 - val_acc: 0.0954\n",
      "\n",
      "Epoch 00020: val_loss improved from 29.95572 to 27.66508, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 21/500\n",
      "1548/1548 [==============================] - 0s 84us/step - loss: 27.0098 - mean_absolute_error: 4.0174 - acc: 0.0846 - val_loss: 25.4451 - val_mean_absolute_error: 3.7220 - val_acc: 0.0928\n",
      "\n",
      "Epoch 00021: val_loss improved from 27.66508 to 25.44505, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 22/500\n",
      "1548/1548 [==============================] - 0s 95us/step - loss: 24.2568 - mean_absolute_error: 3.8149 - acc: 0.0879 - val_loss: 23.2540 - val_mean_absolute_error: 3.5461 - val_acc: 0.1418\n",
      "\n",
      "Epoch 00022: val_loss improved from 25.44505 to 23.25404, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 23/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 21.6164 - mean_absolute_error: 3.6042 - acc: 0.1027 - val_loss: 18.5664 - val_mean_absolute_error: 3.1314 - val_acc: 0.1237\n",
      "\n",
      "Epoch 00023: val_loss improved from 23.25404 to 18.56635, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 24/500\n",
      "1548/1548 [==============================] - 0s 87us/step - loss: 15.8980 - mean_absolute_error: 3.0604 - acc: 0.1137 - val_loss: 13.8060 - val_mean_absolute_error: 2.6572 - val_acc: 0.1495\n",
      "\n",
      "Epoch 00024: val_loss improved from 18.56635 to 13.80597, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 25/500\n",
      "1548/1548 [==============================] - 0s 78us/step - loss: 13.3337 - mean_absolute_error: 2.7806 - acc: 0.1195 - val_loss: 12.4853 - val_mean_absolute_error: 2.4915 - val_acc: 0.1727\n",
      "\n",
      "Epoch 00025: val_loss improved from 13.80597 to 12.48532, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 26/500\n",
      "1548/1548 [==============================] - 0s 87us/step - loss: 12.1353 - mean_absolute_error: 2.6158 - acc: 0.1305 - val_loss: 11.7804 - val_mean_absolute_error: 2.4131 - val_acc: 0.1753\n",
      "\n",
      "Epoch 00026: val_loss improved from 12.48532 to 11.78044, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 27/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 11.5855 - mean_absolute_error: 2.5420 - acc: 0.1350 - val_loss: 11.3992 - val_mean_absolute_error: 2.3787 - val_acc: 0.1572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00027: val_loss improved from 11.78044 to 11.39917, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 28/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 11.2317 - mean_absolute_error: 2.4934 - acc: 0.1389 - val_loss: 11.1643 - val_mean_absolute_error: 2.3585 - val_acc: 0.1443\n",
      "\n",
      "Epoch 00028: val_loss improved from 11.39917 to 11.16429, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 29/500\n",
      "1548/1548 [==============================] - 0s 80us/step - loss: 10.9974 - mean_absolute_error: 2.4587 - acc: 0.1434 - val_loss: 11.0074 - val_mean_absolute_error: 2.3441 - val_acc: 0.1443\n",
      "\n",
      "Epoch 00029: val_loss improved from 11.16429 to 11.00741, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 30/500\n",
      "1548/1548 [==============================] - 0s 100us/step - loss: 10.8352 - mean_absolute_error: 2.4333 - acc: 0.1479 - val_loss: 10.8952 - val_mean_absolute_error: 2.3320 - val_acc: 0.1469\n",
      "\n",
      "Epoch 00030: val_loss improved from 11.00741 to 10.89518, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 31/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 10.7191 - mean_absolute_error: 2.4153 - acc: 0.1512 - val_loss: 10.8108 - val_mean_absolute_error: 2.3207 - val_acc: 0.1521\n",
      "\n",
      "Epoch 00031: val_loss improved from 10.89518 to 10.81078, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 32/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 10.6339 - mean_absolute_error: 2.4025 - acc: 0.1557 - val_loss: 10.7442 - val_mean_absolute_error: 2.3102 - val_acc: 0.1624\n",
      "\n",
      "Epoch 00032: val_loss improved from 10.81078 to 10.74420, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 33/500\n",
      "1548/1548 [==============================] - 0s 83us/step - loss: 10.5700 - mean_absolute_error: 2.3930 - acc: 0.1583 - val_loss: 10.6896 - val_mean_absolute_error: 2.3005 - val_acc: 0.1546\n",
      "\n",
      "Epoch 00033: val_loss improved from 10.74420 to 10.68964, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 34/500\n",
      "1548/1548 [==============================] - 0s 79us/step - loss: 10.5222 - mean_absolute_error: 2.3866 - acc: 0.1609 - val_loss: 10.6425 - val_mean_absolute_error: 2.2919 - val_acc: 0.1546\n",
      "\n",
      "Epoch 00034: val_loss improved from 10.68964 to 10.64250, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 35/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 10.4866 - mean_absolute_error: 2.3822 - acc: 0.1615 - val_loss: 10.6003 - val_mean_absolute_error: 2.2840 - val_acc: 0.1495\n",
      "\n",
      "Epoch 00035: val_loss improved from 10.64250 to 10.60033, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 36/500\n",
      "1548/1548 [==============================] - 0s 91us/step - loss: 10.4607 - mean_absolute_error: 2.3791 - acc: 0.1615 - val_loss: 10.5614 - val_mean_absolute_error: 2.2765 - val_acc: 0.1469\n",
      "\n",
      "Epoch 00036: val_loss improved from 10.60033 to 10.56138, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 37/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 10.4421 - mean_absolute_error: 2.3769 - acc: 0.1576 - val_loss: 10.5242 - val_mean_absolute_error: 2.2690 - val_acc: 0.1469\n",
      "\n",
      "Epoch 00037: val_loss improved from 10.56138 to 10.52420, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 38/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 10.4296 - mean_absolute_error: 2.3758 - acc: 0.1570 - val_loss: 10.4879 - val_mean_absolute_error: 2.2619 - val_acc: 0.1443\n",
      "\n",
      "Epoch 00038: val_loss improved from 10.52420 to 10.48792, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 39/500\n",
      "1548/1548 [==============================] - 0s 89us/step - loss: 10.4218 - mean_absolute_error: 2.3754 - acc: 0.1596 - val_loss: 10.4528 - val_mean_absolute_error: 2.2551 - val_acc: 0.1521\n",
      "\n",
      "Epoch 00039: val_loss improved from 10.48792 to 10.45276, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 40/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 10.4182 - mean_absolute_error: 2.3753 - acc: 0.1537 - val_loss: 10.4172 - val_mean_absolute_error: 2.2480 - val_acc: 0.1572\n",
      "\n",
      "Epoch 00040: val_loss improved from 10.45276 to 10.41722, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 41/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 10.4166 - mean_absolute_error: 2.3756 - acc: 0.1525 - val_loss: 10.3823 - val_mean_absolute_error: 2.2408 - val_acc: 0.1624\n",
      "\n",
      "Epoch 00041: val_loss improved from 10.41722 to 10.38234, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 42/500\n",
      "1548/1548 [==============================] - 0s 94us/step - loss: 10.4171 - mean_absolute_error: 2.3757 - acc: 0.1563 - val_loss: 10.3488 - val_mean_absolute_error: 2.2340 - val_acc: 0.1598\n",
      "\n",
      "Epoch 00042: val_loss improved from 10.38234 to 10.34880, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 43/500\n",
      "1548/1548 [==============================] - 0s 97us/step - loss: 10.4195 - mean_absolute_error: 2.3761 - acc: 0.1583 - val_loss: 10.3159 - val_mean_absolute_error: 2.2273 - val_acc: 0.1624\n",
      "\n",
      "Epoch 00043: val_loss improved from 10.34880 to 10.31585, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 44/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 10.4214 - mean_absolute_error: 2.3764 - acc: 0.1576 - val_loss: 10.2851 - val_mean_absolute_error: 2.2205 - val_acc: 0.1649\n",
      "\n",
      "Epoch 00044: val_loss improved from 10.31585 to 10.28510, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 45/500\n",
      "1548/1548 [==============================] - 0s 78us/step - loss: 10.4230 - mean_absolute_error: 2.3766 - acc: 0.1537 - val_loss: 10.2560 - val_mean_absolute_error: 2.2137 - val_acc: 0.1649\n",
      "\n",
      "Epoch 00045: val_loss improved from 10.28510 to 10.25602, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 46/500\n",
      "1548/1548 [==============================] - 0s 74us/step - loss: 10.4251 - mean_absolute_error: 2.3767 - acc: 0.1512 - val_loss: 10.2293 - val_mean_absolute_error: 2.2070 - val_acc: 0.1675\n",
      "\n",
      "Epoch 00046: val_loss improved from 10.25602 to 10.22934, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 47/500\n",
      "1548/1548 [==============================] - 0s 87us/step - loss: 10.4269 - mean_absolute_error: 2.3766 - acc: 0.1492 - val_loss: 10.2053 - val_mean_absolute_error: 2.2012 - val_acc: 0.1624\n",
      "\n",
      "Epoch 00047: val_loss improved from 10.22934 to 10.20529, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 48/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 10.4281 - mean_absolute_error: 2.3764 - acc: 0.1447 - val_loss: 10.1833 - val_mean_absolute_error: 2.1960 - val_acc: 0.1546\n",
      "\n",
      "Epoch 00048: val_loss improved from 10.20529 to 10.18327, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 49/500\n",
      "1548/1548 [==============================] - 0s 88us/step - loss: 10.4286 - mean_absolute_error: 2.3759 - acc: 0.1479 - val_loss: 10.1645 - val_mean_absolute_error: 2.1915 - val_acc: 0.1649\n",
      "\n",
      "Epoch 00049: val_loss improved from 10.18327 to 10.16447, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 50/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 10.4283 - mean_absolute_error: 2.3755 - acc: 0.1473 - val_loss: 10.1482 - val_mean_absolute_error: 2.1871 - val_acc: 0.1649\n",
      "\n",
      "Epoch 00050: val_loss improved from 10.16447 to 10.14816, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 51/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 10.4270 - mean_absolute_error: 2.3749 - acc: 0.1499 - val_loss: 10.1348 - val_mean_absolute_error: 2.1834 - val_acc: 0.1701\n",
      "\n",
      "Epoch 00051: val_loss improved from 10.14816 to 10.13485, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 52/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 10.4247 - mean_absolute_error: 2.3743 - acc: 0.1518 - val_loss: 10.1243 - val_mean_absolute_error: 2.1804 - val_acc: 0.1727\n",
      "\n",
      "Epoch 00052: val_loss improved from 10.13485 to 10.12433, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 53/500\n",
      "1548/1548 [==============================] - 0s 75us/step - loss: 10.4211 - mean_absolute_error: 2.3735 - acc: 0.1499 - val_loss: 10.1163 - val_mean_absolute_error: 2.1778 - val_acc: 0.1830\n",
      "\n",
      "Epoch 00053: val_loss improved from 10.12433 to 10.11631, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 54/500\n",
      "1548/1548 [==============================] - 0s 83us/step - loss: 10.4154 - mean_absolute_error: 2.3723 - acc: 0.1518 - val_loss: 10.1109 - val_mean_absolute_error: 2.1756 - val_acc: 0.1907\n",
      "\n",
      "Epoch 00054: val_loss improved from 10.11631 to 10.11085, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 55/500\n",
      "1548/1548 [==============================] - 0s 79us/step - loss: 10.4111 - mean_absolute_error: 2.3712 - acc: 0.1518 - val_loss: 10.1075 - val_mean_absolute_error: 2.1740 - val_acc: 0.1985\n",
      "\n",
      "Epoch 00055: val_loss improved from 10.11085 to 10.10745, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 56/500\n",
      "1548/1548 [==============================] - 0s 89us/step - loss: 10.4043 - mean_absolute_error: 2.3695 - acc: 0.1525 - val_loss: 10.1061 - val_mean_absolute_error: 2.1727 - val_acc: 0.1907\n",
      "\n",
      "Epoch 00056: val_loss improved from 10.10745 to 10.10606, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 57/500\n",
      "1548/1548 [==============================] - 0s 86us/step - loss: 10.3969 - mean_absolute_error: 2.3678 - acc: 0.1499 - val_loss: 10.1064 - val_mean_absolute_error: 2.1719 - val_acc: 0.1933\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 10.10606\n",
      "Epoch 58/500\n",
      "1548/1548 [==============================] - 0s 78us/step - loss: 10.3881 - mean_absolute_error: 2.3659 - acc: 0.1479 - val_loss: 10.1084 - val_mean_absolute_error: 2.1713 - val_acc: 0.1907\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 10.10606\n",
      "Epoch 59/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 10.3777 - mean_absolute_error: 2.3639 - acc: 0.1466 - val_loss: 10.1115 - val_mean_absolute_error: 2.1707 - val_acc: 0.1881\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 10.10606\n",
      "Epoch 60/500\n",
      "1548/1548 [==============================] - 0s 84us/step - loss: 10.3668 - mean_absolute_error: 2.3620 - acc: 0.1486 - val_loss: 10.1154 - val_mean_absolute_error: 2.1703 - val_acc: 0.1830\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 10.10606\n",
      "Epoch 61/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 10.3564 - mean_absolute_error: 2.3604 - acc: 0.1479 - val_loss: 10.1207 - val_mean_absolute_error: 2.1702 - val_acc: 0.1830\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 10.10606\n",
      "Epoch 62/500\n",
      "1548/1548 [==============================] - 0s 88us/step - loss: 10.3427 - mean_absolute_error: 2.3583 - acc: 0.1453 - val_loss: 10.1257 - val_mean_absolute_error: 2.1707 - val_acc: 0.1907\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 10.10606\n",
      "Epoch 63/500\n",
      "1548/1548 [==============================] - 0s 83us/step - loss: 10.3313 - mean_absolute_error: 2.3565 - acc: 0.1486 - val_loss: 10.1313 - val_mean_absolute_error: 2.1714 - val_acc: 0.1907\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 10.10606\n",
      "Epoch 64/500\n",
      "1548/1548 [==============================] - 0s 79us/step - loss: 10.3183 - mean_absolute_error: 2.3545 - acc: 0.1512 - val_loss: 10.1367 - val_mean_absolute_error: 2.1722 - val_acc: 0.1907\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 10.10606\n",
      "Epoch 65/500\n",
      "1548/1548 [==============================] - 0s 88us/step - loss: 10.3049 - mean_absolute_error: 2.3525 - acc: 0.1525 - val_loss: 10.1419 - val_mean_absolute_error: 2.1731 - val_acc: 0.1907\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 10.10606\n",
      "Epoch 66/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 10.2911 - mean_absolute_error: 2.3505 - acc: 0.1518 - val_loss: 10.1468 - val_mean_absolute_error: 2.1739 - val_acc: 0.1933\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 10.10606\n",
      "Epoch 67/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 10.2771 - mean_absolute_error: 2.3485 - acc: 0.1525 - val_loss: 10.1511 - val_mean_absolute_error: 2.1747 - val_acc: 0.1933\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 10.10606\n",
      "Epoch 68/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 10.2636 - mean_absolute_error: 2.3467 - acc: 0.1537 - val_loss: 10.1549 - val_mean_absolute_error: 2.1753 - val_acc: 0.1985\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 10.10606\n",
      "Epoch 69/500\n",
      "1548/1548 [==============================] - 0s 86us/step - loss: 10.2501 - mean_absolute_error: 2.3450 - acc: 0.1563 - val_loss: 10.1579 - val_mean_absolute_error: 2.1760 - val_acc: 0.1959\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 10.10606\n",
      "Epoch 70/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 10.2368 - mean_absolute_error: 2.3433 - acc: 0.1531 - val_loss: 10.1603 - val_mean_absolute_error: 2.1765 - val_acc: 0.1959\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 10.10606\n",
      "Epoch 71/500\n",
      "1548/1548 [==============================] - 0s 78us/step - loss: 10.2250 - mean_absolute_error: 2.3419 - acc: 0.1505 - val_loss: 10.1620 - val_mean_absolute_error: 2.1770 - val_acc: 0.1959\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 10.10606\n",
      "Epoch 72/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 10.2129 - mean_absolute_error: 2.3404 - acc: 0.1505 - val_loss: 10.1631 - val_mean_absolute_error: 2.1774 - val_acc: 0.1985\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 10.10606\n",
      "Epoch 73/500\n",
      "1548/1548 [==============================] - 0s 91us/step - loss: 10.2018 - mean_absolute_error: 2.3392 - acc: 0.1486 - val_loss: 10.1637 - val_mean_absolute_error: 2.1778 - val_acc: 0.1985\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 10.10606\n",
      "Epoch 74/500\n",
      "1548/1548 [==============================] - 0s 66us/step - loss: 10.1915 - mean_absolute_error: 2.3382 - acc: 0.1479 - val_loss: 10.1639 - val_mean_absolute_error: 2.1782 - val_acc: 0.1959\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 10.10606\n",
      "Epoch 75/500\n",
      "1548/1548 [==============================] - 0s 88us/step - loss: 10.1822 - mean_absolute_error: 2.3374 - acc: 0.1434 - val_loss: 10.1642 - val_mean_absolute_error: 2.1785 - val_acc: 0.1881\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 10.10606\n",
      "Epoch 76/500\n",
      "1548/1548 [==============================] - 0s 87us/step - loss: 10.1747 - mean_absolute_error: 2.3367 - acc: 0.1441 - val_loss: 10.1640 - val_mean_absolute_error: 2.1789 - val_acc: 0.1881\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 10.10606\n",
      "Epoch 77/500\n",
      "1548/1548 [==============================] - 0s 83us/step - loss: 10.1673 - mean_absolute_error: 2.3360 - acc: 0.1453 - val_loss: 10.1640 - val_mean_absolute_error: 2.1793 - val_acc: 0.1830\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 10.10606\n",
      "Epoch 78/500\n",
      "1548/1548 [==============================] - 0s 63us/step - loss: 10.1609 - mean_absolute_error: 2.3355 - acc: 0.1441 - val_loss: 10.1642 - val_mean_absolute_error: 2.1799 - val_acc: 0.1830\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 10.10606\n",
      "Epoch 79/500\n",
      "1548/1548 [==============================] - 0s 60us/step - loss: 10.1555 - mean_absolute_error: 2.3350 - acc: 0.1421 - val_loss: 10.1646 - val_mean_absolute_error: 2.1805 - val_acc: 0.1804\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 10.10606\n",
      "Epoch 80/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 10.1511 - mean_absolute_error: 2.3346 - acc: 0.1428 - val_loss: 10.1656 - val_mean_absolute_error: 2.1811 - val_acc: 0.1778\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 10.10606\n",
      "Epoch 81/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 10.1479 - mean_absolute_error: 2.3343 - acc: 0.1415 - val_loss: 10.1668 - val_mean_absolute_error: 2.1817 - val_acc: 0.1778\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 10.10606\n",
      "Epoch 82/500\n",
      "1548/1548 [==============================] - 0s 86us/step - loss: 10.1451 - mean_absolute_error: 2.3341 - acc: 0.1395 - val_loss: 10.1686 - val_mean_absolute_error: 2.1824 - val_acc: 0.1778\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 10.10606\n",
      "Epoch 83/500\n",
      "1548/1548 [==============================] - 0s 93us/step - loss: 10.1431 - mean_absolute_error: 2.3339 - acc: 0.1363 - val_loss: 10.1707 - val_mean_absolute_error: 2.1831 - val_acc: 0.1778\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 10.10606\n",
      "Epoch 84/500\n",
      "1548/1548 [==============================] - 0s 91us/step - loss: 10.1420 - mean_absolute_error: 2.3338 - acc: 0.1376 - val_loss: 10.1733 - val_mean_absolute_error: 2.1838 - val_acc: 0.1856\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 10.10606\n",
      "Epoch 85/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 0s 82us/step - loss: 10.1406 - mean_absolute_error: 2.3337 - acc: 0.1376 - val_loss: 10.1762 - val_mean_absolute_error: 2.1846 - val_acc: 0.1804\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 10.10606\n",
      "Epoch 86/500\n",
      "1548/1548 [==============================] - 0s 68us/step - loss: 10.1399 - mean_absolute_error: 2.3337 - acc: 0.1376 - val_loss: 10.1793 - val_mean_absolute_error: 2.1854 - val_acc: 0.1753\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 10.10606\n",
      "Epoch 87/500\n",
      "1548/1548 [==============================] - 0s 65us/step - loss: 10.1400 - mean_absolute_error: 2.3338 - acc: 0.1382 - val_loss: 10.1828 - val_mean_absolute_error: 2.1861 - val_acc: 0.1727\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 10.10606\n",
      "Epoch 88/500\n",
      "1548/1548 [==============================] - 0s 95us/step - loss: 10.1399 - mean_absolute_error: 2.3339 - acc: 0.1376 - val_loss: 10.1863 - val_mean_absolute_error: 2.1869 - val_acc: 0.1701\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 10.10606\n",
      "Epoch 89/500\n",
      "1548/1548 [==============================] - 0s 95us/step - loss: 10.1400 - mean_absolute_error: 2.3341 - acc: 0.1382 - val_loss: 10.1900 - val_mean_absolute_error: 2.1877 - val_acc: 0.1675\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 10.10606\n",
      "Epoch 90/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 10.1402 - mean_absolute_error: 2.3342 - acc: 0.1376 - val_loss: 10.1936 - val_mean_absolute_error: 2.1885 - val_acc: 0.1649\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 10.10606\n",
      "Epoch 91/500\n",
      "1548/1548 [==============================] - 0s 68us/step - loss: 10.1403 - mean_absolute_error: 2.3343 - acc: 0.1382 - val_loss: 10.1972 - val_mean_absolute_error: 2.1893 - val_acc: 0.1675\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 10.10606\n",
      "Epoch 92/500\n",
      "1548/1548 [==============================] - 0s 69us/step - loss: 10.1403 - mean_absolute_error: 2.3344 - acc: 0.1357 - val_loss: 10.2007 - val_mean_absolute_error: 2.1900 - val_acc: 0.1649\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 10.10606\n",
      "Epoch 93/500\n",
      "1548/1548 [==============================] - 0s 74us/step - loss: 10.1402 - mean_absolute_error: 2.3345 - acc: 0.1357 - val_loss: 10.2039 - val_mean_absolute_error: 2.1906 - val_acc: 0.1649\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 10.10606\n",
      "Epoch 94/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 10.1398 - mean_absolute_error: 2.3346 - acc: 0.1376 - val_loss: 10.2072 - val_mean_absolute_error: 2.1912 - val_acc: 0.1675\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 10.10606\n",
      "Epoch 95/500\n",
      "1548/1548 [==============================] - 0s 83us/step - loss: 10.1399 - mean_absolute_error: 2.3346 - acc: 0.1382 - val_loss: 10.2104 - val_mean_absolute_error: 2.1919 - val_acc: 0.1675\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 10.10606\n",
      "Epoch 96/500\n",
      "1548/1548 [==============================] - 0s 67us/step - loss: 10.1395 - mean_absolute_error: 2.3347 - acc: 0.1389 - val_loss: 10.2132 - val_mean_absolute_error: 2.1924 - val_acc: 0.1675\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 10.10606\n",
      "Epoch 97/500\n",
      "1548/1548 [==============================] - 0s 67us/step - loss: 10.1388 - mean_absolute_error: 2.3346 - acc: 0.1389 - val_loss: 10.2159 - val_mean_absolute_error: 2.1929 - val_acc: 0.1675\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 10.10606\n",
      "Epoch 98/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 10.1385 - mean_absolute_error: 2.3347 - acc: 0.1402 - val_loss: 10.2178 - val_mean_absolute_error: 2.1933 - val_acc: 0.1727\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 10.10606\n",
      "Epoch 99/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 10.1363 - mean_absolute_error: 2.3345 - acc: 0.1382 - val_loss: 10.2202 - val_mean_absolute_error: 2.1938 - val_acc: 0.1778\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 10.10606\n",
      "Epoch 100/500\n",
      "1548/1548 [==============================] - 0s 73us/step - loss: 10.1363 - mean_absolute_error: 2.3345 - acc: 0.1370 - val_loss: 10.2219 - val_mean_absolute_error: 2.1940 - val_acc: 0.1778\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 10.10606\n",
      "Epoch 101/500\n",
      "1548/1548 [==============================] - 0s 59us/step - loss: 10.1342 - mean_absolute_error: 2.3343 - acc: 0.1382 - val_loss: 10.2239 - val_mean_absolute_error: 2.1945 - val_acc: 0.1778\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 10.10606\n",
      "Epoch 102/500\n",
      "1548/1548 [==============================] - 0s 62us/step - loss: 10.1336 - mean_absolute_error: 2.3342 - acc: 0.1376 - val_loss: 10.2260 - val_mean_absolute_error: 2.1949 - val_acc: 0.1804\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 10.10606\n",
      "Epoch 103/500\n",
      "1548/1548 [==============================] - 0s 58us/step - loss: 10.1323 - mean_absolute_error: 2.3341 - acc: 0.1376 - val_loss: 10.2276 - val_mean_absolute_error: 2.1952 - val_acc: 0.1804\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 10.10606\n",
      "Epoch 104/500\n",
      "1548/1548 [==============================] - 0s 58us/step - loss: 10.1309 - mean_absolute_error: 2.3340 - acc: 0.1376 - val_loss: 10.2286 - val_mean_absolute_error: 2.1954 - val_acc: 0.1778\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 10.10606\n",
      "Epoch 105/500\n",
      "1548/1548 [==============================] - 0s 59us/step - loss: 10.1290 - mean_absolute_error: 2.3338 - acc: 0.1382 - val_loss: 10.2301 - val_mean_absolute_error: 2.1957 - val_acc: 0.1778\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 10.10606\n",
      "Epoch 106/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 10.1269 - mean_absolute_error: 2.3335 - acc: 0.1382 - val_loss: 10.2312 - val_mean_absolute_error: 2.1960 - val_acc: 0.1778\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 10.10606\n",
      "Epoch 00106: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1a2846c550>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN_baseline(X, y_RNFL, 'cRNFL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1548 samples, validate on 388 samples\n",
      "Epoch 1/500\n",
      "1548/1548 [==============================] - 1s 849us/step - loss: 0.3043 - mean_absolute_error: 0.4375 - acc: 0.0013 - val_loss: 0.1505 - val_mean_absolute_error: 0.3244 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15049, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 2/500\n",
      "1548/1548 [==============================] - 0s 91us/step - loss: 0.1308 - mean_absolute_error: 0.2946 - acc: 0.0013 - val_loss: 0.1388 - val_mean_absolute_error: 0.3106 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15049 to 0.13878, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 3/500\n",
      "1548/1548 [==============================] - 0s 84us/step - loss: 0.1134 - mean_absolute_error: 0.2737 - acc: 0.0013 - val_loss: 0.1093 - val_mean_absolute_error: 0.2611 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13878 to 0.10931, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 4/500\n",
      "1548/1548 [==============================] - 0s 94us/step - loss: 0.0749 - mean_absolute_error: 0.2050 - acc: 0.0013 - val_loss: 0.0667 - val_mean_absolute_error: 0.1891 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.10931 to 0.06672, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 5/500\n",
      "1548/1548 [==============================] - 0s 102us/step - loss: 0.0597 - mean_absolute_error: 0.1781 - acc: 0.0013 - val_loss: 0.0652 - val_mean_absolute_error: 0.1808 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.06672 to 0.06515, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 6/500\n",
      "1548/1548 [==============================] - 0s 120us/step - loss: 0.0562 - mean_absolute_error: 0.1727 - acc: 0.0013 - val_loss: 0.0606 - val_mean_absolute_error: 0.1752 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.06515 to 0.06060, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 7/500\n",
      "1548/1548 [==============================] - 0s 101us/step - loss: 0.0528 - mean_absolute_error: 0.1673 - acc: 0.0013 - val_loss: 0.0598 - val_mean_absolute_error: 0.1729 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.06060 to 0.05980, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 8/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 0.0508 - mean_absolute_error: 0.1643 - acc: 0.0013 - val_loss: 0.0592 - val_mean_absolute_error: 0.1702 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.05980 to 0.05917, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 9/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 0.0491 - mean_absolute_error: 0.1617 - acc: 0.0013 - val_loss: 0.0594 - val_mean_absolute_error: 0.1693 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05917\n",
      "Epoch 10/500\n",
      "1548/1548 [==============================] - 0s 96us/step - loss: 0.0478 - mean_absolute_error: 0.1597 - acc: 0.0013 - val_loss: 0.0596 - val_mean_absolute_error: 0.1692 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05917\n",
      "Epoch 11/500\n",
      "1548/1548 [==============================] - 0s 110us/step - loss: 0.0467 - mean_absolute_error: 0.1580 - acc: 0.0013 - val_loss: 0.0597 - val_mean_absolute_error: 0.1683 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.05917\n",
      "Epoch 12/500\n",
      "1548/1548 [==============================] - 0s 97us/step - loss: 0.0453 - mean_absolute_error: 0.1566 - acc: 0.0013 - val_loss: 0.0599 - val_mean_absolute_error: 0.1686 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.05917\n",
      "Epoch 13/500\n",
      "1548/1548 [==============================] - 0s 89us/step - loss: 0.0442 - mean_absolute_error: 0.1548 - acc: 0.0013 - val_loss: 0.0602 - val_mean_absolute_error: 0.1690 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.05917\n",
      "Epoch 14/500\n",
      "1548/1548 [==============================] - 0s 110us/step - loss: 0.0434 - mean_absolute_error: 0.1535 - acc: 0.0013 - val_loss: 0.0600 - val_mean_absolute_error: 0.1687 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.05917\n",
      "Epoch 15/500\n",
      "1548/1548 [==============================] - 0s 106us/step - loss: 0.0427 - mean_absolute_error: 0.1524 - acc: 0.0013 - val_loss: 0.0589 - val_mean_absolute_error: 0.1672 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.05917 to 0.05889, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 16/500\n",
      "1548/1548 [==============================] - 0s 117us/step - loss: 0.0421 - mean_absolute_error: 0.1513 - acc: 0.0013 - val_loss: 0.0580 - val_mean_absolute_error: 0.1661 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.05889 to 0.05803, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 17/500\n",
      "1548/1548 [==============================] - 0s 128us/step - loss: 0.0417 - mean_absolute_error: 0.1504 - acc: 0.0013 - val_loss: 0.0575 - val_mean_absolute_error: 0.1652 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.05803 to 0.05752, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 18/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 0.0414 - mean_absolute_error: 0.1498 - acc: 0.0013 - val_loss: 0.0572 - val_mean_absolute_error: 0.1649 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.05752 to 0.05719, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 19/500\n",
      "1548/1548 [==============================] - 0s 60us/step - loss: 0.0410 - mean_absolute_error: 0.1487 - acc: 0.0013 - val_loss: 0.0533 - val_mean_absolute_error: 0.1597 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.05719 to 0.05328, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 20/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 0.0408 - mean_absolute_error: 0.1483 - acc: 0.0013 - val_loss: 0.0551 - val_mean_absolute_error: 0.1619 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.05328\n",
      "Epoch 21/500\n",
      "1548/1548 [==============================] - 0s 115us/step - loss: 0.0403 - mean_absolute_error: 0.1471 - acc: 0.0013 - val_loss: 0.0520 - val_mean_absolute_error: 0.1575 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.05328 to 0.05199, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 22/500\n",
      "1548/1548 [==============================] - 0s 88us/step - loss: 0.0401 - mean_absolute_error: 0.1469 - acc: 0.0013 - val_loss: 0.0532 - val_mean_absolute_error: 0.1590 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.05199\n",
      "Epoch 23/500\n",
      "1548/1548 [==============================] - 0s 89us/step - loss: 0.0398 - mean_absolute_error: 0.1461 - acc: 0.0013 - val_loss: 0.0519 - val_mean_absolute_error: 0.1571 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.05199 to 0.05194, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 24/500\n",
      "1548/1548 [==============================] - 0s 86us/step - loss: 0.0393 - mean_absolute_error: 0.1448 - acc: 0.0013 - val_loss: 0.0489 - val_mean_absolute_error: 0.1532 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.05194 to 0.04894, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 25/500\n",
      "1548/1548 [==============================] - 0s 95us/step - loss: 0.0389 - mean_absolute_error: 0.1439 - acc: 0.0013 - val_loss: 0.0483 - val_mean_absolute_error: 0.1523 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.04894 to 0.04831, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 26/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 0.0385 - mean_absolute_error: 0.1427 - acc: 0.0013 - val_loss: 0.0470 - val_mean_absolute_error: 0.1508 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.04831 to 0.04700, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 27/500\n",
      "1548/1548 [==============================] - 0s 98us/step - loss: 0.0384 - mean_absolute_error: 0.1427 - acc: 0.0013 - val_loss: 0.0473 - val_mean_absolute_error: 0.1507 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.04700\n",
      "Epoch 28/500\n",
      "1548/1548 [==============================] - 0s 80us/step - loss: 0.0382 - mean_absolute_error: 0.1421 - acc: 0.0013 - val_loss: 0.0467 - val_mean_absolute_error: 0.1497 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.04700 to 0.04672, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 29/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 0.0379 - mean_absolute_error: 0.1410 - acc: 0.0013 - val_loss: 0.0463 - val_mean_absolute_error: 0.1491 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.04672 to 0.04634, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 30/500\n",
      "1548/1548 [==============================] - 0s 126us/step - loss: 0.0379 - mean_absolute_error: 0.1414 - acc: 0.0013 - val_loss: 0.0463 - val_mean_absolute_error: 0.1493 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.04634 to 0.04626, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 31/500\n",
      "1548/1548 [==============================] - 0s 83us/step - loss: 0.0374 - mean_absolute_error: 0.1402 - acc: 0.0013 - val_loss: 0.0457 - val_mean_absolute_error: 0.1484 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.04626 to 0.04567, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 32/500\n",
      "1548/1548 [==============================] - 0s 87us/step - loss: 0.0374 - mean_absolute_error: 0.1398 - acc: 0.0013 - val_loss: 0.0459 - val_mean_absolute_error: 0.1480 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.04567\n",
      "Epoch 33/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 0.0370 - mean_absolute_error: 0.1393 - acc: 0.0013 - val_loss: 0.0454 - val_mean_absolute_error: 0.1473 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.04567 to 0.04540, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 34/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 0.0370 - mean_absolute_error: 0.1388 - acc: 0.0013 - val_loss: 0.0454 - val_mean_absolute_error: 0.1471 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.04540\n",
      "Epoch 35/500\n",
      "1548/1548 [==============================] - 0s 84us/step - loss: 0.0367 - mean_absolute_error: 0.1384 - acc: 0.0013 - val_loss: 0.0455 - val_mean_absolute_error: 0.1463 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.04540\n",
      "Epoch 36/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 0.0365 - mean_absolute_error: 0.1379 - acc: 0.0013 - val_loss: 0.0450 - val_mean_absolute_error: 0.1461 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.04540 to 0.04502, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 37/500\n",
      "1548/1548 [==============================] - 0s 99us/step - loss: 0.0369 - mean_absolute_error: 0.1383 - acc: 0.0013 - val_loss: 0.0448 - val_mean_absolute_error: 0.1460 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.04502 to 0.04483, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 38/500\n",
      "1548/1548 [==============================] - 0s 95us/step - loss: 0.0365 - mean_absolute_error: 0.1374 - acc: 0.0013 - val_loss: 0.0448 - val_mean_absolute_error: 0.1454 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.04483 to 0.04481, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 39/500\n",
      "1548/1548 [==============================] - 0s 94us/step - loss: 0.0363 - mean_absolute_error: 0.1372 - acc: 0.0013 - val_loss: 0.0453 - val_mean_absolute_error: 0.1455 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.04481\n",
      "Epoch 40/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 0.0354 - mean_absolute_error: 0.1359 - acc: 0.0013 - val_loss: 0.0460 - val_mean_absolute_error: 0.1465 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.04481\n",
      "Epoch 41/500\n",
      "1548/1548 [==============================] - 0s 74us/step - loss: 0.0356 - mean_absolute_error: 0.1358 - acc: 0.0013 - val_loss: 0.0456 - val_mean_absolute_error: 0.1458 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.04481\n",
      "Epoch 42/500\n",
      "1548/1548 [==============================] - 0s 80us/step - loss: 0.0356 - mean_absolute_error: 0.1355 - acc: 0.0013 - val_loss: 0.0441 - val_mean_absolute_error: 0.1440 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.04481 to 0.04415, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 43/500\n",
      "1548/1548 [==============================] - 0s 58us/step - loss: 0.0359 - mean_absolute_error: 0.1359 - acc: 0.0013 - val_loss: 0.0445 - val_mean_absolute_error: 0.1439 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.04415\n",
      "Epoch 44/500\n",
      "1548/1548 [==============================] - 0s 62us/step - loss: 0.0355 - mean_absolute_error: 0.1349 - acc: 0.0013 - val_loss: 0.0441 - val_mean_absolute_error: 0.1433 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.04415 to 0.04410, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 45/500\n",
      "1548/1548 [==============================] - 0s 55us/step - loss: 0.0356 - mean_absolute_error: 0.1350 - acc: 0.0013 - val_loss: 0.0443 - val_mean_absolute_error: 0.1440 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.04410\n",
      "Epoch 46/500\n",
      "1548/1548 [==============================] - 0s 75us/step - loss: 0.0350 - mean_absolute_error: 0.1340 - acc: 0.0013 - val_loss: 0.0438 - val_mean_absolute_error: 0.1428 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.04410 to 0.04379, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 47/500\n",
      "1548/1548 [==============================] - 0s 69us/step - loss: 0.0350 - mean_absolute_error: 0.1337 - acc: 0.0013 - val_loss: 0.0438 - val_mean_absolute_error: 0.1426 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.04379 to 0.04376, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 48/500\n",
      "1548/1548 [==============================] - 0s 68us/step - loss: 0.0349 - mean_absolute_error: 0.1334 - acc: 0.0013 - val_loss: 0.0438 - val_mean_absolute_error: 0.1424 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.04376\n",
      "Epoch 49/500\n",
      "1548/1548 [==============================] - 0s 104us/step - loss: 0.0348 - mean_absolute_error: 0.1332 - acc: 0.0013 - val_loss: 0.0436 - val_mean_absolute_error: 0.1419 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.04376 to 0.04362, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 50/500\n",
      "1548/1548 [==============================] - 0s 75us/step - loss: 0.0346 - mean_absolute_error: 0.1328 - acc: 0.0013 - val_loss: 0.0436 - val_mean_absolute_error: 0.1418 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.04362\n",
      "Epoch 51/500\n",
      "1548/1548 [==============================] - 0s 60us/step - loss: 0.0344 - mean_absolute_error: 0.1323 - acc: 0.0013 - val_loss: 0.0437 - val_mean_absolute_error: 0.1418 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.04362\n",
      "Epoch 52/500\n",
      "1548/1548 [==============================] - 0s 65us/step - loss: 0.0350 - mean_absolute_error: 0.1333 - acc: 0.0013 - val_loss: 0.0438 - val_mean_absolute_error: 0.1434 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.04362\n",
      "Epoch 53/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 0.0342 - mean_absolute_error: 0.1325 - acc: 0.0013 - val_loss: 0.0438 - val_mean_absolute_error: 0.1423 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.04362\n",
      "Epoch 54/500\n",
      "1548/1548 [==============================] - 0s 105us/step - loss: 0.0342 - mean_absolute_error: 0.1318 - acc: 0.0013 - val_loss: 0.0434 - val_mean_absolute_error: 0.1414 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.04362 to 0.04337, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 55/500\n",
      "1548/1548 [==============================] - 0s 74us/step - loss: 0.0343 - mean_absolute_error: 0.1316 - acc: 0.0013 - val_loss: 0.0434 - val_mean_absolute_error: 0.1413 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.04337 to 0.04335, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 56/500\n",
      "1548/1548 [==============================] - 0s 78us/step - loss: 0.0340 - mean_absolute_error: 0.1310 - acc: 0.0013 - val_loss: 0.0430 - val_mean_absolute_error: 0.1409 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.04335 to 0.04299, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 57/500\n",
      "1548/1548 [==============================] - 0s 75us/step - loss: 0.0341 - mean_absolute_error: 0.1315 - acc: 0.0013 - val_loss: 0.0431 - val_mean_absolute_error: 0.1413 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.04299\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 0s 118us/step - loss: 0.0338 - mean_absolute_error: 0.1305 - acc: 0.0013 - val_loss: 0.0433 - val_mean_absolute_error: 0.1409 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.04299\n",
      "Epoch 59/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 0.0336 - mean_absolute_error: 0.1308 - acc: 0.0013 - val_loss: 0.0428 - val_mean_absolute_error: 0.1405 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.04299 to 0.04276, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 60/500\n",
      "1548/1548 [==============================] - 0s 80us/step - loss: 0.0336 - mean_absolute_error: 0.1299 - acc: 0.0013 - val_loss: 0.0429 - val_mean_absolute_error: 0.1405 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.04276\n",
      "Epoch 61/500\n",
      "1548/1548 [==============================] - 0s 78us/step - loss: 0.0336 - mean_absolute_error: 0.1303 - acc: 0.0013 - val_loss: 0.0427 - val_mean_absolute_error: 0.1404 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.04276 to 0.04275, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 62/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 0.0336 - mean_absolute_error: 0.1299 - acc: 0.0013 - val_loss: 0.0425 - val_mean_absolute_error: 0.1403 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.04275 to 0.04253, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 63/500\n",
      "1548/1548 [==============================] - 0s 73us/step - loss: 0.0338 - mean_absolute_error: 0.1305 - acc: 0.0013 - val_loss: 0.0425 - val_mean_absolute_error: 0.1412 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.04253 to 0.04251, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 64/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 0.0338 - mean_absolute_error: 0.1303 - acc: 0.0013 - val_loss: 0.0426 - val_mean_absolute_error: 0.1407 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.04251\n",
      "Epoch 65/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 0.0337 - mean_absolute_error: 0.1301 - acc: 0.0013 - val_loss: 0.0430 - val_mean_absolute_error: 0.1423 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.04251\n",
      "Epoch 66/500\n",
      "1548/1548 [==============================] - 0s 64us/step - loss: 0.0332 - mean_absolute_error: 0.1294 - acc: 0.0013 - val_loss: 0.0424 - val_mean_absolute_error: 0.1404 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.04251 to 0.04236, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 67/500\n",
      "1548/1548 [==============================] - 0s 67us/step - loss: 0.0333 - mean_absolute_error: 0.1292 - acc: 0.0013 - val_loss: 0.0428 - val_mean_absolute_error: 0.1415 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.04236\n",
      "Epoch 68/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 0.0333 - mean_absolute_error: 0.1295 - acc: 0.0013 - val_loss: 0.0425 - val_mean_absolute_error: 0.1405 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.04236\n",
      "Epoch 69/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 0.0332 - mean_absolute_error: 0.1289 - acc: 0.0013 - val_loss: 0.0424 - val_mean_absolute_error: 0.1417 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.04236\n",
      "Epoch 70/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 0.0334 - mean_absolute_error: 0.1295 - acc: 0.0013 - val_loss: 0.0424 - val_mean_absolute_error: 0.1409 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.04236\n",
      "Epoch 71/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 0.0331 - mean_absolute_error: 0.1288 - acc: 0.0013 - val_loss: 0.0426 - val_mean_absolute_error: 0.1416 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.04236\n",
      "Epoch 72/500\n",
      "1548/1548 [==============================] - 0s 65us/step - loss: 0.0330 - mean_absolute_error: 0.1287 - acc: 0.0013 - val_loss: 0.0423 - val_mean_absolute_error: 0.1410 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.04236 to 0.04235, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 73/500\n",
      "1548/1548 [==============================] - 0s 68us/step - loss: 0.0329 - mean_absolute_error: 0.1282 - acc: 0.0013 - val_loss: 0.0424 - val_mean_absolute_error: 0.1415 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.04235\n",
      "Epoch 74/500\n",
      "1548/1548 [==============================] - 0s 78us/step - loss: 0.0329 - mean_absolute_error: 0.1283 - acc: 0.0013 - val_loss: 0.0423 - val_mean_absolute_error: 0.1404 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.04235 to 0.04234, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 75/500\n",
      "1548/1548 [==============================] - 0s 89us/step - loss: 0.0326 - mean_absolute_error: 0.1279 - acc: 0.0013 - val_loss: 0.0424 - val_mean_absolute_error: 0.1403 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.04234\n",
      "Epoch 76/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 0.0330 - mean_absolute_error: 0.1287 - acc: 0.0013 - val_loss: 0.0424 - val_mean_absolute_error: 0.1422 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.04234\n",
      "Epoch 77/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 0.0330 - mean_absolute_error: 0.1283 - acc: 0.0013 - val_loss: 0.0422 - val_mean_absolute_error: 0.1401 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.04234 to 0.04220, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 78/500\n",
      "1548/1548 [==============================] - 0s 69us/step - loss: 0.0330 - mean_absolute_error: 0.1284 - acc: 0.0013 - val_loss: 0.0427 - val_mean_absolute_error: 0.1419 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.04220\n",
      "Epoch 79/500\n",
      "1548/1548 [==============================] - 0s 105us/step - loss: 0.0328 - mean_absolute_error: 0.1279 - acc: 0.0013 - val_loss: 0.0425 - val_mean_absolute_error: 0.1418 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.04220\n",
      "Epoch 80/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 0.0332 - mean_absolute_error: 0.1288 - acc: 0.0013 - val_loss: 0.0429 - val_mean_absolute_error: 0.1425 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.04220\n",
      "Epoch 81/500\n",
      "1548/1548 [==============================] - 0s 93us/step - loss: 0.0322 - mean_absolute_error: 0.1271 - acc: 0.0013 - val_loss: 0.0424 - val_mean_absolute_error: 0.1403 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.04220\n",
      "Epoch 82/500\n",
      "1548/1548 [==============================] - 0s 59us/step - loss: 0.0326 - mean_absolute_error: 0.1274 - acc: 0.0013 - val_loss: 0.0422 - val_mean_absolute_error: 0.1405 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.04220\n",
      "Epoch 83/500\n",
      "1548/1548 [==============================] - 0s 54us/step - loss: 0.0328 - mean_absolute_error: 0.1281 - acc: 0.0013 - val_loss: 0.0426 - val_mean_absolute_error: 0.1417 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.04220\n",
      "Epoch 84/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 0.0327 - mean_absolute_error: 0.1279 - acc: 0.0013 - val_loss: 0.0425 - val_mean_absolute_error: 0.1415 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.04220\n",
      "Epoch 85/500\n",
      "1548/1548 [==============================] - 0s 94us/step - loss: 0.0323 - mean_absolute_error: 0.1272 - acc: 0.0013 - val_loss: 0.0422 - val_mean_absolute_error: 0.1403 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.04220\n",
      "Epoch 86/500\n",
      "1548/1548 [==============================] - 0s 94us/step - loss: 0.0322 - mean_absolute_error: 0.1268 - acc: 0.0013 - val_loss: 0.0425 - val_mean_absolute_error: 0.1399 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.04220\n",
      "Epoch 87/500\n",
      "1548/1548 [==============================] - 0s 106us/step - loss: 0.0322 - mean_absolute_error: 0.1267 - acc: 0.0013 - val_loss: 0.0422 - val_mean_absolute_error: 0.1412 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.04220 to 0.04216, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 88/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 0.0325 - mean_absolute_error: 0.1274 - acc: 0.0013 - val_loss: 0.0422 - val_mean_absolute_error: 0.1412 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.04216\n",
      "Epoch 89/500\n",
      "1548/1548 [==============================] - 0s 96us/step - loss: 0.0323 - mean_absolute_error: 0.1268 - acc: 0.0013 - val_loss: 0.0424 - val_mean_absolute_error: 0.1424 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.04216\n",
      "Epoch 90/500\n",
      "1548/1548 [==============================] - 0s 150us/step - loss: 0.0324 - mean_absolute_error: 0.1274 - acc: 0.0013 - val_loss: 0.0424 - val_mean_absolute_error: 0.1402 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.04216\n",
      "Epoch 91/500\n",
      "1548/1548 [==============================] - 0s 105us/step - loss: 0.0318 - mean_absolute_error: 0.1260 - acc: 0.0013 - val_loss: 0.0422 - val_mean_absolute_error: 0.1396 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.04216\n",
      "Epoch 92/500\n",
      "1548/1548 [==============================] - 0s 127us/step - loss: 0.0321 - mean_absolute_error: 0.1267 - acc: 0.0013 - val_loss: 0.0420 - val_mean_absolute_error: 0.1405 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.04216 to 0.04198, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 93/500\n",
      "1548/1548 [==============================] - 0s 101us/step - loss: 0.0324 - mean_absolute_error: 0.1269 - acc: 0.0013 - val_loss: 0.0422 - val_mean_absolute_error: 0.1407 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.04198\n",
      "Epoch 94/500\n",
      "1548/1548 [==============================] - 0s 99us/step - loss: 0.0325 - mean_absolute_error: 0.1274 - acc: 0.0013 - val_loss: 0.0424 - val_mean_absolute_error: 0.1419 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.04198\n",
      "Epoch 95/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 0.0323 - mean_absolute_error: 0.1269 - acc: 0.0013 - val_loss: 0.0422 - val_mean_absolute_error: 0.1403 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.04198\n",
      "Epoch 96/500\n",
      "1548/1548 [==============================] - 0s 66us/step - loss: 0.0321 - mean_absolute_error: 0.1264 - acc: 0.0013 - val_loss: 0.0423 - val_mean_absolute_error: 0.1409 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.04198\n",
      "Epoch 97/500\n",
      "1548/1548 [==============================] - 0s 57us/step - loss: 0.0320 - mean_absolute_error: 0.1263 - acc: 0.0013 - val_loss: 0.0421 - val_mean_absolute_error: 0.1399 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.04198\n",
      "Epoch 98/500\n",
      "1548/1548 [==============================] - 0s 60us/step - loss: 0.0321 - mean_absolute_error: 0.1263 - acc: 0.0013 - val_loss: 0.0421 - val_mean_absolute_error: 0.1404 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.04198\n",
      "Epoch 99/500\n",
      "1548/1548 [==============================] - 0s 68us/step - loss: 0.0320 - mean_absolute_error: 0.1262 - acc: 0.0013 - val_loss: 0.0423 - val_mean_absolute_error: 0.1407 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.04198\n",
      "Epoch 100/500\n",
      "1548/1548 [==============================] - 0s 68us/step - loss: 0.0318 - mean_absolute_error: 0.1258 - acc: 0.0013 - val_loss: 0.0423 - val_mean_absolute_error: 0.1400 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.04198\n",
      "Epoch 101/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 0.0317 - mean_absolute_error: 0.1257 - acc: 0.0013 - val_loss: 0.0420 - val_mean_absolute_error: 0.1402 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.04198\n",
      "Epoch 102/500\n",
      "1548/1548 [==============================] - 0s 80us/step - loss: 0.0319 - mean_absolute_error: 0.1258 - acc: 0.0013 - val_loss: 0.0424 - val_mean_absolute_error: 0.1402 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.04198\n",
      "Epoch 103/500\n",
      "1548/1548 [==============================] - 0s 61us/step - loss: 0.0316 - mean_absolute_error: 0.1254 - acc: 0.0013 - val_loss: 0.0422 - val_mean_absolute_error: 0.1401 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.04198\n",
      "Epoch 104/500\n",
      "1548/1548 [==============================] - 0s 79us/step - loss: 0.0317 - mean_absolute_error: 0.1254 - acc: 0.0013 - val_loss: 0.0421 - val_mean_absolute_error: 0.1402 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.04198\n",
      "Epoch 105/500\n",
      "1548/1548 [==============================] - 0s 68us/step - loss: 0.0320 - mean_absolute_error: 0.1259 - acc: 0.0013 - val_loss: 0.0420 - val_mean_absolute_error: 0.1406 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.04198\n",
      "Epoch 106/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 0.0319 - mean_absolute_error: 0.1260 - acc: 0.0013 - val_loss: 0.0421 - val_mean_absolute_error: 0.1411 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.04198\n",
      "Epoch 107/500\n",
      "1548/1548 [==============================] - 0s 59us/step - loss: 0.0316 - mean_absolute_error: 0.1254 - acc: 0.0013 - val_loss: 0.0421 - val_mean_absolute_error: 0.1401 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.04198\n",
      "Epoch 108/500\n",
      "1548/1548 [==============================] - 0s 65us/step - loss: 0.0319 - mean_absolute_error: 0.1258 - acc: 0.0013 - val_loss: 0.0422 - val_mean_absolute_error: 0.1413 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.04198\n",
      "Epoch 109/500\n",
      "1548/1548 [==============================] - 0s 68us/step - loss: 0.0317 - mean_absolute_error: 0.1253 - acc: 0.0013 - val_loss: 0.0421 - val_mean_absolute_error: 0.1410 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.04198\n",
      "Epoch 110/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 0.0317 - mean_absolute_error: 0.1253 - acc: 0.0013 - val_loss: 0.0422 - val_mean_absolute_error: 0.1412 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.04198\n",
      "Epoch 111/500\n",
      "1548/1548 [==============================] - 0s 112us/step - loss: 0.0315 - mean_absolute_error: 0.1248 - acc: 0.0013 - val_loss: 0.0421 - val_mean_absolute_error: 0.1402 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.04198\n",
      "Epoch 112/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 0.0316 - mean_absolute_error: 0.1250 - acc: 0.0013 - val_loss: 0.0423 - val_mean_absolute_error: 0.1415 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.04198\n",
      "Epoch 113/500\n",
      "1548/1548 [==============================] - 0s 63us/step - loss: 0.0317 - mean_absolute_error: 0.1254 - acc: 0.0013 - val_loss: 0.0424 - val_mean_absolute_error: 0.1411 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.04198\n",
      "Epoch 114/500\n",
      "1548/1548 [==============================] - 0s 58us/step - loss: 0.0311 - mean_absolute_error: 0.1243 - acc: 0.0013 - val_loss: 0.0423 - val_mean_absolute_error: 0.1403 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.04198\n",
      "Epoch 115/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 0.0311 - mean_absolute_error: 0.1241 - acc: 0.0013 - val_loss: 0.0422 - val_mean_absolute_error: 0.1407 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.04198\n",
      "Epoch 116/500\n",
      "1548/1548 [==============================] - 0s 60us/step - loss: 0.0315 - mean_absolute_error: 0.1250 - acc: 0.0013 - val_loss: 0.0422 - val_mean_absolute_error: 0.1412 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.04198\n",
      "Epoch 117/500\n",
      "1548/1548 [==============================] - 0s 99us/step - loss: 0.0315 - mean_absolute_error: 0.1250 - acc: 0.0013 - val_loss: 0.0429 - val_mean_absolute_error: 0.1407 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.04198\n",
      "Epoch 118/500\n",
      "1548/1548 [==============================] - 0s 87us/step - loss: 0.0311 - mean_absolute_error: 0.1240 - acc: 0.0013 - val_loss: 0.0423 - val_mean_absolute_error: 0.1417 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.04198\n",
      "Epoch 119/500\n",
      "1548/1548 [==============================] - 0s 93us/step - loss: 0.0310 - mean_absolute_error: 0.1239 - acc: 0.0013 - val_loss: 0.0424 - val_mean_absolute_error: 0.1404 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00119: val_loss did not improve from 0.04198\n",
      "Epoch 120/500\n",
      "1548/1548 [==============================] - 0s 60us/step - loss: 0.0315 - mean_absolute_error: 0.1248 - acc: 0.0013 - val_loss: 0.0422 - val_mean_absolute_error: 0.1414 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.04198\n",
      "Epoch 121/500\n",
      "1548/1548 [==============================] - 0s 61us/step - loss: 0.0315 - mean_absolute_error: 0.1246 - acc: 0.0013 - val_loss: 0.0426 - val_mean_absolute_error: 0.1410 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.04198\n",
      "Epoch 122/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 0.0312 - mean_absolute_error: 0.1243 - acc: 0.0013 - val_loss: 0.0422 - val_mean_absolute_error: 0.1406 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.04198\n",
      "Epoch 123/500\n",
      "1548/1548 [==============================] - 0s 95us/step - loss: 0.0311 - mean_absolute_error: 0.1239 - acc: 0.0013 - val_loss: 0.0424 - val_mean_absolute_error: 0.1407 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.04198\n",
      "Epoch 124/500\n",
      "1548/1548 [==============================] - 0s 67us/step - loss: 0.0310 - mean_absolute_error: 0.1237 - acc: 0.0013 - val_loss: 0.0425 - val_mean_absolute_error: 0.1421 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.04198\n",
      "Epoch 125/500\n",
      "1548/1548 [==============================] - 0s 65us/step - loss: 0.0310 - mean_absolute_error: 0.1238 - acc: 0.0013 - val_loss: 0.0424 - val_mean_absolute_error: 0.1407 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.04198\n",
      "Epoch 126/500\n",
      "1548/1548 [==============================] - 0s 65us/step - loss: 0.0309 - mean_absolute_error: 0.1236 - acc: 0.0013 - val_loss: 0.0425 - val_mean_absolute_error: 0.1415 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.04198\n",
      "Epoch 127/500\n",
      "1548/1548 [==============================] - 0s 59us/step - loss: 0.0313 - mean_absolute_error: 0.1244 - acc: 0.0013 - val_loss: 0.0425 - val_mean_absolute_error: 0.1417 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.04198\n",
      "Epoch 128/500\n",
      "1548/1548 [==============================] - 0s 66us/step - loss: 0.0315 - mean_absolute_error: 0.1243 - acc: 0.0013 - val_loss: 0.0425 - val_mean_absolute_error: 0.1420 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.04198\n",
      "Epoch 129/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 0.0312 - mean_absolute_error: 0.1244 - acc: 0.0013 - val_loss: 0.0426 - val_mean_absolute_error: 0.1409 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.04198\n",
      "Epoch 130/500\n",
      "1548/1548 [==============================] - 0s 101us/step - loss: 0.0309 - mean_absolute_error: 0.1236 - acc: 0.0013 - val_loss: 0.0427 - val_mean_absolute_error: 0.1410 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.04198\n",
      "Epoch 131/500\n",
      "1548/1548 [==============================] - 0s 88us/step - loss: 0.0310 - mean_absolute_error: 0.1237 - acc: 0.0013 - val_loss: 0.0429 - val_mean_absolute_error: 0.1425 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.04198\n",
      "Epoch 132/500\n",
      "1548/1548 [==============================] - 0s 74us/step - loss: 0.0311 - mean_absolute_error: 0.1242 - acc: 0.0013 - val_loss: 0.0428 - val_mean_absolute_error: 0.1412 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.04198\n",
      "Epoch 133/500\n",
      "1548/1548 [==============================] - 0s 61us/step - loss: 0.0313 - mean_absolute_error: 0.1241 - acc: 0.0013 - val_loss: 0.0431 - val_mean_absolute_error: 0.1444 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.04198\n",
      "Epoch 134/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 0.0315 - mean_absolute_error: 0.1246 - acc: 0.0013 - val_loss: 0.0427 - val_mean_absolute_error: 0.1419 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.04198\n",
      "Epoch 135/500\n",
      "1548/1548 [==============================] - 0s 62us/step - loss: 0.0306 - mean_absolute_error: 0.1227 - acc: 0.0013 - val_loss: 0.0427 - val_mean_absolute_error: 0.1422 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.04198\n",
      "Epoch 136/500\n",
      "1548/1548 [==============================] - 0s 91us/step - loss: 0.0305 - mean_absolute_error: 0.1226 - acc: 0.0013 - val_loss: 0.0428 - val_mean_absolute_error: 0.1429 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.04198\n",
      "Epoch 137/500\n",
      "1548/1548 [==============================] - 0s 83us/step - loss: 0.0314 - mean_absolute_error: 0.1242 - acc: 0.0013 - val_loss: 0.0431 - val_mean_absolute_error: 0.1442 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.04198\n",
      "Epoch 138/500\n",
      "1548/1548 [==============================] - 0s 60us/step - loss: 0.0308 - mean_absolute_error: 0.1233 - acc: 0.0013 - val_loss: 0.0425 - val_mean_absolute_error: 0.1413 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.04198\n",
      "Epoch 139/500\n",
      "1548/1548 [==============================] - 0s 66us/step - loss: 0.0307 - mean_absolute_error: 0.1231 - acc: 0.0013 - val_loss: 0.0425 - val_mean_absolute_error: 0.1420 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.04198\n",
      "Epoch 140/500\n",
      "1548/1548 [==============================] - 0s 67us/step - loss: 0.0310 - mean_absolute_error: 0.1237 - acc: 0.0013 - val_loss: 0.0431 - val_mean_absolute_error: 0.1435 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.04198\n",
      "Epoch 141/500\n",
      "1548/1548 [==============================] - 0s 75us/step - loss: 0.0310 - mean_absolute_error: 0.1236 - acc: 0.0013 - val_loss: 0.0428 - val_mean_absolute_error: 0.1428 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.04198\n",
      "Epoch 142/500\n",
      "1548/1548 [==============================] - 0s 75us/step - loss: 0.0304 - mean_absolute_error: 0.1226 - acc: 0.0013 - val_loss: 0.0430 - val_mean_absolute_error: 0.1426 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.04198\n",
      "Epoch 00142: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1a2abd7b38>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN_baseline(X, y_MD, 'MD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1548 samples, validate on 388 samples\n",
      "Epoch 1/500\n",
      "1548/1548 [==============================] - 1s 674us/step - loss: 3546.2425 - mean_absolute_error: 55.3437 - acc: 0.0000e+00 - val_loss: 139.3901 - val_mean_absolute_error: 11.3135 - val_acc: 0.0026\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 139.39014, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 2/500\n",
      "1548/1548 [==============================] - 0s 118us/step - loss: 54.6957 - mean_absolute_error: 5.6638 - acc: 0.0633 - val_loss: 11.3813 - val_mean_absolute_error: 2.5753 - val_acc: 0.1418\n",
      "\n",
      "Epoch 00002: val_loss improved from 139.39014 to 11.38129, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 3/500\n",
      "1548/1548 [==============================] - 0s 87us/step - loss: 12.9389 - mean_absolute_error: 2.5795 - acc: 0.1234 - val_loss: 10.7006 - val_mean_absolute_error: 2.4809 - val_acc: 0.1443\n",
      "\n",
      "Epoch 00003: val_loss improved from 11.38129 to 10.70060, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 4/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 12.3631 - mean_absolute_error: 2.4988 - acc: 0.1415 - val_loss: 10.4727 - val_mean_absolute_error: 2.4601 - val_acc: 0.1443\n",
      "\n",
      "Epoch 00004: val_loss improved from 10.70060 to 10.47266, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 5/500\n",
      "1548/1548 [==============================] - 0s 101us/step - loss: 12.0178 - mean_absolute_error: 2.4522 - acc: 0.1363 - val_loss: 10.0290 - val_mean_absolute_error: 2.4051 - val_acc: 0.1521\n",
      "\n",
      "Epoch 00005: val_loss improved from 10.47266 to 10.02896, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 6/500\n",
      "1548/1548 [==============================] - 0s 84us/step - loss: 11.6253 - mean_absolute_error: 2.3997 - acc: 0.1350 - val_loss: 9.3680 - val_mean_absolute_error: 2.3125 - val_acc: 0.1675\n",
      "\n",
      "Epoch 00006: val_loss improved from 10.02896 to 9.36803, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 7/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 11.1830 - mean_absolute_error: 2.3366 - acc: 0.1311 - val_loss: 8.6326 - val_mean_absolute_error: 2.2032 - val_acc: 0.2036\n",
      "\n",
      "Epoch 00007: val_loss improved from 9.36803 to 8.63265, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 8/500\n",
      "1548/1548 [==============================] - 0s 88us/step - loss: 10.6974 - mean_absolute_error: 2.2641 - acc: 0.1415 - val_loss: 8.0393 - val_mean_absolute_error: 2.1127 - val_acc: 0.2062\n",
      "\n",
      "Epoch 00008: val_loss improved from 8.63265 to 8.03926, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 9/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 10.2112 - mean_absolute_error: 2.1893 - acc: 0.1486 - val_loss: 7.5986 - val_mean_absolute_error: 2.0505 - val_acc: 0.2062\n",
      "\n",
      "Epoch 00009: val_loss improved from 8.03926 to 7.59856, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 10/500\n",
      "1548/1548 [==============================] - 0s 67us/step - loss: 9.7594 - mean_absolute_error: 2.1184 - acc: 0.1550 - val_loss: 7.2461 - val_mean_absolute_error: 2.0030 - val_acc: 0.2088\n",
      "\n",
      "Epoch 00010: val_loss improved from 7.59856 to 7.24605, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 11/500\n",
      "1548/1548 [==============================] - 0s 105us/step - loss: 9.3428 - mean_absolute_error: 2.0513 - acc: 0.1654 - val_loss: 6.9608 - val_mean_absolute_error: 1.9652 - val_acc: 0.1753\n",
      "\n",
      "Epoch 00011: val_loss improved from 7.24605 to 6.96083, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 12/500\n",
      "1548/1548 [==============================] - 0s 79us/step - loss: 8.9553 - mean_absolute_error: 1.9867 - acc: 0.1731 - val_loss: 6.7439 - val_mean_absolute_error: 1.9451 - val_acc: 0.1881\n",
      "\n",
      "Epoch 00012: val_loss improved from 6.96083 to 6.74388, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 13/500\n",
      "1548/1548 [==============================] - 0s 78us/step - loss: 8.5954 - mean_absolute_error: 1.9238 - acc: 0.1822 - val_loss: 6.5928 - val_mean_absolute_error: 1.9370 - val_acc: 0.1804\n",
      "\n",
      "Epoch 00013: val_loss improved from 6.74388 to 6.59282, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 14/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 8.2631 - mean_absolute_error: 1.8630 - acc: 0.1906 - val_loss: 6.4816 - val_mean_absolute_error: 1.9334 - val_acc: 0.1649\n",
      "\n",
      "Epoch 00014: val_loss improved from 6.59282 to 6.48162, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 15/500\n",
      "1548/1548 [==============================] - 0s 91us/step - loss: 7.9572 - mean_absolute_error: 1.8043 - acc: 0.1996 - val_loss: 6.3623 - val_mean_absolute_error: 1.9270 - val_acc: 0.1572\n",
      "\n",
      "Epoch 00015: val_loss improved from 6.48162 to 6.36227, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 16/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 7.6761 - mean_absolute_error: 1.7482 - acc: 0.2054 - val_loss: 6.2021 - val_mean_absolute_error: 1.9088 - val_acc: 0.1727\n",
      "\n",
      "Epoch 00016: val_loss improved from 6.36227 to 6.20211, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 17/500\n",
      "1548/1548 [==============================] - 0s 63us/step - loss: 7.4198 - mean_absolute_error: 1.6955 - acc: 0.2196 - val_loss: 6.0199 - val_mean_absolute_error: 1.8842 - val_acc: 0.1753\n",
      "\n",
      "Epoch 00017: val_loss improved from 6.20211 to 6.01995, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 18/500\n",
      "1548/1548 [==============================] - 0s 66us/step - loss: 7.1911 - mean_absolute_error: 1.6483 - acc: 0.2306 - val_loss: 5.8677 - val_mean_absolute_error: 1.8644 - val_acc: 0.1649\n",
      "\n",
      "Epoch 00018: val_loss improved from 6.01995 to 5.86774, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 19/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 6.9945 - mean_absolute_error: 1.6067 - acc: 0.2319 - val_loss: 5.7769 - val_mean_absolute_error: 1.8576 - val_acc: 0.1521\n",
      "\n",
      "Epoch 00019: val_loss improved from 5.86774 to 5.77692, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 20/500\n",
      "1548/1548 [==============================] - 0s 66us/step - loss: 6.8329 - mean_absolute_error: 1.5723 - acc: 0.2422 - val_loss: 5.7477 - val_mean_absolute_error: 1.8653 - val_acc: 0.1443\n",
      "\n",
      "Epoch 00020: val_loss improved from 5.77692 to 5.74771, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 21/500\n",
      "1548/1548 [==============================] - 0s 67us/step - loss: 6.7064 - mean_absolute_error: 1.5452 - acc: 0.2429 - val_loss: 5.7590 - val_mean_absolute_error: 1.8817 - val_acc: 0.1443\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 5.74771\n",
      "Epoch 22/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 6.6120 - mean_absolute_error: 1.5273 - acc: 0.2487 - val_loss: 5.7765 - val_mean_absolute_error: 1.8966 - val_acc: 0.1469\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 5.74771\n",
      "Epoch 23/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 6.5447 - mean_absolute_error: 1.5189 - acc: 0.2578 - val_loss: 5.7489 - val_mean_absolute_error: 1.8980 - val_acc: 0.1443\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 5.74771\n",
      "Epoch 24/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 6.4963 - mean_absolute_error: 1.5171 - acc: 0.2513 - val_loss: 5.6214 - val_mean_absolute_error: 1.8737 - val_acc: 0.1366\n",
      "\n",
      "Epoch 00024: val_loss improved from 5.74771 to 5.62144, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 25/500\n",
      "1548/1548 [==============================] - 0s 88us/step - loss: 6.4544 - mean_absolute_error: 1.5197 - acc: 0.2500 - val_loss: 5.3571 - val_mean_absolute_error: 1.8125 - val_acc: 0.1572\n",
      "\n",
      "Epoch 00025: val_loss improved from 5.62144 to 5.35711, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 26/500\n",
      "1548/1548 [==============================] - 0s 103us/step - loss: 6.4060 - mean_absolute_error: 1.5203 - acc: 0.2435 - val_loss: 4.9747 - val_mean_absolute_error: 1.7164 - val_acc: 0.1675\n",
      "\n",
      "Epoch 00026: val_loss improved from 5.35711 to 4.97472, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 27/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 6.3385 - mean_absolute_error: 1.5142 - acc: 0.2339 - val_loss: 4.5421 - val_mean_absolute_error: 1.5974 - val_acc: 0.1727\n",
      "\n",
      "Epoch 00027: val_loss improved from 4.97472 to 4.54214, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 28/500\n",
      "1548/1548 [==============================] - 0s 87us/step - loss: 6.2470 - mean_absolute_error: 1.4992 - acc: 0.2351 - val_loss: 4.1513 - val_mean_absolute_error: 1.4854 - val_acc: 0.2088\n",
      "\n",
      "Epoch 00028: val_loss improved from 4.54214 to 4.15134, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 29/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 6.1367 - mean_absolute_error: 1.4767 - acc: 0.2532 - val_loss: 3.8586 - val_mean_absolute_error: 1.3955 - val_acc: 0.2371\n",
      "\n",
      "Epoch 00029: val_loss improved from 4.15134 to 3.85858, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 30/500\n",
      "1548/1548 [==============================] - 0s 65us/step - loss: 6.0194 - mean_absolute_error: 1.4489 - acc: 0.2610 - val_loss: 3.6709 - val_mean_absolute_error: 1.3344 - val_acc: 0.2680\n",
      "\n",
      "Epoch 00030: val_loss improved from 3.85858 to 3.67087, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 31/500\n",
      "1548/1548 [==============================] - 0s 79us/step - loss: 5.9112 - mean_absolute_error: 1.4207 - acc: 0.2578 - val_loss: 3.5587 - val_mean_absolute_error: 1.2962 - val_acc: 0.2809\n",
      "\n",
      "Epoch 00031: val_loss improved from 3.67087 to 3.55873, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 32/500\n",
      "1548/1548 [==============================] - 0s 87us/step - loss: 5.8213 - mean_absolute_error: 1.3957 - acc: 0.2642 - val_loss: 3.4935 - val_mean_absolute_error: 1.2745 - val_acc: 0.3015\n",
      "\n",
      "Epoch 00032: val_loss improved from 3.55873 to 3.49350, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 33/500\n",
      "1548/1548 [==============================] - 0s 84us/step - loss: 5.7523 - mean_absolute_error: 1.3767 - acc: 0.2733 - val_loss: 3.4532 - val_mean_absolute_error: 1.2617 - val_acc: 0.3093\n",
      "\n",
      "Epoch 00033: val_loss improved from 3.49350 to 3.45321, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 34/500\n",
      "1548/1548 [==============================] - 0s 64us/step - loss: 5.7040 - mean_absolute_error: 1.3638 - acc: 0.2771 - val_loss: 3.4228 - val_mean_absolute_error: 1.2521 - val_acc: 0.3144\n",
      "\n",
      "Epoch 00034: val_loss improved from 3.45321 to 3.42280, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 35/500\n",
      "1548/1548 [==============================] - 0s 67us/step - loss: 5.6740 - mean_absolute_error: 1.3572 - acc: 0.2778 - val_loss: 3.3925 - val_mean_absolute_error: 1.2422 - val_acc: 0.3247\n",
      "\n",
      "Epoch 00035: val_loss improved from 3.42280 to 3.39252, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 36/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 5.6595 - mean_absolute_error: 1.3563 - acc: 0.2758 - val_loss: 3.3537 - val_mean_absolute_error: 1.2281 - val_acc: 0.3299\n",
      "\n",
      "Epoch 00036: val_loss improved from 3.39252 to 3.35369, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 37/500\n",
      "1548/1548 [==============================] - 0s 61us/step - loss: 5.6569 - mean_absolute_error: 1.3603 - acc: 0.2758 - val_loss: 3.3028 - val_mean_absolute_error: 1.2080 - val_acc: 0.3299\n",
      "\n",
      "Epoch 00037: val_loss improved from 3.35369 to 3.30279, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 38/500\n",
      "1548/1548 [==============================] - 0s 79us/step - loss: 5.6607 - mean_absolute_error: 1.3681 - acc: 0.2655 - val_loss: 3.2414 - val_mean_absolute_error: 1.1820 - val_acc: 0.3325\n",
      "\n",
      "Epoch 00038: val_loss improved from 3.30279 to 3.24136, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 39/500\n",
      "1548/1548 [==============================] - 0s 86us/step - loss: 5.6651 - mean_absolute_error: 1.3781 - acc: 0.2539 - val_loss: 3.1800 - val_mean_absolute_error: 1.1546 - val_acc: 0.3557\n",
      "\n",
      "Epoch 00039: val_loss improved from 3.24136 to 3.17995, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 40/500\n",
      "1548/1548 [==============================] - 0s 66us/step - loss: 5.6627 - mean_absolute_error: 1.3865 - acc: 0.2571 - val_loss: 3.1293 - val_mean_absolute_error: 1.1302 - val_acc: 0.3660\n",
      "\n",
      "Epoch 00040: val_loss improved from 3.17995 to 3.12930, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 41/500\n",
      "1548/1548 [==============================] - 0s 74us/step - loss: 5.6473 - mean_absolute_error: 1.3904 - acc: 0.2455 - val_loss: 3.0978 - val_mean_absolute_error: 1.1142 - val_acc: 0.3737\n",
      "\n",
      "Epoch 00041: val_loss improved from 3.12930 to 3.09777, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 42/500\n",
      "1548/1548 [==============================] - 0s 67us/step - loss: 5.6171 - mean_absolute_error: 1.3892 - acc: 0.2442 - val_loss: 3.0831 - val_mean_absolute_error: 1.1081 - val_acc: 0.3763\n",
      "\n",
      "Epoch 00042: val_loss improved from 3.09777 to 3.08314, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 43/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 5.5724 - mean_absolute_error: 1.3834 - acc: 0.2487 - val_loss: 3.0762 - val_mean_absolute_error: 1.1056 - val_acc: 0.3737\n",
      "\n",
      "Epoch 00043: val_loss improved from 3.08314 to 3.07618, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 44/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 5.5192 - mean_absolute_error: 1.3724 - acc: 0.2545 - val_loss: 3.0680 - val_mean_absolute_error: 1.1030 - val_acc: 0.3840\n",
      "\n",
      "Epoch 00044: val_loss improved from 3.07618 to 3.06803, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 45/500\n",
      "1548/1548 [==============================] - 0s 80us/step - loss: 5.4639 - mean_absolute_error: 1.3586 - acc: 0.2655 - val_loss: 3.0556 - val_mean_absolute_error: 1.0992 - val_acc: 0.3814\n",
      "\n",
      "Epoch 00045: val_loss improved from 3.06803 to 3.05555, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 46/500\n",
      "1548/1548 [==============================] - 0s 63us/step - loss: 5.4123 - mean_absolute_error: 1.3437 - acc: 0.2681 - val_loss: 3.0407 - val_mean_absolute_error: 1.0951 - val_acc: 0.3814\n",
      "\n",
      "Epoch 00046: val_loss improved from 3.05555 to 3.04068, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 47/500\n",
      "1548/1548 [==============================] - 0s 63us/step - loss: 5.3672 - mean_absolute_error: 1.3299 - acc: 0.2726 - val_loss: 3.0273 - val_mean_absolute_error: 1.0918 - val_acc: 0.3814\n",
      "\n",
      "Epoch 00047: val_loss improved from 3.04068 to 3.02727, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 48/500\n",
      "1548/1548 [==============================] - 0s 74us/step - loss: 5.3310 - mean_absolute_error: 1.3190 - acc: 0.2745 - val_loss: 3.0182 - val_mean_absolute_error: 1.0907 - val_acc: 0.3840\n",
      "\n",
      "Epoch 00048: val_loss improved from 3.02727 to 3.01822, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 49/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 5.3033 - mean_absolute_error: 1.3111 - acc: 0.2758 - val_loss: 3.0148 - val_mean_absolute_error: 1.0920 - val_acc: 0.3814\n",
      "\n",
      "Epoch 00049: val_loss improved from 3.01822 to 3.01480, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 50/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 5.2839 - mean_absolute_error: 1.3059 - acc: 0.2733 - val_loss: 3.0164 - val_mean_absolute_error: 1.0959 - val_acc: 0.3866\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.01480\n",
      "Epoch 51/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 5.2719 - mean_absolute_error: 1.3031 - acc: 0.2713 - val_loss: 3.0209 - val_mean_absolute_error: 1.1006 - val_acc: 0.3789\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.01480\n",
      "Epoch 52/500\n",
      "1548/1548 [==============================] - 0s 62us/step - loss: 5.2664 - mean_absolute_error: 1.3032 - acc: 0.2713 - val_loss: 3.0246 - val_mean_absolute_error: 1.1040 - val_acc: 0.3866\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.01480\n",
      "Epoch 53/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 5.2659 - mean_absolute_error: 1.3050 - acc: 0.2694 - val_loss: 3.0239 - val_mean_absolute_error: 1.1054 - val_acc: 0.3840\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.01480\n",
      "Epoch 54/500\n",
      "1548/1548 [==============================] - 0s 96us/step - loss: 5.2692 - mean_absolute_error: 1.3076 - acc: 0.2726 - val_loss: 3.0161 - val_mean_absolute_error: 1.1036 - val_acc: 0.3892\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 3.01480\n",
      "Epoch 55/500\n",
      "1548/1548 [==============================] - 0s 95us/step - loss: 5.2718 - mean_absolute_error: 1.3106 - acc: 0.2720 - val_loss: 3.0006 - val_mean_absolute_error: 1.0983 - val_acc: 0.3866\n",
      "\n",
      "Epoch 00055: val_loss improved from 3.01480 to 3.00062, saving model to ANN_Interval_best_GCIPL.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "1548/1548 [==============================] - 0s 67us/step - loss: 5.2731 - mean_absolute_error: 1.3135 - acc: 0.2726 - val_loss: 2.9803 - val_mean_absolute_error: 1.0909 - val_acc: 0.3892\n",
      "\n",
      "Epoch 00056: val_loss improved from 3.00062 to 2.98027, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 57/500\n",
      "1548/1548 [==============================] - 0s 91us/step - loss: 5.2705 - mean_absolute_error: 1.3154 - acc: 0.2739 - val_loss: 2.9591 - val_mean_absolute_error: 1.0829 - val_acc: 0.3995\n",
      "\n",
      "Epoch 00057: val_loss improved from 2.98027 to 2.95910, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 58/500\n",
      "1548/1548 [==============================] - 0s 113us/step - loss: 5.2621 - mean_absolute_error: 1.3153 - acc: 0.2758 - val_loss: 2.9410 - val_mean_absolute_error: 1.0755 - val_acc: 0.4021\n",
      "\n",
      "Epoch 00058: val_loss improved from 2.95910 to 2.94098, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 59/500\n",
      "1548/1548 [==============================] - 0s 88us/step - loss: 5.2471 - mean_absolute_error: 1.3125 - acc: 0.2739 - val_loss: 2.9280 - val_mean_absolute_error: 1.0692 - val_acc: 0.4046\n",
      "\n",
      "Epoch 00059: val_loss improved from 2.94098 to 2.92795, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 60/500\n",
      "1548/1548 [==============================] - 0s 84us/step - loss: 5.2491 - mean_absolute_error: 1.3156 - acc: 0.2707 - val_loss: 2.9206 - val_mean_absolute_error: 1.0646 - val_acc: 0.3969\n",
      "\n",
      "Epoch 00060: val_loss improved from 2.92795 to 2.92063, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 61/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 5.1999 - mean_absolute_error: 1.3039 - acc: 0.2797 - val_loss: 2.9150 - val_mean_absolute_error: 1.0630 - val_acc: 0.3995\n",
      "\n",
      "Epoch 00061: val_loss improved from 2.92063 to 2.91498, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 62/500\n",
      "1548/1548 [==============================] - 0s 107us/step - loss: 5.1707 - mean_absolute_error: 1.2979 - acc: 0.2842 - val_loss: 2.9121 - val_mean_absolute_error: 1.0617 - val_acc: 0.3969\n",
      "\n",
      "Epoch 00062: val_loss improved from 2.91498 to 2.91210, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 63/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 5.1409 - mean_absolute_error: 1.2919 - acc: 0.2959 - val_loss: 2.9087 - val_mean_absolute_error: 1.0604 - val_acc: 0.3995\n",
      "\n",
      "Epoch 00063: val_loss improved from 2.91210 to 2.90871, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 64/500\n",
      "1548/1548 [==============================] - 0s 84us/step - loss: 5.1114 - mean_absolute_error: 1.2859 - acc: 0.3004 - val_loss: 2.9040 - val_mean_absolute_error: 1.0589 - val_acc: 0.4021\n",
      "\n",
      "Epoch 00064: val_loss improved from 2.90871 to 2.90403, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 65/500\n",
      "1548/1548 [==============================] - 0s 93us/step - loss: 5.0837 - mean_absolute_error: 1.2799 - acc: 0.3036 - val_loss: 2.8982 - val_mean_absolute_error: 1.0572 - val_acc: 0.4021\n",
      "\n",
      "Epoch 00065: val_loss improved from 2.90403 to 2.89821, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 66/500\n",
      "1548/1548 [==============================] - 0s 115us/step - loss: 5.0596 - mean_absolute_error: 1.2749 - acc: 0.3068 - val_loss: 2.8924 - val_mean_absolute_error: 1.0555 - val_acc: 0.4072\n",
      "\n",
      "Epoch 00066: val_loss improved from 2.89821 to 2.89237, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 67/500\n",
      "1548/1548 [==============================] - 0s 69us/step - loss: 5.0389 - mean_absolute_error: 1.2707 - acc: 0.3075 - val_loss: 2.8880 - val_mean_absolute_error: 1.0548 - val_acc: 0.4098\n",
      "\n",
      "Epoch 00067: val_loss improved from 2.89237 to 2.88801, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 68/500\n",
      "1548/1548 [==============================] - 0s 69us/step - loss: 5.0223 - mean_absolute_error: 1.2677 - acc: 0.3068 - val_loss: 2.8868 - val_mean_absolute_error: 1.0564 - val_acc: 0.4046\n",
      "\n",
      "Epoch 00068: val_loss improved from 2.88801 to 2.88679, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 69/500\n",
      "1548/1548 [==============================] - 0s 94us/step - loss: 5.0093 - mean_absolute_error: 1.2660 - acc: 0.3030 - val_loss: 2.8902 - val_mean_absolute_error: 1.0611 - val_acc: 0.4072\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 2.88679\n",
      "Epoch 70/500\n",
      "1548/1548 [==============================] - 0s 102us/step - loss: 4.9997 - mean_absolute_error: 1.2653 - acc: 0.3049 - val_loss: 2.8994 - val_mean_absolute_error: 1.0686 - val_acc: 0.4072\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 2.88679\n",
      "Epoch 71/500\n",
      "1548/1548 [==============================] - 0s 80us/step - loss: 4.9930 - mean_absolute_error: 1.2658 - acc: 0.3017 - val_loss: 2.9153 - val_mean_absolute_error: 1.0789 - val_acc: 0.3969\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 2.88679\n",
      "Epoch 72/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 4.9883 - mean_absolute_error: 1.2678 - acc: 0.3030 - val_loss: 2.9369 - val_mean_absolute_error: 1.0913 - val_acc: 0.3892\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 2.88679\n",
      "Epoch 73/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 4.9852 - mean_absolute_error: 1.2705 - acc: 0.3036 - val_loss: 2.9655 - val_mean_absolute_error: 1.1066 - val_acc: 0.3686\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 2.88679\n",
      "Epoch 74/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 4.9832 - mean_absolute_error: 1.2737 - acc: 0.3036 - val_loss: 2.9987 - val_mean_absolute_error: 1.1225 - val_acc: 0.3505\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 2.88679\n",
      "Epoch 75/500\n",
      "1548/1548 [==============================] - 0s 66us/step - loss: 4.9817 - mean_absolute_error: 1.2770 - acc: 0.3043 - val_loss: 3.0363 - val_mean_absolute_error: 1.1398 - val_acc: 0.3196\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 2.88679\n",
      "Epoch 76/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 4.9800 - mean_absolute_error: 1.2806 - acc: 0.3010 - val_loss: 3.0759 - val_mean_absolute_error: 1.1579 - val_acc: 0.3222\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 2.88679\n",
      "Epoch 77/500\n",
      "1548/1548 [==============================] - 0s 61us/step - loss: 4.9781 - mean_absolute_error: 1.2840 - acc: 0.3023 - val_loss: 3.1164 - val_mean_absolute_error: 1.1766 - val_acc: 0.2990\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 2.88679\n",
      "Epoch 78/500\n",
      "1548/1548 [==============================] - 0s 93us/step - loss: 4.9744 - mean_absolute_error: 1.2867 - acc: 0.2991 - val_loss: 3.1552 - val_mean_absolute_error: 1.1941 - val_acc: 0.2835\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 2.88679\n",
      "Epoch 79/500\n",
      "1548/1548 [==============================] - 0s 106us/step - loss: 4.9714 - mean_absolute_error: 1.2895 - acc: 0.2959 - val_loss: 3.1946 - val_mean_absolute_error: 1.2115 - val_acc: 0.2784\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 2.88679\n",
      "Epoch 80/500\n",
      "1548/1548 [==============================] - 0s 97us/step - loss: 4.9671 - mean_absolute_error: 1.2920 - acc: 0.2959 - val_loss: 3.2307 - val_mean_absolute_error: 1.2272 - val_acc: 0.2680\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 2.88679\n",
      "Epoch 81/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 4.9614 - mean_absolute_error: 1.2941 - acc: 0.2972 - val_loss: 3.2635 - val_mean_absolute_error: 1.2411 - val_acc: 0.2680\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 2.88679\n",
      "Epoch 82/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 4.9548 - mean_absolute_error: 1.2958 - acc: 0.2965 - val_loss: 3.2941 - val_mean_absolute_error: 1.2541 - val_acc: 0.2603\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 2.88679\n",
      "Epoch 83/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 4.9475 - mean_absolute_error: 1.2972 - acc: 0.2952 - val_loss: 3.3219 - val_mean_absolute_error: 1.2660 - val_acc: 0.2655\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 2.88679\n",
      "Epoch 84/500\n",
      "1548/1548 [==============================] - 0s 66us/step - loss: 4.9395 - mean_absolute_error: 1.2984 - acc: 0.2939 - val_loss: 3.3467 - val_mean_absolute_error: 1.2763 - val_acc: 0.2655\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 2.88679\n",
      "Epoch 85/500\n",
      "1548/1548 [==============================] - 0s 91us/step - loss: 4.9308 - mean_absolute_error: 1.2994 - acc: 0.2913 - val_loss: 3.3689 - val_mean_absolute_error: 1.2854 - val_acc: 0.2680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00085: val_loss did not improve from 2.88679\n",
      "Epoch 86/500\n",
      "1548/1548 [==============================] - 0s 83us/step - loss: 4.9217 - mean_absolute_error: 1.3002 - acc: 0.2862 - val_loss: 3.3896 - val_mean_absolute_error: 1.2938 - val_acc: 0.2655\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 2.88679\n",
      "Epoch 87/500\n",
      "1548/1548 [==============================] - 0s 98us/step - loss: 4.9120 - mean_absolute_error: 1.3007 - acc: 0.2849 - val_loss: 3.4069 - val_mean_absolute_error: 1.3006 - val_acc: 0.2629\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 2.88679\n",
      "Epoch 88/500\n",
      "1548/1548 [==============================] - 0s 74us/step - loss: 4.9020 - mean_absolute_error: 1.3010 - acc: 0.2855 - val_loss: 3.4234 - val_mean_absolute_error: 1.3069 - val_acc: 0.2526\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 2.88679\n",
      "Epoch 89/500\n",
      "1548/1548 [==============================] - 0s 78us/step - loss: 4.8916 - mean_absolute_error: 1.3011 - acc: 0.2888 - val_loss: 3.4381 - val_mean_absolute_error: 1.3126 - val_acc: 0.2474\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 2.88679\n",
      "Epoch 90/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 4.8813 - mean_absolute_error: 1.3011 - acc: 0.2868 - val_loss: 3.4521 - val_mean_absolute_error: 1.3180 - val_acc: 0.2474\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 2.88679\n",
      "Epoch 91/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 4.8707 - mean_absolute_error: 1.3010 - acc: 0.2881 - val_loss: 3.4632 - val_mean_absolute_error: 1.3223 - val_acc: 0.2423\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 2.88679\n",
      "Epoch 92/500\n",
      "1548/1548 [==============================] - 0s 56us/step - loss: 4.8598 - mean_absolute_error: 1.3007 - acc: 0.2894 - val_loss: 3.4740 - val_mean_absolute_error: 1.3264 - val_acc: 0.2397\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 2.88679\n",
      "Epoch 93/500\n",
      "1548/1548 [==============================] - 0s 60us/step - loss: 4.8487 - mean_absolute_error: 1.3002 - acc: 0.2888 - val_loss: 3.4834 - val_mean_absolute_error: 1.3300 - val_acc: 0.2397\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 2.88679\n",
      "Epoch 94/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 4.8375 - mean_absolute_error: 1.2996 - acc: 0.2875 - val_loss: 3.4919 - val_mean_absolute_error: 1.3332 - val_acc: 0.2371\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 2.88679\n",
      "Epoch 95/500\n",
      "1548/1548 [==============================] - 0s 65us/step - loss: 4.8263 - mean_absolute_error: 1.2990 - acc: 0.2868 - val_loss: 3.5000 - val_mean_absolute_error: 1.3363 - val_acc: 0.2345\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 2.88679\n",
      "Epoch 96/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 4.8151 - mean_absolute_error: 1.2983 - acc: 0.2849 - val_loss: 3.5070 - val_mean_absolute_error: 1.3388 - val_acc: 0.2345\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 2.88679\n",
      "Epoch 97/500\n",
      "1548/1548 [==============================] - 0s 66us/step - loss: 4.8038 - mean_absolute_error: 1.2977 - acc: 0.2849 - val_loss: 3.5134 - val_mean_absolute_error: 1.3411 - val_acc: 0.2371\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 2.88679\n",
      "Epoch 98/500\n",
      "1548/1548 [==============================] - 0s 78us/step - loss: 4.7925 - mean_absolute_error: 1.2970 - acc: 0.2875 - val_loss: 3.5187 - val_mean_absolute_error: 1.3431 - val_acc: 0.2371\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 2.88679\n",
      "Epoch 99/500\n",
      "1548/1548 [==============================] - 0s 69us/step - loss: 4.7811 - mean_absolute_error: 1.2962 - acc: 0.2875 - val_loss: 3.5234 - val_mean_absolute_error: 1.3447 - val_acc: 0.2397\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 2.88679\n",
      "Epoch 100/500\n",
      "1548/1548 [==============================] - 0s 64us/step - loss: 4.7697 - mean_absolute_error: 1.2954 - acc: 0.2913 - val_loss: 3.5275 - val_mean_absolute_error: 1.3462 - val_acc: 0.2397\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 2.88679\n",
      "Epoch 101/500\n",
      "1548/1548 [==============================] - 0s 68us/step - loss: 4.7583 - mean_absolute_error: 1.2946 - acc: 0.2868 - val_loss: 3.5309 - val_mean_absolute_error: 1.3474 - val_acc: 0.2397\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 2.88679\n",
      "Epoch 102/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 4.7470 - mean_absolute_error: 1.2936 - acc: 0.2849 - val_loss: 3.5337 - val_mean_absolute_error: 1.3484 - val_acc: 0.2397\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 2.88679\n",
      "Epoch 103/500\n",
      "1548/1548 [==============================] - 0s 111us/step - loss: 4.7356 - mean_absolute_error: 1.2925 - acc: 0.2829 - val_loss: 3.5360 - val_mean_absolute_error: 1.3492 - val_acc: 0.2397\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 2.88679\n",
      "Epoch 104/500\n",
      "1548/1548 [==============================] - 0s 112us/step - loss: 4.7242 - mean_absolute_error: 1.2914 - acc: 0.2842 - val_loss: 3.5376 - val_mean_absolute_error: 1.3497 - val_acc: 0.2397\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 2.88679\n",
      "Epoch 105/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 4.7129 - mean_absolute_error: 1.2902 - acc: 0.2836 - val_loss: 3.5389 - val_mean_absolute_error: 1.3501 - val_acc: 0.2371\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 2.88679\n",
      "Epoch 106/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 4.7016 - mean_absolute_error: 1.2890 - acc: 0.2829 - val_loss: 3.5398 - val_mean_absolute_error: 1.3504 - val_acc: 0.2371\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 2.88679\n",
      "Epoch 107/500\n",
      "1548/1548 [==============================] - 0s 91us/step - loss: 4.6904 - mean_absolute_error: 1.2877 - acc: 0.2829 - val_loss: 3.5403 - val_mean_absolute_error: 1.3505 - val_acc: 0.2371\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 2.88679\n",
      "Epoch 108/500\n",
      "1548/1548 [==============================] - 0s 103us/step - loss: 4.6792 - mean_absolute_error: 1.2863 - acc: 0.2829 - val_loss: 3.5405 - val_mean_absolute_error: 1.3505 - val_acc: 0.2371\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 2.88679\n",
      "Epoch 109/500\n",
      "1548/1548 [==============================] - 0s 111us/step - loss: 4.6683 - mean_absolute_error: 1.2850 - acc: 0.2829 - val_loss: 3.5404 - val_mean_absolute_error: 1.3504 - val_acc: 0.2371\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 2.88679\n",
      "Epoch 110/500\n",
      "1548/1548 [==============================] - 0s 83us/step - loss: 4.6577 - mean_absolute_error: 1.2837 - acc: 0.2804 - val_loss: 3.5400 - val_mean_absolute_error: 1.3502 - val_acc: 0.2397\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 2.88679\n",
      "Epoch 111/500\n",
      "1548/1548 [==============================] - 0s 105us/step - loss: 4.6465 - mean_absolute_error: 1.2822 - acc: 0.2784 - val_loss: 3.5403 - val_mean_absolute_error: 1.3502 - val_acc: 0.2397\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 2.88679\n",
      "Epoch 112/500\n",
      "1548/1548 [==============================] - 0s 93us/step - loss: 4.6357 - mean_absolute_error: 1.2808 - acc: 0.2771 - val_loss: 3.5401 - val_mean_absolute_error: 1.3501 - val_acc: 0.2397\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 2.88679\n",
      "Epoch 113/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 4.6252 - mean_absolute_error: 1.2794 - acc: 0.2784 - val_loss: 3.5401 - val_mean_absolute_error: 1.3500 - val_acc: 0.2371\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 2.88679\n",
      "Epoch 114/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 4.6149 - mean_absolute_error: 1.2782 - acc: 0.2817 - val_loss: 3.5404 - val_mean_absolute_error: 1.3500 - val_acc: 0.2371\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 2.88679\n",
      "Epoch 115/500\n",
      "1548/1548 [==============================] - 0s 67us/step - loss: 4.6049 - mean_absolute_error: 1.2769 - acc: 0.2817 - val_loss: 3.5410 - val_mean_absolute_error: 1.3501 - val_acc: 0.2371\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 2.88679\n",
      "Epoch 116/500\n",
      "1548/1548 [==============================] - 0s 69us/step - loss: 4.5952 - mean_absolute_error: 1.2758 - acc: 0.2829 - val_loss: 3.5421 - val_mean_absolute_error: 1.3504 - val_acc: 0.2320\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 2.88679\n",
      "Epoch 117/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 4.5860 - mean_absolute_error: 1.2747 - acc: 0.2842 - val_loss: 3.5436 - val_mean_absolute_error: 1.3510 - val_acc: 0.2371\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 2.88679\n",
      "Epoch 118/500\n",
      "1548/1548 [==============================] - 0s 101us/step - loss: 4.5767 - mean_absolute_error: 1.2736 - acc: 0.2862 - val_loss: 3.5458 - val_mean_absolute_error: 1.3517 - val_acc: 0.2345\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 2.88679\n",
      "Epoch 00118: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1a2a5dba20>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN_baseline(X, y_GCA, 'GCIPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1548 samples, validate on 388 samples\n",
      "Epoch 1/500\n",
      "1548/1548 [==============================] - 1s 963us/step - loss: 6117.5409 - mean_absolute_error: 72.3121 - acc: 0.0013 - val_loss: 506.6579 - val_mean_absolute_error: 18.1654 - val_acc: 0.0077\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 506.65790, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 2/500\n",
      "1548/1548 [==============================] - 0s 132us/step - loss: 238.9953 - mean_absolute_error: 11.6003 - acc: 0.0226 - val_loss: 184.7940 - val_mean_absolute_error: 8.7527 - val_acc: 0.0644\n",
      "\n",
      "Epoch 00002: val_loss improved from 506.65790 to 184.79403, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 3/500\n",
      "1548/1548 [==============================] - 0s 92us/step - loss: 154.9363 - mean_absolute_error: 8.2825 - acc: 0.0439 - val_loss: 170.0585 - val_mean_absolute_error: 8.6469 - val_acc: 0.0309\n",
      "\n",
      "Epoch 00003: val_loss improved from 184.79403 to 170.05851, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 4/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 145.5238 - mean_absolute_error: 7.9758 - acc: 0.0452 - val_loss: 160.2658 - val_mean_absolute_error: 8.4172 - val_acc: 0.0387\n",
      "\n",
      "Epoch 00004: val_loss improved from 170.05851 to 160.26578, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 5/500\n",
      "1548/1548 [==============================] - 0s 93us/step - loss: 137.1428 - mean_absolute_error: 7.7403 - acc: 0.0413 - val_loss: 151.2987 - val_mean_absolute_error: 8.2053 - val_acc: 0.0361\n",
      "\n",
      "Epoch 00005: val_loss improved from 160.26578 to 151.29870, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 6/500\n",
      "1548/1548 [==============================] - 0s 110us/step - loss: 127.3852 - mean_absolute_error: 7.4712 - acc: 0.0510 - val_loss: 135.3223 - val_mean_absolute_error: 7.6466 - val_acc: 0.0387\n",
      "\n",
      "Epoch 00006: val_loss improved from 151.29870 to 135.32232, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 7/500\n",
      "1548/1548 [==============================] - 0s 74us/step - loss: 110.5514 - mean_absolute_error: 6.9484 - acc: 0.0556 - val_loss: 115.8531 - val_mean_absolute_error: 6.8020 - val_acc: 0.0696\n",
      "\n",
      "Epoch 00007: val_loss improved from 135.32232 to 115.85311, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 8/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 91.9323 - mean_absolute_error: 6.3010 - acc: 0.0549 - val_loss: 99.1717 - val_mean_absolute_error: 6.2438 - val_acc: 0.0567\n",
      "\n",
      "Epoch 00008: val_loss improved from 115.85311 to 99.17166, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 9/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 76.1079 - mean_absolute_error: 5.7451 - acc: 0.0620 - val_loss: 85.1959 - val_mean_absolute_error: 5.7132 - val_acc: 0.0696\n",
      "\n",
      "Epoch 00009: val_loss improved from 99.17166 to 85.19590, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 10/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 63.2272 - mean_absolute_error: 5.2455 - acc: 0.0704 - val_loss: 72.9772 - val_mean_absolute_error: 5.1714 - val_acc: 0.0799\n",
      "\n",
      "Epoch 00010: val_loss improved from 85.19590 to 72.97716, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 11/500\n",
      "1548/1548 [==============================] - 0s 84us/step - loss: 51.5441 - mean_absolute_error: 4.6771 - acc: 0.0807 - val_loss: 61.2460 - val_mean_absolute_error: 4.6464 - val_acc: 0.0979\n",
      "\n",
      "Epoch 00011: val_loss improved from 72.97716 to 61.24598, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 12/500\n",
      "1548/1548 [==============================] - 0s 117us/step - loss: 42.8431 - mean_absolute_error: 4.2379 - acc: 0.0898 - val_loss: 53.0012 - val_mean_absolute_error: 4.2910 - val_acc: 0.0928\n",
      "\n",
      "Epoch 00012: val_loss improved from 61.24598 to 53.00125, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 13/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 35.1892 - mean_absolute_error: 3.7632 - acc: 0.0956 - val_loss: 45.2177 - val_mean_absolute_error: 3.8573 - val_acc: 0.0876\n",
      "\n",
      "Epoch 00013: val_loss improved from 53.00125 to 45.21774, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 14/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 28.8799 - mean_absolute_error: 3.1837 - acc: 0.1195 - val_loss: 39.6672 - val_mean_absolute_error: 3.3123 - val_acc: 0.1237\n",
      "\n",
      "Epoch 00014: val_loss improved from 45.21774 to 39.66721, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 15/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 26.5026 - mean_absolute_error: 2.9759 - acc: 0.1292 - val_loss: 37.8797 - val_mean_absolute_error: 3.2233 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00015: val_loss improved from 39.66721 to 37.87974, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 16/500\n",
      "1548/1548 [==============================] - 0s 84us/step - loss: 25.3193 - mean_absolute_error: 2.8826 - acc: 0.1298 - val_loss: 36.4820 - val_mean_absolute_error: 3.1159 - val_acc: 0.1134\n",
      "\n",
      "Epoch 00016: val_loss improved from 37.87974 to 36.48196, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 17/500\n",
      "1548/1548 [==============================] - 0s 108us/step - loss: 24.6653 - mean_absolute_error: 2.8138 - acc: 0.1357 - val_loss: 36.7858 - val_mean_absolute_error: 3.2207 - val_acc: 0.1005\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 36.48196\n",
      "Epoch 18/500\n",
      "1548/1548 [==============================] - 0s 122us/step - loss: 24.5982 - mean_absolute_error: 2.8326 - acc: 0.1337 - val_loss: 35.9968 - val_mean_absolute_error: 3.1681 - val_acc: 0.0979\n",
      "\n",
      "Epoch 00018: val_loss improved from 36.48196 to 35.99683, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 19/500\n",
      "1548/1548 [==============================] - 0s 122us/step - loss: 24.4713 - mean_absolute_error: 2.8232 - acc: 0.1447 - val_loss: 35.7026 - val_mean_absolute_error: 3.1420 - val_acc: 0.0954\n",
      "\n",
      "Epoch 00019: val_loss improved from 35.99683 to 35.70262, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 20/500\n",
      "1548/1548 [==============================] - 0s 126us/step - loss: 24.1406 - mean_absolute_error: 2.7875 - acc: 0.1512 - val_loss: 35.6871 - val_mean_absolute_error: 3.1809 - val_acc: 0.0979\n",
      "\n",
      "Epoch 00020: val_loss improved from 35.70262 to 35.68711, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 21/500\n",
      "1548/1548 [==============================] - 0s 93us/step - loss: 24.1232 - mean_absolute_error: 2.7947 - acc: 0.1518 - val_loss: 35.7876 - val_mean_absolute_error: 3.2732 - val_acc: 0.0825\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 35.68711\n",
      "Epoch 22/500\n",
      "1548/1548 [==============================] - 0s 117us/step - loss: 24.1845 - mean_absolute_error: 2.8112 - acc: 0.1512 - val_loss: 36.0810 - val_mean_absolute_error: 3.2844 - val_acc: 0.0799\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 35.68711\n",
      "Epoch 23/500\n",
      "1548/1548 [==============================] - 0s 83us/step - loss: 24.1809 - mean_absolute_error: 2.8191 - acc: 0.1447 - val_loss: 36.2416 - val_mean_absolute_error: 3.2848 - val_acc: 0.0825\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 35.68711\n",
      "Epoch 24/500\n",
      "1548/1548 [==============================] - 0s 100us/step - loss: 24.1639 - mean_absolute_error: 2.8305 - acc: 0.1434 - val_loss: 35.7722 - val_mean_absolute_error: 3.2204 - val_acc: 0.0954\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 35.68711\n",
      "Epoch 25/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 24.0378 - mean_absolute_error: 2.8138 - acc: 0.1512 - val_loss: 35.8171 - val_mean_absolute_error: 3.3036 - val_acc: 0.0670\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 35.68711\n",
      "Epoch 26/500\n",
      "1548/1548 [==============================] - 0s 92us/step - loss: 23.9715 - mean_absolute_error: 2.8201 - acc: 0.1473 - val_loss: 35.7956 - val_mean_absolute_error: 3.2829 - val_acc: 0.0722\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 35.68711\n",
      "Epoch 27/500\n",
      "1548/1548 [==============================] - 0s 88us/step - loss: 23.9060 - mean_absolute_error: 2.8174 - acc: 0.1428 - val_loss: 35.6600 - val_mean_absolute_error: 3.2578 - val_acc: 0.0747\n",
      "\n",
      "Epoch 00027: val_loss improved from 35.68711 to 35.65998, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 28/500\n",
      "1548/1548 [==============================] - 0s 86us/step - loss: 23.8615 - mean_absolute_error: 2.8200 - acc: 0.1428 - val_loss: 35.6311 - val_mean_absolute_error: 3.2343 - val_acc: 0.0851\n",
      "\n",
      "Epoch 00028: val_loss improved from 35.65998 to 35.63111, saving model to ANN_Interval_best_VFI.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 23.8200 - mean_absolute_error: 2.8223 - acc: 0.1415 - val_loss: 35.4737 - val_mean_absolute_error: 3.1940 - val_acc: 0.0876\n",
      "\n",
      "Epoch 00029: val_loss improved from 35.63111 to 35.47374, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 30/500\n",
      "1548/1548 [==============================] - 0s 75us/step - loss: 23.7767 - mean_absolute_error: 2.8264 - acc: 0.1305 - val_loss: 34.9026 - val_mean_absolute_error: 3.1322 - val_acc: 0.1057\n",
      "\n",
      "Epoch 00030: val_loss improved from 35.47374 to 34.90265, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 31/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 23.5566 - mean_absolute_error: 2.7979 - acc: 0.1298 - val_loss: 34.9146 - val_mean_absolute_error: 3.0930 - val_acc: 0.1186\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 34.90265\n",
      "Epoch 32/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 23.5212 - mean_absolute_error: 2.8012 - acc: 0.1286 - val_loss: 34.5858 - val_mean_absolute_error: 3.0244 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00032: val_loss improved from 34.90265 to 34.58579, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 33/500\n",
      "1548/1548 [==============================] - 0s 74us/step - loss: 23.3783 - mean_absolute_error: 2.7815 - acc: 0.1305 - val_loss: 33.9165 - val_mean_absolute_error: 2.6319 - val_acc: 0.2088\n",
      "\n",
      "Epoch 00033: val_loss improved from 34.58579 to 33.91650, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 34/500\n",
      "1548/1548 [==============================] - 0s 62us/step - loss: 22.9777 - mean_absolute_error: 2.6859 - acc: 0.1466 - val_loss: 34.3891 - val_mean_absolute_error: 2.8615 - val_acc: 0.1469\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 33.91650\n",
      "Epoch 35/500\n",
      "1548/1548 [==============================] - 0s 69us/step - loss: 23.2522 - mean_absolute_error: 2.7689 - acc: 0.1350 - val_loss: 33.9768 - val_mean_absolute_error: 2.7901 - val_acc: 0.1624\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 33.91650\n",
      "Epoch 36/500\n",
      "1548/1548 [==============================] - 0s 118us/step - loss: 23.1319 - mean_absolute_error: 2.7505 - acc: 0.1331 - val_loss: 33.5673 - val_mean_absolute_error: 2.7174 - val_acc: 0.2113\n",
      "\n",
      "Epoch 00036: val_loss improved from 33.91650 to 33.56726, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 37/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 22.9660 - mean_absolute_error: 2.7177 - acc: 0.1376 - val_loss: 33.6206 - val_mean_absolute_error: 2.6843 - val_acc: 0.2088\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 33.56726\n",
      "Epoch 38/500\n",
      "1548/1548 [==============================] - 0s 104us/step - loss: 22.9828 - mean_absolute_error: 2.7231 - acc: 0.1395 - val_loss: 33.4838 - val_mean_absolute_error: 2.6358 - val_acc: 0.2062\n",
      "\n",
      "Epoch 00038: val_loss improved from 33.56726 to 33.48384, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 39/500\n",
      "1548/1548 [==============================] - 0s 106us/step - loss: 22.9079 - mean_absolute_error: 2.7072 - acc: 0.1453 - val_loss: 33.6137 - val_mean_absolute_error: 2.6101 - val_acc: 0.2010\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 33.48384\n",
      "Epoch 40/500\n",
      "1548/1548 [==============================] - 0s 93us/step - loss: 22.8533 - mean_absolute_error: 2.7008 - acc: 0.1486 - val_loss: 33.5593 - val_mean_absolute_error: 2.5926 - val_acc: 0.2320\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 33.48384\n",
      "Epoch 41/500\n",
      "1548/1548 [==============================] - 0s 112us/step - loss: 22.7595 - mean_absolute_error: 2.6868 - acc: 0.1479 - val_loss: 33.6742 - val_mean_absolute_error: 2.5832 - val_acc: 0.2397\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 33.48384\n",
      "Epoch 42/500\n",
      "1548/1548 [==============================] - 0s 127us/step - loss: 22.7614 - mean_absolute_error: 2.6893 - acc: 0.1473 - val_loss: 33.6358 - val_mean_absolute_error: 2.5882 - val_acc: 0.2423\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 33.48384\n",
      "Epoch 43/500\n",
      "1548/1548 [==============================] - 0s 102us/step - loss: 22.7936 - mean_absolute_error: 2.6958 - acc: 0.1550 - val_loss: 33.7515 - val_mean_absolute_error: 2.5934 - val_acc: 0.2191\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 33.48384\n",
      "Epoch 44/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 22.7134 - mean_absolute_error: 2.6785 - acc: 0.1609 - val_loss: 33.8924 - val_mean_absolute_error: 2.5869 - val_acc: 0.2268\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 33.48384\n",
      "Epoch 45/500\n",
      "1548/1548 [==============================] - 0s 79us/step - loss: 22.6931 - mean_absolute_error: 2.6887 - acc: 0.1499 - val_loss: 33.9853 - val_mean_absolute_error: 2.6122 - val_acc: 0.2088\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 33.48384\n",
      "Epoch 46/500\n",
      "1548/1548 [==============================] - 0s 109us/step - loss: 22.7434 - mean_absolute_error: 2.6909 - acc: 0.1583 - val_loss: 34.3116 - val_mean_absolute_error: 2.6117 - val_acc: 0.2191\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 33.48384\n",
      "Epoch 47/500\n",
      "1548/1548 [==============================] - 0s 114us/step - loss: 22.7117 - mean_absolute_error: 2.6947 - acc: 0.1531 - val_loss: 34.3047 - val_mean_absolute_error: 2.6469 - val_acc: 0.2088\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 33.48384\n",
      "Epoch 48/500\n",
      "1548/1548 [==============================] - 0s 128us/step - loss: 22.8130 - mean_absolute_error: 2.7112 - acc: 0.1557 - val_loss: 34.3086 - val_mean_absolute_error: 2.6981 - val_acc: 0.1830\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 33.48384\n",
      "Epoch 49/500\n",
      "1548/1548 [==============================] - 0s 133us/step - loss: 22.7874 - mean_absolute_error: 2.7049 - acc: 0.1589 - val_loss: 34.4322 - val_mean_absolute_error: 2.7011 - val_acc: 0.1804\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 33.48384\n",
      "Epoch 50/500\n",
      "1548/1548 [==============================] - 0s 92us/step - loss: 22.7177 - mean_absolute_error: 2.6977 - acc: 0.1537 - val_loss: 34.6086 - val_mean_absolute_error: 2.6894 - val_acc: 0.1933\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 33.48384\n",
      "Epoch 51/500\n",
      "1548/1548 [==============================] - 0s 63us/step - loss: 22.6688 - mean_absolute_error: 2.7003 - acc: 0.1525 - val_loss: 34.7562 - val_mean_absolute_error: 2.7068 - val_acc: 0.1856\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 33.48384\n",
      "Epoch 52/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 22.8413 - mean_absolute_error: 2.7335 - acc: 0.1466 - val_loss: 34.6670 - val_mean_absolute_error: 2.8292 - val_acc: 0.1443\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 33.48384\n",
      "Epoch 53/500\n",
      "1548/1548 [==============================] - 0s 63us/step - loss: 22.9066 - mean_absolute_error: 2.7368 - acc: 0.1428 - val_loss: 34.7705 - val_mean_absolute_error: 2.8406 - val_acc: 0.1443\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 33.48384\n",
      "Epoch 54/500\n",
      "1548/1548 [==============================] - 0s 83us/step - loss: 22.8241 - mean_absolute_error: 2.7291 - acc: 0.1466 - val_loss: 34.6659 - val_mean_absolute_error: 2.8300 - val_acc: 0.1418\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 33.48384\n",
      "Epoch 55/500\n",
      "1548/1548 [==============================] - 0s 56us/step - loss: 22.7313 - mean_absolute_error: 2.7170 - acc: 0.1460 - val_loss: 34.8215 - val_mean_absolute_error: 2.8114 - val_acc: 0.1392\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 33.48384\n",
      "Epoch 56/500\n",
      "1548/1548 [==============================] - 0s 61us/step - loss: 22.7369 - mean_absolute_error: 2.7225 - acc: 0.1479 - val_loss: 35.0328 - val_mean_absolute_error: 2.7536 - val_acc: 0.1572\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 33.48384\n",
      "Epoch 57/500\n",
      "1548/1548 [==============================] - 0s 58us/step - loss: 22.7272 - mean_absolute_error: 2.7419 - acc: 0.1415 - val_loss: 34.7440 - val_mean_absolute_error: 2.8574 - val_acc: 0.1392\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 33.48384\n",
      "Epoch 58/500\n",
      "1548/1548 [==============================] - 0s 65us/step - loss: 22.7958 - mean_absolute_error: 2.7487 - acc: 0.1363 - val_loss: 34.9156 - val_mean_absolute_error: 2.9081 - val_acc: 0.1392\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 33.48384\n",
      "Epoch 59/500\n",
      "1548/1548 [==============================] - 0s 64us/step - loss: 22.8952 - mean_absolute_error: 2.7629 - acc: 0.1421 - val_loss: 34.9208 - val_mean_absolute_error: 2.8943 - val_acc: 0.1418\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 33.48384\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 0s 105us/step - loss: 22.9147 - mean_absolute_error: 2.7722 - acc: 0.1370 - val_loss: 35.0141 - val_mean_absolute_error: 2.9143 - val_acc: 0.1366\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 33.48384\n",
      "Epoch 61/500\n",
      "1548/1548 [==============================] - 0s 79us/step - loss: 22.9387 - mean_absolute_error: 2.7794 - acc: 0.1363 - val_loss: 34.9866 - val_mean_absolute_error: 2.9231 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 33.48384\n",
      "Epoch 62/500\n",
      "1548/1548 [==============================] - 0s 88us/step - loss: 22.9550 - mean_absolute_error: 2.7837 - acc: 0.1389 - val_loss: 35.0997 - val_mean_absolute_error: 2.9412 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 33.48384\n",
      "Epoch 63/500\n",
      "1548/1548 [==============================] - 0s 107us/step - loss: 22.9881 - mean_absolute_error: 2.7927 - acc: 0.1363 - val_loss: 35.0640 - val_mean_absolute_error: 2.9553 - val_acc: 0.1160\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 33.48384\n",
      "Epoch 64/500\n",
      "1548/1548 [==============================] - 0s 87us/step - loss: 22.8577 - mean_absolute_error: 2.7775 - acc: 0.1376 - val_loss: 34.8628 - val_mean_absolute_error: 2.9448 - val_acc: 0.1237\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 33.48384\n",
      "Epoch 65/500\n",
      "1548/1548 [==============================] - 0s 67us/step - loss: 22.7781 - mean_absolute_error: 2.7671 - acc: 0.1363 - val_loss: 34.9252 - val_mean_absolute_error: 2.9191 - val_acc: 0.1340\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 33.48384\n",
      "Epoch 66/500\n",
      "1548/1548 [==============================] - 0s 84us/step - loss: 22.6221 - mean_absolute_error: 2.7532 - acc: 0.1382 - val_loss: 34.6858 - val_mean_absolute_error: 2.8671 - val_acc: 0.1443\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 33.48384\n",
      "Epoch 67/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 22.4135 - mean_absolute_error: 2.7278 - acc: 0.1453 - val_loss: 34.5981 - val_mean_absolute_error: 2.8531 - val_acc: 0.1392\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 33.48384\n",
      "Epoch 68/500\n",
      "1548/1548 [==============================] - 0s 129us/step - loss: 22.4967 - mean_absolute_error: 2.7478 - acc: 0.1428 - val_loss: 34.8088 - val_mean_absolute_error: 2.9482 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 33.48384\n",
      "Epoch 69/500\n",
      "1548/1548 [==============================] - 0s 101us/step - loss: 22.5847 - mean_absolute_error: 2.7621 - acc: 0.1357 - val_loss: 34.6884 - val_mean_absolute_error: 2.9290 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 33.48384\n",
      "Epoch 70/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 22.4115 - mean_absolute_error: 2.7407 - acc: 0.1408 - val_loss: 34.3282 - val_mean_absolute_error: 2.8982 - val_acc: 0.1392\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 33.48384\n",
      "Epoch 71/500\n",
      "1548/1548 [==============================] - 0s 67us/step - loss: 22.1689 - mean_absolute_error: 2.7042 - acc: 0.1499 - val_loss: 34.3949 - val_mean_absolute_error: 2.9362 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 33.48384\n",
      "Epoch 72/500\n",
      "1548/1548 [==============================] - 0s 78us/step - loss: 22.3744 - mean_absolute_error: 2.7421 - acc: 0.1402 - val_loss: 34.5504 - val_mean_absolute_error: 2.9781 - val_acc: 0.1134\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 33.48384\n",
      "Epoch 73/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 22.2531 - mean_absolute_error: 2.7240 - acc: 0.1453 - val_loss: 34.2301 - val_mean_absolute_error: 2.8712 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 33.48384\n",
      "Epoch 74/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 21.9517 - mean_absolute_error: 2.6820 - acc: 0.1499 - val_loss: 34.0963 - val_mean_absolute_error: 2.8077 - val_acc: 0.1340\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 33.48384\n",
      "Epoch 75/500\n",
      "1548/1548 [==============================] - 0s 74us/step - loss: 21.8730 - mean_absolute_error: 2.6803 - acc: 0.1453 - val_loss: 34.0339 - val_mean_absolute_error: 2.7860 - val_acc: 0.1392\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 33.48384\n",
      "Epoch 76/500\n",
      "1548/1548 [==============================] - 0s 66us/step - loss: 21.8076 - mean_absolute_error: 2.6774 - acc: 0.1466 - val_loss: 33.9498 - val_mean_absolute_error: 2.7794 - val_acc: 0.1418\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 33.48384\n",
      "Epoch 77/500\n",
      "1548/1548 [==============================] - 0s 61us/step - loss: 21.7100 - mean_absolute_error: 2.6680 - acc: 0.1441 - val_loss: 33.6278 - val_mean_absolute_error: 2.7679 - val_acc: 0.1572\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 33.48384\n",
      "Epoch 78/500\n",
      "1548/1548 [==============================] - 0s 69us/step - loss: 21.6932 - mean_absolute_error: 2.6716 - acc: 0.1434 - val_loss: 33.6357 - val_mean_absolute_error: 2.7787 - val_acc: 0.1546\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 33.48384\n",
      "Epoch 79/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 21.6622 - mean_absolute_error: 2.6701 - acc: 0.1434 - val_loss: 33.5126 - val_mean_absolute_error: 2.7632 - val_acc: 0.1624\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 33.48384\n",
      "Epoch 80/500\n",
      "1548/1548 [==============================] - 0s 91us/step - loss: 21.5669 - mean_absolute_error: 2.6565 - acc: 0.1466 - val_loss: 33.6338 - val_mean_absolute_error: 2.7210 - val_acc: 0.1778\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 33.48384\n",
      "Epoch 81/500\n",
      "1548/1548 [==============================] - 0s 99us/step - loss: 21.6609 - mean_absolute_error: 2.6786 - acc: 0.1389 - val_loss: 33.3402 - val_mean_absolute_error: 2.7076 - val_acc: 0.1727\n",
      "\n",
      "Epoch 00081: val_loss improved from 33.48384 to 33.34025, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 82/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 21.9695 - mean_absolute_error: 2.7451 - acc: 0.1415 - val_loss: 33.7346 - val_mean_absolute_error: 2.9140 - val_acc: 0.1160\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 33.34025\n",
      "Epoch 83/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 22.3780 - mean_absolute_error: 2.7831 - acc: 0.1395 - val_loss: 34.1245 - val_mean_absolute_error: 2.9865 - val_acc: 0.1186\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 33.34025\n",
      "Epoch 84/500\n",
      "1548/1548 [==============================] - 0s 86us/step - loss: 22.5453 - mean_absolute_error: 2.8094 - acc: 0.1408 - val_loss: 34.1833 - val_mean_absolute_error: 3.0118 - val_acc: 0.1160\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 33.34025\n",
      "Epoch 85/500\n",
      "1548/1548 [==============================] - 0s 94us/step - loss: 22.5361 - mean_absolute_error: 2.8091 - acc: 0.1395 - val_loss: 34.1971 - val_mean_absolute_error: 2.9732 - val_acc: 0.1134\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 33.34025\n",
      "Epoch 86/500\n",
      "1548/1548 [==============================] - 0s 89us/step - loss: 22.4869 - mean_absolute_error: 2.8136 - acc: 0.1376 - val_loss: 34.0414 - val_mean_absolute_error: 2.9937 - val_acc: 0.1108\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 33.34025\n",
      "Epoch 87/500\n",
      "1548/1548 [==============================] - 0s 64us/step - loss: 22.1139 - mean_absolute_error: 2.7628 - acc: 0.1428 - val_loss: 33.6918 - val_mean_absolute_error: 2.9474 - val_acc: 0.1186\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 33.34025\n",
      "Epoch 88/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 22.1755 - mean_absolute_error: 2.7685 - acc: 0.1415 - val_loss: 33.8338 - val_mean_absolute_error: 2.9809 - val_acc: 0.1108\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 33.34025\n",
      "Epoch 89/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 21.6676 - mean_absolute_error: 2.6987 - acc: 0.1434 - val_loss: 33.5903 - val_mean_absolute_error: 2.7476 - val_acc: 0.1624\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 33.34025\n",
      "Epoch 90/500\n",
      "1548/1548 [==============================] - 0s 60us/step - loss: 21.6431 - mean_absolute_error: 2.7065 - acc: 0.1447 - val_loss: 33.1192 - val_mean_absolute_error: 2.8330 - val_acc: 0.1340\n",
      "\n",
      "Epoch 00090: val_loss improved from 33.34025 to 33.11917, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 91/500\n",
      "1548/1548 [==============================] - 0s 61us/step - loss: 21.9713 - mean_absolute_error: 2.7554 - acc: 0.1447 - val_loss: 33.7670 - val_mean_absolute_error: 2.9630 - val_acc: 0.1160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00091: val_loss did not improve from 33.11917\n",
      "Epoch 92/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 21.5904 - mean_absolute_error: 2.6987 - acc: 0.1479 - val_loss: 33.4199 - val_mean_absolute_error: 2.7758 - val_acc: 0.1443\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 33.11917\n",
      "Epoch 93/500\n",
      "1548/1548 [==============================] - 0s 64us/step - loss: 21.7099 - mean_absolute_error: 2.7152 - acc: 0.1441 - val_loss: 33.2432 - val_mean_absolute_error: 2.8981 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 33.11917\n",
      "Epoch 94/500\n",
      "1548/1548 [==============================] - 0s 65us/step - loss: 21.4173 - mean_absolute_error: 2.6804 - acc: 0.1505 - val_loss: 33.4776 - val_mean_absolute_error: 2.7382 - val_acc: 0.1649\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 33.11917\n",
      "Epoch 95/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 21.1376 - mean_absolute_error: 2.6429 - acc: 0.1518 - val_loss: 33.3135 - val_mean_absolute_error: 2.6936 - val_acc: 0.1624\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 33.11917\n",
      "Epoch 96/500\n",
      "1548/1548 [==============================] - 0s 78us/step - loss: 21.0872 - mean_absolute_error: 2.6428 - acc: 0.1486 - val_loss: 33.3419 - val_mean_absolute_error: 2.7416 - val_acc: 0.1495\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 33.11917\n",
      "Epoch 97/500\n",
      "1548/1548 [==============================] - 0s 64us/step - loss: 21.0679 - mean_absolute_error: 2.6340 - acc: 0.1544 - val_loss: 32.9111 - val_mean_absolute_error: 2.6784 - val_acc: 0.1701\n",
      "\n",
      "Epoch 00097: val_loss improved from 33.11917 to 32.91112, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 98/500\n",
      "1548/1548 [==============================] - 0s 98us/step - loss: 21.0529 - mean_absolute_error: 2.6458 - acc: 0.1370 - val_loss: 33.0027 - val_mean_absolute_error: 2.7098 - val_acc: 0.1675\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 32.91112\n",
      "Epoch 99/500\n",
      "1548/1548 [==============================] - 0s 115us/step - loss: 21.3768 - mean_absolute_error: 2.6914 - acc: 0.1389 - val_loss: 32.5393 - val_mean_absolute_error: 2.7793 - val_acc: 0.1546\n",
      "\n",
      "Epoch 00099: val_loss improved from 32.91112 to 32.53931, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 100/500\n",
      "1548/1548 [==============================] - 0s 68us/step - loss: 21.1563 - mean_absolute_error: 2.6695 - acc: 0.1421 - val_loss: 32.6292 - val_mean_absolute_error: 2.6755 - val_acc: 0.1727\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 32.53931\n",
      "Epoch 101/500\n",
      "1548/1548 [==============================] - 0s 73us/step - loss: 20.8950 - mean_absolute_error: 2.6328 - acc: 0.1402 - val_loss: 32.5555 - val_mean_absolute_error: 2.6928 - val_acc: 0.1675\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 32.53931\n",
      "Epoch 102/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 20.8886 - mean_absolute_error: 2.6268 - acc: 0.1441 - val_loss: 32.2744 - val_mean_absolute_error: 2.6270 - val_acc: 0.2010\n",
      "\n",
      "Epoch 00102: val_loss improved from 32.53931 to 32.27440, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 103/500\n",
      "1548/1548 [==============================] - 0s 116us/step - loss: 20.8469 - mean_absolute_error: 2.6231 - acc: 0.1447 - val_loss: 33.2351 - val_mean_absolute_error: 2.6343 - val_acc: 0.1856\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 32.27440\n",
      "Epoch 104/500\n",
      "1548/1548 [==============================] - 0s 80us/step - loss: 20.6657 - mean_absolute_error: 2.6000 - acc: 0.1537 - val_loss: 32.1669 - val_mean_absolute_error: 2.5892 - val_acc: 0.2268\n",
      "\n",
      "Epoch 00104: val_loss improved from 32.27440 to 32.16686, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 105/500\n",
      "1548/1548 [==============================] - 0s 64us/step - loss: 20.6468 - mean_absolute_error: 2.5994 - acc: 0.1441 - val_loss: 32.6580 - val_mean_absolute_error: 2.6093 - val_acc: 0.1959\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 32.16686\n",
      "Epoch 106/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 20.8841 - mean_absolute_error: 2.6365 - acc: 0.1428 - val_loss: 31.5992 - val_mean_absolute_error: 2.6336 - val_acc: 0.2010\n",
      "\n",
      "Epoch 00106: val_loss improved from 32.16686 to 31.59922, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 107/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 20.7162 - mean_absolute_error: 2.6193 - acc: 0.1421 - val_loss: 31.7398 - val_mean_absolute_error: 2.6148 - val_acc: 0.2165\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 31.59922\n",
      "Epoch 108/500\n",
      "1548/1548 [==============================] - 0s 69us/step - loss: 20.7852 - mean_absolute_error: 2.6243 - acc: 0.1376 - val_loss: 31.3376 - val_mean_absolute_error: 2.6458 - val_acc: 0.1933\n",
      "\n",
      "Epoch 00108: val_loss improved from 31.59922 to 31.33761, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 109/500\n",
      "1548/1548 [==============================] - 0s 97us/step - loss: 20.6793 - mean_absolute_error: 2.6154 - acc: 0.1441 - val_loss: 31.9860 - val_mean_absolute_error: 2.5558 - val_acc: 0.2603\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 31.33761\n",
      "Epoch 110/500\n",
      "1548/1548 [==============================] - 0s 103us/step - loss: 20.5310 - mean_absolute_error: 2.6012 - acc: 0.1460 - val_loss: 31.5897 - val_mean_absolute_error: 2.5772 - val_acc: 0.2423\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 31.33761\n",
      "Epoch 111/500\n",
      "1548/1548 [==============================] - 0s 97us/step - loss: 20.7502 - mean_absolute_error: 2.6295 - acc: 0.1389 - val_loss: 31.3146 - val_mean_absolute_error: 2.6075 - val_acc: 0.2268\n",
      "\n",
      "Epoch 00111: val_loss improved from 31.33761 to 31.31456, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 112/500\n",
      "1548/1548 [==============================] - 0s 67us/step - loss: 20.5231 - mean_absolute_error: 2.5965 - acc: 0.1453 - val_loss: 31.4561 - val_mean_absolute_error: 2.5816 - val_acc: 0.2500\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 31.31456\n",
      "Epoch 113/500\n",
      "1548/1548 [==============================] - ETA: 0s - loss: 22.4663 - mean_absolute_error: 2.5249 - acc: 0.135 - 0s 64us/step - loss: 20.8661 - mean_absolute_error: 2.6292 - acc: 0.1453 - val_loss: 31.7106 - val_mean_absolute_error: 2.5557 - val_acc: 0.2294\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 31.31456\n",
      "Epoch 114/500\n",
      "1548/1548 [==============================] - 0s 65us/step - loss: 20.3997 - mean_absolute_error: 2.5871 - acc: 0.1466 - val_loss: 31.6888 - val_mean_absolute_error: 2.5634 - val_acc: 0.2448\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 31.31456\n",
      "Epoch 115/500\n",
      "1548/1548 [==============================] - 0s 75us/step - loss: 20.2793 - mean_absolute_error: 2.5626 - acc: 0.1512 - val_loss: 31.2728 - val_mean_absolute_error: 2.5724 - val_acc: 0.2474\n",
      "\n",
      "Epoch 00115: val_loss improved from 31.31456 to 31.27278, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 116/500\n",
      "1548/1548 [==============================] - 0s 99us/step - loss: 20.2056 - mean_absolute_error: 2.5417 - acc: 0.1550 - val_loss: 31.0997 - val_mean_absolute_error: 2.5785 - val_acc: 0.2474\n",
      "\n",
      "Epoch 00116: val_loss improved from 31.27278 to 31.09968, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 117/500\n",
      "1548/1548 [==============================] - 0s 83us/step - loss: 20.7605 - mean_absolute_error: 2.6100 - acc: 0.1525 - val_loss: 31.5264 - val_mean_absolute_error: 2.5828 - val_acc: 0.2216\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 31.09968\n",
      "Epoch 118/500\n",
      "1548/1548 [==============================] - 0s 89us/step - loss: 20.2162 - mean_absolute_error: 2.5584 - acc: 0.1550 - val_loss: 31.4738 - val_mean_absolute_error: 2.5772 - val_acc: 0.2371\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 31.09968\n",
      "Epoch 119/500\n",
      "1548/1548 [==============================] - 0s 89us/step - loss: 20.0960 - mean_absolute_error: 2.5303 - acc: 0.1641 - val_loss: 31.1415 - val_mean_absolute_error: 2.5777 - val_acc: 0.2320\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 31.09968\n",
      "Epoch 120/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 20.7010 - mean_absolute_error: 2.6003 - acc: 0.1583 - val_loss: 31.2372 - val_mean_absolute_error: 2.5997 - val_acc: 0.2113\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 31.09968\n",
      "Epoch 121/500\n",
      "1548/1548 [==============================] - 0s 96us/step - loss: 20.0807 - mean_absolute_error: 2.5339 - acc: 0.1660 - val_loss: 31.6773 - val_mean_absolute_error: 2.5833 - val_acc: 0.2294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00121: val_loss did not improve from 31.09968\n",
      "Epoch 122/500\n",
      "1548/1548 [==============================] - 0s 114us/step - loss: 19.9863 - mean_absolute_error: 2.5168 - acc: 0.1764 - val_loss: 31.6844 - val_mean_absolute_error: 2.5953 - val_acc: 0.2268\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 31.09968\n",
      "Epoch 123/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 19.9850 - mean_absolute_error: 2.5152 - acc: 0.1764 - val_loss: 31.1081 - val_mean_absolute_error: 2.5740 - val_acc: 0.2320\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 31.09968\n",
      "Epoch 124/500\n",
      "1548/1548 [==============================] - 0s 65us/step - loss: 20.1855 - mean_absolute_error: 2.5387 - acc: 0.1686 - val_loss: 29.9319 - val_mean_absolute_error: 2.6038 - val_acc: 0.2474\n",
      "\n",
      "Epoch 00124: val_loss improved from 31.09968 to 29.93193, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 125/500\n",
      "1548/1548 [==============================] - 0s 67us/step - loss: 20.0201 - mean_absolute_error: 2.5198 - acc: 0.1641 - val_loss: 30.9792 - val_mean_absolute_error: 2.6842 - val_acc: 0.1804\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 29.93193\n",
      "Epoch 126/500\n",
      "1548/1548 [==============================] - 0s 59us/step - loss: 19.9595 - mean_absolute_error: 2.5161 - acc: 0.1744 - val_loss: 31.3773 - val_mean_absolute_error: 2.6595 - val_acc: 0.1778\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 29.93193\n",
      "Epoch 127/500\n",
      "1548/1548 [==============================] - 0s 116us/step - loss: 19.9249 - mean_absolute_error: 2.5130 - acc: 0.1822 - val_loss: 31.3316 - val_mean_absolute_error: 2.6434 - val_acc: 0.1959\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 29.93193\n",
      "Epoch 128/500\n",
      "1548/1548 [==============================] - 0s 75us/step - loss: 19.8842 - mean_absolute_error: 2.5082 - acc: 0.1796 - val_loss: 31.1765 - val_mean_absolute_error: 2.6387 - val_acc: 0.1959\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 29.93193\n",
      "Epoch 129/500\n",
      "1548/1548 [==============================] - 0s 74us/step - loss: 19.8815 - mean_absolute_error: 2.5065 - acc: 0.1822 - val_loss: 31.5363 - val_mean_absolute_error: 2.6805 - val_acc: 0.1649\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 29.93193\n",
      "Epoch 130/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 19.9015 - mean_absolute_error: 2.5106 - acc: 0.1802 - val_loss: 30.9447 - val_mean_absolute_error: 2.6057 - val_acc: 0.2294\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 29.93193\n",
      "Epoch 131/500\n",
      "1548/1548 [==============================] - 0s 64us/step - loss: 20.5671 - mean_absolute_error: 2.5844 - acc: 0.1667 - val_loss: 32.0708 - val_mean_absolute_error: 2.7264 - val_acc: 0.1521\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 29.93193\n",
      "Epoch 132/500\n",
      "1548/1548 [==============================] - 0s 63us/step - loss: 19.8555 - mean_absolute_error: 2.5247 - acc: 0.1667 - val_loss: 31.5237 - val_mean_absolute_error: 2.6965 - val_acc: 0.1727\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 29.93193\n",
      "Epoch 133/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 19.8482 - mean_absolute_error: 2.5180 - acc: 0.1673 - val_loss: 31.5334 - val_mean_absolute_error: 2.7061 - val_acc: 0.1701\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 29.93193\n",
      "Epoch 134/500\n",
      "1548/1548 [==============================] - 0s 60us/step - loss: 19.8459 - mean_absolute_error: 2.5185 - acc: 0.1699 - val_loss: 31.4038 - val_mean_absolute_error: 2.7003 - val_acc: 0.1753\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 29.93193\n",
      "Epoch 135/500\n",
      "1548/1548 [==============================] - 0s 62us/step - loss: 19.8444 - mean_absolute_error: 2.5207 - acc: 0.1718 - val_loss: 31.4160 - val_mean_absolute_error: 2.7213 - val_acc: 0.1701\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 29.93193\n",
      "Epoch 136/500\n",
      "1548/1548 [==============================] - 0s 65us/step - loss: 19.8661 - mean_absolute_error: 2.5249 - acc: 0.1654 - val_loss: 31.3817 - val_mean_absolute_error: 2.7094 - val_acc: 0.1727\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 29.93193\n",
      "Epoch 137/500\n",
      "1548/1548 [==============================] - 0s 78us/step - loss: 19.8203 - mean_absolute_error: 2.5199 - acc: 0.1647 - val_loss: 30.8164 - val_mean_absolute_error: 2.6596 - val_acc: 0.1856\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 29.93193\n",
      "Epoch 138/500\n",
      "1548/1548 [==============================] - 0s 63us/step - loss: 19.8247 - mean_absolute_error: 2.5165 - acc: 0.1589 - val_loss: 31.3900 - val_mean_absolute_error: 2.7475 - val_acc: 0.1598\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 29.93193\n",
      "Epoch 139/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 19.8368 - mean_absolute_error: 2.5307 - acc: 0.1589 - val_loss: 31.3783 - val_mean_absolute_error: 2.7294 - val_acc: 0.1675\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 29.93193\n",
      "Epoch 140/500\n",
      "1548/1548 [==============================] - 0s 75us/step - loss: 19.8264 - mean_absolute_error: 2.5284 - acc: 0.1628 - val_loss: 30.3780 - val_mean_absolute_error: 2.6494 - val_acc: 0.2139\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 29.93193\n",
      "Epoch 141/500\n",
      "1548/1548 [==============================] - 0s 83us/step - loss: 20.2023 - mean_absolute_error: 2.5728 - acc: 0.1563 - val_loss: 31.3842 - val_mean_absolute_error: 2.7949 - val_acc: 0.1340\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 29.93193\n",
      "Epoch 142/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 19.7814 - mean_absolute_error: 2.5257 - acc: 0.1609 - val_loss: 31.4460 - val_mean_absolute_error: 2.7350 - val_acc: 0.1649\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 29.93193\n",
      "Epoch 143/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 19.8044 - mean_absolute_error: 2.5306 - acc: 0.1589 - val_loss: 31.3976 - val_mean_absolute_error: 2.7646 - val_acc: 0.1418\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 29.93193\n",
      "Epoch 144/500\n",
      "1548/1548 [==============================] - 0s 96us/step - loss: 19.8290 - mean_absolute_error: 2.5372 - acc: 0.1583 - val_loss: 31.3944 - val_mean_absolute_error: 2.7554 - val_acc: 0.1495\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 29.93193\n",
      "Epoch 145/500\n",
      "1548/1548 [==============================] - 0s 102us/step - loss: 19.8080 - mean_absolute_error: 2.5365 - acc: 0.1589 - val_loss: 31.1856 - val_mean_absolute_error: 2.7537 - val_acc: 0.1598\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 29.93193\n",
      "Epoch 146/500\n",
      "1548/1548 [==============================] - 0s 112us/step - loss: 19.8668 - mean_absolute_error: 2.5457 - acc: 0.1525 - val_loss: 31.2646 - val_mean_absolute_error: 2.7788 - val_acc: 0.1443\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 29.93193\n",
      "Epoch 147/500\n",
      "1548/1548 [==============================] - 0s 116us/step - loss: 19.8005 - mean_absolute_error: 2.5389 - acc: 0.1583 - val_loss: 31.0156 - val_mean_absolute_error: 2.7114 - val_acc: 0.1675\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 29.93193\n",
      "Epoch 148/500\n",
      "1548/1548 [==============================] - 0s 106us/step - loss: 19.7493 - mean_absolute_error: 2.5294 - acc: 0.1583 - val_loss: 31.5173 - val_mean_absolute_error: 2.7786 - val_acc: 0.1443\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 29.93193\n",
      "Epoch 149/500\n",
      "1548/1548 [==============================] - 0s 84us/step - loss: 20.4513 - mean_absolute_error: 2.5995 - acc: 0.1647 - val_loss: 32.0775 - val_mean_absolute_error: 2.5719 - val_acc: 0.2242\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 29.93193\n",
      "Epoch 150/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 19.5565 - mean_absolute_error: 2.4866 - acc: 0.1647 - val_loss: 30.7782 - val_mean_absolute_error: 2.6628 - val_acc: 0.1959\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 29.93193\n",
      "Epoch 151/500\n",
      "1548/1548 [==============================] - 0s 79us/step - loss: 19.8133 - mean_absolute_error: 2.5366 - acc: 0.1499 - val_loss: 31.7282 - val_mean_absolute_error: 2.8113 - val_acc: 0.1366\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 29.93193\n",
      "Epoch 152/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 19.8569 - mean_absolute_error: 2.5581 - acc: 0.1615 - val_loss: 30.6168 - val_mean_absolute_error: 2.6949 - val_acc: 0.1881\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 29.93193\n",
      "Epoch 153/500\n",
      "1548/1548 [==============================] - 0s 86us/step - loss: 20.1430 - mean_absolute_error: 2.5857 - acc: 0.1537 - val_loss: 31.2544 - val_mean_absolute_error: 2.7316 - val_acc: 0.1469\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 29.93193\n",
      "Epoch 154/500\n",
      "1548/1548 [==============================] - 0s 93us/step - loss: 19.6582 - mean_absolute_error: 2.5189 - acc: 0.1673 - val_loss: 30.5096 - val_mean_absolute_error: 2.6613 - val_acc: 0.1985\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 29.93193\n",
      "Epoch 155/500\n",
      "1548/1548 [==============================] - 0s 118us/step - loss: 19.8908 - mean_absolute_error: 2.5563 - acc: 0.1518 - val_loss: 30.0366 - val_mean_absolute_error: 2.6972 - val_acc: 0.1881\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 29.93193\n",
      "Epoch 156/500\n",
      "1548/1548 [==============================] - 0s 136us/step - loss: 19.6479 - mean_absolute_error: 2.5219 - acc: 0.1583 - val_loss: 31.1307 - val_mean_absolute_error: 2.7753 - val_acc: 0.1443\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 29.93193\n",
      "Epoch 157/500\n",
      "1548/1548 [==============================] - 0s 137us/step - loss: 19.6957 - mean_absolute_error: 2.5328 - acc: 0.1654 - val_loss: 30.6503 - val_mean_absolute_error: 2.6866 - val_acc: 0.1856\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 29.93193\n",
      "Epoch 158/500\n",
      "1548/1548 [==============================] - 0s 138us/step - loss: 20.1527 - mean_absolute_error: 2.5958 - acc: 0.1505 - val_loss: 31.0225 - val_mean_absolute_error: 2.7256 - val_acc: 0.1495\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 29.93193\n",
      "Epoch 159/500\n",
      "1548/1548 [==============================] - 0s 63us/step - loss: 19.6196 - mean_absolute_error: 2.5202 - acc: 0.1654 - val_loss: 31.4964 - val_mean_absolute_error: 2.7199 - val_acc: 0.1598\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 29.93193\n",
      "Epoch 160/500\n",
      "1548/1548 [==============================] - 0s 61us/step - loss: 19.7391 - mean_absolute_error: 2.5508 - acc: 0.1550 - val_loss: 30.3565 - val_mean_absolute_error: 2.7072 - val_acc: 0.1830\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 29.93193\n",
      "Epoch 161/500\n",
      "1548/1548 [==============================] - 0s 61us/step - loss: 20.0801 - mean_absolute_error: 2.5796 - acc: 0.1641 - val_loss: 31.6451 - val_mean_absolute_error: 2.6987 - val_acc: 0.1649\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 29.93193\n",
      "Epoch 162/500\n",
      "1548/1548 [==============================] - 0s 117us/step - loss: 19.6040 - mean_absolute_error: 2.5142 - acc: 0.1673 - val_loss: 30.8495 - val_mean_absolute_error: 2.6779 - val_acc: 0.1959\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 29.93193\n",
      "Epoch 163/500\n",
      "1548/1548 [==============================] - 0s 148us/step - loss: 20.3746 - mean_absolute_error: 2.6300 - acc: 0.1408 - val_loss: 31.0617 - val_mean_absolute_error: 2.8209 - val_acc: 0.1263\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 29.93193\n",
      "Epoch 164/500\n",
      "1548/1548 [==============================] - 0s 143us/step - loss: 19.5866 - mean_absolute_error: 2.5281 - acc: 0.1641 - val_loss: 31.0075 - val_mean_absolute_error: 2.6622 - val_acc: 0.2062\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 29.93193\n",
      "Epoch 165/500\n",
      "1548/1548 [==============================] - 0s 92us/step - loss: 19.6953 - mean_absolute_error: 2.5362 - acc: 0.1531 - val_loss: 31.0555 - val_mean_absolute_error: 2.7434 - val_acc: 0.1521\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 29.93193\n",
      "Epoch 166/500\n",
      "1548/1548 [==============================] - 0s 69us/step - loss: 19.7278 - mean_absolute_error: 2.5499 - acc: 0.1544 - val_loss: 31.0859 - val_mean_absolute_error: 2.7277 - val_acc: 0.1624\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 29.93193\n",
      "Epoch 167/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 20.0159 - mean_absolute_error: 2.6045 - acc: 0.1479 - val_loss: 28.9891 - val_mean_absolute_error: 2.7081 - val_acc: 0.2010\n",
      "\n",
      "Epoch 00167: val_loss improved from 29.93193 to 28.98907, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 168/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 19.5724 - mean_absolute_error: 2.5230 - acc: 0.1589 - val_loss: 30.8829 - val_mean_absolute_error: 2.7842 - val_acc: 0.1418\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 28.98907\n",
      "Epoch 169/500\n",
      "1548/1548 [==============================] - 0s 86us/step - loss: 19.6329 - mean_absolute_error: 2.5442 - acc: 0.1531 - val_loss: 31.3340 - val_mean_absolute_error: 2.7802 - val_acc: 0.1443\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 28.98907\n",
      "Epoch 170/500\n",
      "1548/1548 [==============================] - 0s 63us/step - loss: 19.7067 - mean_absolute_error: 2.5593 - acc: 0.1544 - val_loss: 31.1357 - val_mean_absolute_error: 2.7974 - val_acc: 0.1418\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 28.98907\n",
      "Epoch 171/500\n",
      "1548/1548 [==============================] - 0s 146us/step - loss: 19.7080 - mean_absolute_error: 2.5613 - acc: 0.1550 - val_loss: 31.0943 - val_mean_absolute_error: 2.7843 - val_acc: 0.1392\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 28.98907\n",
      "Epoch 172/500\n",
      "1548/1548 [==============================] - 0s 73us/step - loss: 19.6212 - mean_absolute_error: 2.5476 - acc: 0.1570 - val_loss: 31.0826 - val_mean_absolute_error: 2.7970 - val_acc: 0.1418\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 28.98907\n",
      "Epoch 173/500\n",
      "1548/1548 [==============================] - 0s 69us/step - loss: 19.6709 - mean_absolute_error: 2.5569 - acc: 0.1531 - val_loss: 31.1691 - val_mean_absolute_error: 2.7875 - val_acc: 0.1366\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 28.98907\n",
      "Epoch 174/500\n",
      "1548/1548 [==============================] - 0s 68us/step - loss: 19.5929 - mean_absolute_error: 2.5433 - acc: 0.1563 - val_loss: 31.1427 - val_mean_absolute_error: 2.7956 - val_acc: 0.1366\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 28.98907\n",
      "Epoch 175/500\n",
      "1548/1548 [==============================] - 0s 62us/step - loss: 19.6958 - mean_absolute_error: 2.5666 - acc: 0.1525 - val_loss: 29.5029 - val_mean_absolute_error: 2.7189 - val_acc: 0.1881\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 28.98907\n",
      "Epoch 176/500\n",
      "1548/1548 [==============================] - 0s 65us/step - loss: 19.6058 - mean_absolute_error: 2.5364 - acc: 0.1583 - val_loss: 29.0394 - val_mean_absolute_error: 2.6262 - val_acc: 0.2088\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 28.98907\n",
      "Epoch 177/500\n",
      "1548/1548 [==============================] - 0s 93us/step - loss: 20.5526 - mean_absolute_error: 2.6517 - acc: 0.1583 - val_loss: 31.7269 - val_mean_absolute_error: 2.6652 - val_acc: 0.1856\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 28.98907\n",
      "Epoch 178/500\n",
      "1548/1548 [==============================] - 0s 95us/step - loss: 19.3488 - mean_absolute_error: 2.4858 - acc: 0.1660 - val_loss: 31.5564 - val_mean_absolute_error: 2.6265 - val_acc: 0.2165\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 28.98907\n",
      "Epoch 179/500\n",
      "1548/1548 [==============================] - 0s 136us/step - loss: 19.6130 - mean_absolute_error: 2.5450 - acc: 0.1609 - val_loss: 30.0170 - val_mean_absolute_error: 2.7675 - val_acc: 0.1546\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 28.98907\n",
      "Epoch 180/500\n",
      "1548/1548 [==============================] - 0s 79us/step - loss: 19.5594 - mean_absolute_error: 2.5413 - acc: 0.1583 - val_loss: 31.5248 - val_mean_absolute_error: 2.7893 - val_acc: 0.1340\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 28.98907\n",
      "Epoch 181/500\n",
      "1548/1548 [==============================] - 0s 61us/step - loss: 19.5273 - mean_absolute_error: 2.5344 - acc: 0.1609 - val_loss: 31.1962 - val_mean_absolute_error: 2.6794 - val_acc: 0.1985\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 28.98907\n",
      "Epoch 182/500\n",
      "1548/1548 [==============================] - 0s 64us/step - loss: 19.5044 - mean_absolute_error: 2.5196 - acc: 0.1550 - val_loss: 31.5589 - val_mean_absolute_error: 2.6812 - val_acc: 0.1856\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 28.98907\n",
      "Epoch 183/500\n",
      "1548/1548 [==============================] - 0s 60us/step - loss: 19.5474 - mean_absolute_error: 2.5258 - acc: 0.1505 - val_loss: 31.8170 - val_mean_absolute_error: 2.6477 - val_acc: 0.2036\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 28.98907\n",
      "Epoch 184/500\n",
      "1548/1548 [==============================] - 0s 97us/step - loss: 19.4622 - mean_absolute_error: 2.5201 - acc: 0.1557 - val_loss: 31.9065 - val_mean_absolute_error: 2.6725 - val_acc: 0.1907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00184: val_loss did not improve from 28.98907\n",
      "Epoch 185/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 19.4511 - mean_absolute_error: 2.5159 - acc: 0.1525 - val_loss: 31.9348 - val_mean_absolute_error: 2.6455 - val_acc: 0.1959\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 28.98907\n",
      "Epoch 186/500\n",
      "1548/1548 [==============================] - 0s 83us/step - loss: 19.3894 - mean_absolute_error: 2.5210 - acc: 0.1499 - val_loss: 31.4149 - val_mean_absolute_error: 2.7060 - val_acc: 0.1675\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 28.98907\n",
      "Epoch 187/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 19.3752 - mean_absolute_error: 2.5241 - acc: 0.1525 - val_loss: 32.0107 - val_mean_absolute_error: 2.7724 - val_acc: 0.1418\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 28.98907\n",
      "Epoch 188/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 19.4548 - mean_absolute_error: 2.5347 - acc: 0.1641 - val_loss: 31.5630 - val_mean_absolute_error: 2.6725 - val_acc: 0.1881\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 28.98907\n",
      "Epoch 189/500\n",
      "1548/1548 [==============================] - 0s 68us/step - loss: 19.3755 - mean_absolute_error: 2.5122 - acc: 0.1531 - val_loss: 31.6638 - val_mean_absolute_error: 2.6593 - val_acc: 0.1881\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 28.98907\n",
      "Epoch 190/500\n",
      "1548/1548 [==============================] - 0s 107us/step - loss: 19.3384 - mean_absolute_error: 2.5188 - acc: 0.1479 - val_loss: 32.5563 - val_mean_absolute_error: 2.7757 - val_acc: 0.1469\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 28.98907\n",
      "Epoch 191/500\n",
      "1548/1548 [==============================] - 0s 111us/step - loss: 19.3697 - mean_absolute_error: 2.5292 - acc: 0.1641 - val_loss: 31.7144 - val_mean_absolute_error: 2.6730 - val_acc: 0.1830\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 28.98907\n",
      "Epoch 192/500\n",
      "1548/1548 [==============================] - 0s 98us/step - loss: 19.2953 - mean_absolute_error: 2.5108 - acc: 0.1525 - val_loss: 32.1052 - val_mean_absolute_error: 2.7200 - val_acc: 0.1649\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 28.98907\n",
      "Epoch 193/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 19.3395 - mean_absolute_error: 2.5214 - acc: 0.1583 - val_loss: 31.5037 - val_mean_absolute_error: 2.6676 - val_acc: 0.1778\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 28.98907\n",
      "Epoch 194/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 19.2702 - mean_absolute_error: 2.5002 - acc: 0.1563 - val_loss: 31.6664 - val_mean_absolute_error: 2.6595 - val_acc: 0.1830\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 28.98907\n",
      "Epoch 195/500\n",
      "1548/1548 [==============================] - 0s 100us/step - loss: 19.2852 - mean_absolute_error: 2.5149 - acc: 0.1537 - val_loss: 32.5182 - val_mean_absolute_error: 2.7728 - val_acc: 0.1495\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 28.98907\n",
      "Epoch 196/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 19.2356 - mean_absolute_error: 2.5134 - acc: 0.1693 - val_loss: 31.5231 - val_mean_absolute_error: 2.6428 - val_acc: 0.1830\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 28.98907\n",
      "Epoch 197/500\n",
      "1548/1548 [==============================] - 0s 69us/step - loss: 19.2727 - mean_absolute_error: 2.5086 - acc: 0.1596 - val_loss: 31.9380 - val_mean_absolute_error: 2.7821 - val_acc: 0.1418\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 28.98907\n",
      "Epoch 198/500\n",
      "1548/1548 [==============================] - 0s 79us/step - loss: 19.2839 - mean_absolute_error: 2.5230 - acc: 0.1654 - val_loss: 32.0954 - val_mean_absolute_error: 2.7073 - val_acc: 0.1572\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 28.98907\n",
      "Epoch 199/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 19.2531 - mean_absolute_error: 2.5190 - acc: 0.1583 - val_loss: 31.9537 - val_mean_absolute_error: 2.7590 - val_acc: 0.1418\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 28.98907\n",
      "Epoch 200/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 19.4517 - mean_absolute_error: 2.5535 - acc: 0.1583 - val_loss: 29.4691 - val_mean_absolute_error: 2.6563 - val_acc: 0.1881\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 28.98907\n",
      "Epoch 201/500\n",
      "1548/1548 [==============================] - 0s 79us/step - loss: 19.1620 - mean_absolute_error: 2.4861 - acc: 0.1705 - val_loss: 31.2676 - val_mean_absolute_error: 2.7060 - val_acc: 0.1624\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 28.98907\n",
      "Epoch 202/500\n",
      "1548/1548 [==============================] - 0s 75us/step - loss: 19.2382 - mean_absolute_error: 2.5135 - acc: 0.1596 - val_loss: 31.7904 - val_mean_absolute_error: 2.7569 - val_acc: 0.1366\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 28.98907\n",
      "Epoch 203/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 19.1915 - mean_absolute_error: 2.5135 - acc: 0.1602 - val_loss: 31.6436 - val_mean_absolute_error: 2.7624 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 28.98907\n",
      "Epoch 204/500\n",
      "1548/1548 [==============================] - 0s 75us/step - loss: 19.7050 - mean_absolute_error: 2.5922 - acc: 0.1537 - val_loss: 30.4523 - val_mean_absolute_error: 2.8008 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 28.98907\n",
      "Epoch 205/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 19.2402 - mean_absolute_error: 2.5245 - acc: 0.1609 - val_loss: 31.1751 - val_mean_absolute_error: 2.7567 - val_acc: 0.1495\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 28.98907\n",
      "Epoch 206/500\n",
      "1548/1548 [==============================] - 0s 69us/step - loss: 19.4332 - mean_absolute_error: 2.5647 - acc: 0.1563 - val_loss: 30.2696 - val_mean_absolute_error: 2.6949 - val_acc: 0.1624\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 28.98907\n",
      "Epoch 207/500\n",
      "1548/1548 [==============================] - 0s 95us/step - loss: 19.0259 - mean_absolute_error: 2.4826 - acc: 0.1699 - val_loss: 30.8402 - val_mean_absolute_error: 2.7114 - val_acc: 0.1649\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 28.98907\n",
      "Epoch 208/500\n",
      "1548/1548 [==============================] - 0s 99us/step - loss: 19.4120 - mean_absolute_error: 2.5568 - acc: 0.1647 - val_loss: 30.8550 - val_mean_absolute_error: 2.7240 - val_acc: 0.1340\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 28.98907\n",
      "Epoch 209/500\n",
      "1548/1548 [==============================] - 0s 91us/step - loss: 19.0854 - mean_absolute_error: 2.4959 - acc: 0.1634 - val_loss: 31.0912 - val_mean_absolute_error: 2.7393 - val_acc: 0.1495\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 28.98907\n",
      "Epoch 210/500\n",
      "1548/1548 [==============================] - 0s 123us/step - loss: 19.6410 - mean_absolute_error: 2.5872 - acc: 0.1544 - val_loss: 30.9457 - val_mean_absolute_error: 2.6867 - val_acc: 0.1495\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 28.98907\n",
      "Epoch 211/500\n",
      "1548/1548 [==============================] - 0s 86us/step - loss: 18.9823 - mean_absolute_error: 2.4767 - acc: 0.1686 - val_loss: 31.1152 - val_mean_absolute_error: 2.7285 - val_acc: 0.1495\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 28.98907\n",
      "Epoch 212/500\n",
      "1548/1548 [==============================] - 0s 78us/step - loss: 19.1164 - mean_absolute_error: 2.5173 - acc: 0.1589 - val_loss: 29.6965 - val_mean_absolute_error: 2.7003 - val_acc: 0.1572\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 28.98907\n",
      "Epoch 213/500\n",
      "1548/1548 [==============================] - 0s 88us/step - loss: 18.9786 - mean_absolute_error: 2.4849 - acc: 0.1686 - val_loss: 29.6934 - val_mean_absolute_error: 2.7049 - val_acc: 0.1572\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 28.98907\n",
      "Epoch 214/500\n",
      "1548/1548 [==============================] - 0s 92us/step - loss: 19.4281 - mean_absolute_error: 2.5448 - acc: 0.1667 - val_loss: 31.2363 - val_mean_absolute_error: 2.6604 - val_acc: 0.1675\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 28.98907\n",
      "Epoch 215/500\n",
      "1548/1548 [==============================] - 0s 108us/step - loss: 18.8997 - mean_absolute_error: 2.4684 - acc: 0.1738 - val_loss: 31.1824 - val_mean_absolute_error: 2.7304 - val_acc: 0.1495\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 28.98907\n",
      "Epoch 216/500\n",
      "1548/1548 [==============================] - 0s 78us/step - loss: 19.1238 - mean_absolute_error: 2.5158 - acc: 0.1609 - val_loss: 31.0078 - val_mean_absolute_error: 2.8034 - val_acc: 0.1263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00216: val_loss did not improve from 28.98907\n",
      "Epoch 217/500\n",
      "1548/1548 [==============================] - 0s 59us/step - loss: 19.3325 - mean_absolute_error: 2.5591 - acc: 0.1557 - val_loss: 28.8988 - val_mean_absolute_error: 2.6417 - val_acc: 0.1933\n",
      "\n",
      "Epoch 00217: val_loss improved from 28.98907 to 28.89885, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 218/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 18.9414 - mean_absolute_error: 2.4692 - acc: 0.1764 - val_loss: 30.7821 - val_mean_absolute_error: 2.7307 - val_acc: 0.1443\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 28.89885\n",
      "Epoch 219/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 19.0529 - mean_absolute_error: 2.5056 - acc: 0.1609 - val_loss: 31.3254 - val_mean_absolute_error: 2.8009 - val_acc: 0.1366\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 28.89885\n",
      "Epoch 220/500\n",
      "1548/1548 [==============================] - 0s 66us/step - loss: 19.0273 - mean_absolute_error: 2.5125 - acc: 0.1609 - val_loss: 30.7253 - val_mean_absolute_error: 2.8100 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 28.89885\n",
      "Epoch 221/500\n",
      "1548/1548 [==============================] - 0s 75us/step - loss: 19.6513 - mean_absolute_error: 2.6015 - acc: 0.1525 - val_loss: 30.3156 - val_mean_absolute_error: 2.8341 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 28.89885\n",
      "Epoch 222/500\n",
      "1548/1548 [==============================] - 0s 96us/step - loss: 18.9644 - mean_absolute_error: 2.5001 - acc: 0.1647 - val_loss: 30.5652 - val_mean_absolute_error: 2.7693 - val_acc: 0.1340\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 28.89885\n",
      "Epoch 223/500\n",
      "1548/1548 [==============================] - 0s 125us/step - loss: 19.1160 - mean_absolute_error: 2.5201 - acc: 0.1576 - val_loss: 32.4585 - val_mean_absolute_error: 2.7287 - val_acc: 0.1521\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 28.89885\n",
      "Epoch 224/500\n",
      "1548/1548 [==============================] - 0s 86us/step - loss: 19.2688 - mean_absolute_error: 2.5446 - acc: 0.1531 - val_loss: 28.5593 - val_mean_absolute_error: 2.7739 - val_acc: 0.1675\n",
      "\n",
      "Epoch 00224: val_loss improved from 28.89885 to 28.55927, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 225/500\n",
      "1548/1548 [==============================] - 0s 66us/step - loss: 19.0057 - mean_absolute_error: 2.5071 - acc: 0.1596 - val_loss: 30.5769 - val_mean_absolute_error: 2.8234 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 28.55927\n",
      "Epoch 226/500\n",
      "1548/1548 [==============================] - 0s 95us/step - loss: 19.0839 - mean_absolute_error: 2.5326 - acc: 0.1557 - val_loss: 30.7377 - val_mean_absolute_error: 2.8552 - val_acc: 0.1263\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 28.55927\n",
      "Epoch 227/500\n",
      "1548/1548 [==============================] - 0s 63us/step - loss: 19.0294 - mean_absolute_error: 2.5243 - acc: 0.1550 - val_loss: 30.3906 - val_mean_absolute_error: 2.8596 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 28.55927\n",
      "Epoch 228/500\n",
      "1548/1548 [==============================] - 0s 94us/step - loss: 19.4427 - mean_absolute_error: 2.5774 - acc: 0.1544 - val_loss: 30.1490 - val_mean_absolute_error: 2.7854 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 28.55927\n",
      "Epoch 229/500\n",
      "1548/1548 [==============================] - 0s 89us/step - loss: 18.7865 - mean_absolute_error: 2.4772 - acc: 0.1712 - val_loss: 30.8472 - val_mean_absolute_error: 2.7573 - val_acc: 0.1340\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 28.55927\n",
      "Epoch 230/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 18.9332 - mean_absolute_error: 2.5059 - acc: 0.1512 - val_loss: 31.3106 - val_mean_absolute_error: 2.8231 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 28.55927\n",
      "Epoch 231/500\n",
      "1548/1548 [==============================] - 0s 112us/step - loss: 18.8999 - mean_absolute_error: 2.5038 - acc: 0.1525 - val_loss: 31.0271 - val_mean_absolute_error: 2.8218 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 28.55927\n",
      "Epoch 232/500\n",
      "1548/1548 [==============================] - 0s 78us/step - loss: 18.8465 - mean_absolute_error: 2.4979 - acc: 0.1570 - val_loss: 30.5421 - val_mean_absolute_error: 2.8091 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 28.55927\n",
      "Epoch 233/500\n",
      "1548/1548 [==============================] - 0s 64us/step - loss: 19.5255 - mean_absolute_error: 2.5869 - acc: 0.1557 - val_loss: 29.8246 - val_mean_absolute_error: 2.8260 - val_acc: 0.1134\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 28.55927\n",
      "Epoch 234/500\n",
      "1548/1548 [==============================] - 0s 60us/step - loss: 18.8668 - mean_absolute_error: 2.4990 - acc: 0.1609 - val_loss: 30.8902 - val_mean_absolute_error: 2.7939 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 28.55927\n",
      "Epoch 235/500\n",
      "1548/1548 [==============================] - 0s 60us/step - loss: 18.9885 - mean_absolute_error: 2.5176 - acc: 0.1486 - val_loss: 31.8229 - val_mean_absolute_error: 2.8038 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 28.55927\n",
      "Epoch 236/500\n",
      "1548/1548 [==============================] - 0s 59us/step - loss: 18.7947 - mean_absolute_error: 2.4912 - acc: 0.1596 - val_loss: 31.3879 - val_mean_absolute_error: 2.7903 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 28.55927\n",
      "Epoch 237/500\n",
      "1548/1548 [==============================] - 0s 66us/step - loss: 18.7920 - mean_absolute_error: 2.4946 - acc: 0.1557 - val_loss: 30.7072 - val_mean_absolute_error: 2.8123 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 28.55927\n",
      "Epoch 238/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 19.4178 - mean_absolute_error: 2.5786 - acc: 0.1621 - val_loss: 29.5555 - val_mean_absolute_error: 2.8052 - val_acc: 0.1134\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 28.55927\n",
      "Epoch 239/500\n",
      "1548/1548 [==============================] - 0s 75us/step - loss: 18.8231 - mean_absolute_error: 2.4974 - acc: 0.1576 - val_loss: 31.9520 - val_mean_absolute_error: 2.8291 - val_acc: 0.1340\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 28.55927\n",
      "Epoch 240/500\n",
      "1548/1548 [==============================] - 0s 59us/step - loss: 19.0387 - mean_absolute_error: 2.5400 - acc: 0.1518 - val_loss: 29.5569 - val_mean_absolute_error: 2.8363 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 28.55927\n",
      "Epoch 241/500\n",
      "1548/1548 [==============================] - 0s 62us/step - loss: 18.8458 - mean_absolute_error: 2.4909 - acc: 0.1667 - val_loss: 32.9384 - val_mean_absolute_error: 2.7809 - val_acc: 0.1366\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 28.55927\n",
      "Epoch 242/500\n",
      "1548/1548 [==============================] - 0s 65us/step - loss: 19.2494 - mean_absolute_error: 2.5685 - acc: 0.1550 - val_loss: 27.6939 - val_mean_absolute_error: 2.7616 - val_acc: 0.1366\n",
      "\n",
      "Epoch 00242: val_loss improved from 28.55927 to 27.69386, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 243/500\n",
      "1548/1548 [==============================] - 0s 62us/step - loss: 18.7501 - mean_absolute_error: 2.4725 - acc: 0.1699 - val_loss: 31.4527 - val_mean_absolute_error: 2.7224 - val_acc: 0.1495\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 27.69386\n",
      "Epoch 244/500\n",
      "1548/1548 [==============================] - 0s 92us/step - loss: 18.6738 - mean_absolute_error: 2.4775 - acc: 0.1621 - val_loss: 31.1062 - val_mean_absolute_error: 2.7895 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 27.69386\n",
      "Epoch 245/500\n",
      "1548/1548 [==============================] - 0s 102us/step - loss: 18.7453 - mean_absolute_error: 2.4954 - acc: 0.1563 - val_loss: 30.9829 - val_mean_absolute_error: 2.8224 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 27.69386\n",
      "Epoch 246/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 18.7818 - mean_absolute_error: 2.4933 - acc: 0.1602 - val_loss: 31.2454 - val_mean_absolute_error: 2.8035 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 27.69386\n",
      "Epoch 247/500\n",
      "1548/1548 [==============================] - 0s 71us/step - loss: 18.6460 - mean_absolute_error: 2.4818 - acc: 0.1615 - val_loss: 30.9401 - val_mean_absolute_error: 2.8094 - val_acc: 0.1263\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 27.69386\n",
      "Epoch 248/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 19.0359 - mean_absolute_error: 2.5448 - acc: 0.1557 - val_loss: 29.2686 - val_mean_absolute_error: 2.8133 - val_acc: 0.1134\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 27.69386\n",
      "Epoch 249/500\n",
      "1548/1548 [==============================] - 0s 69us/step - loss: 18.7415 - mean_absolute_error: 2.4824 - acc: 0.1628 - val_loss: 31.4154 - val_mean_absolute_error: 2.7677 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 27.69386\n",
      "Epoch 250/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 18.6019 - mean_absolute_error: 2.4768 - acc: 0.1602 - val_loss: 30.9114 - val_mean_absolute_error: 2.7905 - val_acc: 0.1340\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 27.69386\n",
      "Epoch 251/500\n",
      "1548/1548 [==============================] - 0s 74us/step - loss: 19.0816 - mean_absolute_error: 2.5503 - acc: 0.1615 - val_loss: 29.6451 - val_mean_absolute_error: 2.7868 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 27.69386\n",
      "Epoch 252/500\n",
      "1548/1548 [==============================] - 0s 116us/step - loss: 19.0268 - mean_absolute_error: 2.5353 - acc: 0.1583 - val_loss: 27.7494 - val_mean_absolute_error: 2.7500 - val_acc: 0.1340\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 27.69386\n",
      "Epoch 253/500\n",
      "1548/1548 [==============================] - 0s 87us/step - loss: 18.6775 - mean_absolute_error: 2.4675 - acc: 0.1615 - val_loss: 32.2661 - val_mean_absolute_error: 2.6806 - val_acc: 0.1778\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 27.69386\n",
      "Epoch 254/500\n",
      "1548/1548 [==============================] - 0s 79us/step - loss: 19.2232 - mean_absolute_error: 2.5548 - acc: 0.1576 - val_loss: 27.2024 - val_mean_absolute_error: 2.8338 - val_acc: 0.1443\n",
      "\n",
      "Epoch 00254: val_loss improved from 27.69386 to 27.20238, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 255/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 18.7673 - mean_absolute_error: 2.4913 - acc: 0.1621 - val_loss: 32.4362 - val_mean_absolute_error: 2.8125 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 27.20238\n",
      "Epoch 256/500\n",
      "1548/1548 [==============================] - 0s 65us/step - loss: 18.6426 - mean_absolute_error: 2.4867 - acc: 0.1570 - val_loss: 32.6628 - val_mean_absolute_error: 2.8115 - val_acc: 0.1263\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 27.20238\n",
      "Epoch 257/500\n",
      "1548/1548 [==============================] - 0s 86us/step - loss: 18.7948 - mean_absolute_error: 2.5198 - acc: 0.1460 - val_loss: 31.1781 - val_mean_absolute_error: 2.8980 - val_acc: 0.1186\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 27.20238\n",
      "Epoch 258/500\n",
      "1548/1548 [==============================] - 0s 89us/step - loss: 18.7630 - mean_absolute_error: 2.5149 - acc: 0.1589 - val_loss: 30.4405 - val_mean_absolute_error: 2.8553 - val_acc: 0.1160\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 27.20238\n",
      "Epoch 259/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 18.7246 - mean_absolute_error: 2.5079 - acc: 0.1589 - val_loss: 30.3143 - val_mean_absolute_error: 2.8534 - val_acc: 0.1186\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 27.20238\n",
      "Epoch 260/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 18.6984 - mean_absolute_error: 2.5049 - acc: 0.1621 - val_loss: 30.2883 - val_mean_absolute_error: 2.8478 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 27.20238\n",
      "Epoch 261/500\n",
      "1548/1548 [==============================] - 0s 99us/step - loss: 18.8232 - mean_absolute_error: 2.5282 - acc: 0.1609 - val_loss: 28.3558 - val_mean_absolute_error: 2.7730 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 27.20238\n",
      "Epoch 262/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 18.4405 - mean_absolute_error: 2.4594 - acc: 0.1641 - val_loss: 30.3511 - val_mean_absolute_error: 2.7898 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 27.20238\n",
      "Epoch 263/500\n",
      "1548/1548 [==============================] - 0s 58us/step - loss: 18.9225 - mean_absolute_error: 2.5402 - acc: 0.1596 - val_loss: 28.1709 - val_mean_absolute_error: 2.6393 - val_acc: 0.1856\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 27.20238\n",
      "Epoch 264/500\n",
      "1548/1548 [==============================] - 0s 64us/step - loss: 18.5388 - mean_absolute_error: 2.4654 - acc: 0.1705 - val_loss: 28.2887 - val_mean_absolute_error: 2.8416 - val_acc: 0.1237\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 27.20238\n",
      "Epoch 265/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 18.5954 - mean_absolute_error: 2.4852 - acc: 0.1602 - val_loss: 30.9745 - val_mean_absolute_error: 2.7875 - val_acc: 0.1237\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 27.20238\n",
      "Epoch 266/500\n",
      "1548/1548 [==============================] - 0s 106us/step - loss: 19.0599 - mean_absolute_error: 2.5605 - acc: 0.1654 - val_loss: 29.2587 - val_mean_absolute_error: 2.7740 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 27.20238\n",
      "Epoch 267/500\n",
      "1548/1548 [==============================] - 0s 93us/step - loss: 18.9031 - mean_absolute_error: 2.5184 - acc: 0.1680 - val_loss: 26.8535 - val_mean_absolute_error: 2.6136 - val_acc: 0.1985\n",
      "\n",
      "Epoch 00267: val_loss improved from 27.20238 to 26.85350, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 268/500\n",
      "1548/1548 [==============================] - 0s 87us/step - loss: 18.5785 - mean_absolute_error: 2.4540 - acc: 0.1654 - val_loss: 30.0214 - val_mean_absolute_error: 2.7847 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 26.85350\n",
      "Epoch 269/500\n",
      "1548/1548 [==============================] - 0s 98us/step - loss: 18.7345 - mean_absolute_error: 2.4801 - acc: 0.1680 - val_loss: 32.5671 - val_mean_absolute_error: 2.7860 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 26.85350\n",
      "Epoch 270/500\n",
      "1548/1548 [==============================] - 0s 86us/step - loss: 18.6365 - mean_absolute_error: 2.4916 - acc: 0.1589 - val_loss: 32.4943 - val_mean_absolute_error: 2.7617 - val_acc: 0.1418\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 26.85350\n",
      "Epoch 271/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 19.1227 - mean_absolute_error: 2.5637 - acc: 0.1570 - val_loss: 26.8347 - val_mean_absolute_error: 2.8235 - val_acc: 0.1469\n",
      "\n",
      "Epoch 00271: val_loss improved from 26.85350 to 26.83473, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 272/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 18.5892 - mean_absolute_error: 2.4760 - acc: 0.1634 - val_loss: 31.5234 - val_mean_absolute_error: 2.8105 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 26.83473\n",
      "Epoch 273/500\n",
      "1548/1548 [==============================] - 0s 92us/step - loss: 18.4856 - mean_absolute_error: 2.4706 - acc: 0.1693 - val_loss: 32.0801 - val_mean_absolute_error: 2.7905 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 26.83473\n",
      "Epoch 274/500\n",
      "1548/1548 [==============================] - 0s 73us/step - loss: 18.5607 - mean_absolute_error: 2.4937 - acc: 0.1596 - val_loss: 31.0350 - val_mean_absolute_error: 2.8327 - val_acc: 0.1237\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 26.83473\n",
      "Epoch 275/500\n",
      "1548/1548 [==============================] - 0s 96us/step - loss: 18.5355 - mean_absolute_error: 2.4927 - acc: 0.1583 - val_loss: 30.6156 - val_mean_absolute_error: 2.8347 - val_acc: 0.1237\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 26.83473\n",
      "Epoch 276/500\n",
      "1548/1548 [==============================] - 0s 104us/step - loss: 18.5824 - mean_absolute_error: 2.4875 - acc: 0.1628 - val_loss: 30.9889 - val_mean_absolute_error: 2.8020 - val_acc: 0.1263\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 26.83473\n",
      "Epoch 277/500\n",
      "1548/1548 [==============================] - 0s 79us/step - loss: 18.3885 - mean_absolute_error: 2.4659 - acc: 0.1654 - val_loss: 30.5371 - val_mean_absolute_error: 2.8045 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 26.83473\n",
      "Epoch 278/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 18.6607 - mean_absolute_error: 2.5034 - acc: 0.1654 - val_loss: 29.8479 - val_mean_absolute_error: 2.8650 - val_acc: 0.1186\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 26.83473\n",
      "Epoch 279/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 0s 95us/step - loss: 18.4745 - mean_absolute_error: 2.4860 - acc: 0.1583 - val_loss: 30.3497 - val_mean_absolute_error: 2.8156 - val_acc: 0.1263\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 26.83473\n",
      "Epoch 280/500\n",
      "1548/1548 [==============================] - 0s 98us/step - loss: 18.5507 - mean_absolute_error: 2.4861 - acc: 0.1641 - val_loss: 30.7661 - val_mean_absolute_error: 2.8005 - val_acc: 0.1237\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 26.83473\n",
      "Epoch 281/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 18.5121 - mean_absolute_error: 2.4937 - acc: 0.1621 - val_loss: 28.9859 - val_mean_absolute_error: 2.8989 - val_acc: 0.1160\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 26.83473\n",
      "Epoch 282/500\n",
      "1548/1548 [==============================] - 0s 86us/step - loss: 18.6098 - mean_absolute_error: 2.4997 - acc: 0.1615 - val_loss: 30.4652 - val_mean_absolute_error: 2.7766 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 26.83473\n",
      "Epoch 283/500\n",
      "1548/1548 [==============================] - 0s 106us/step - loss: 18.3573 - mean_absolute_error: 2.4658 - acc: 0.1596 - val_loss: 30.2526 - val_mean_absolute_error: 2.8161 - val_acc: 0.1237\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 26.83473\n",
      "Epoch 284/500\n",
      "1548/1548 [==============================] - 0s 96us/step - loss: 18.5080 - mean_absolute_error: 2.4834 - acc: 0.1621 - val_loss: 30.5319 - val_mean_absolute_error: 2.8013 - val_acc: 0.1263\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 26.83473\n",
      "Epoch 285/500\n",
      "1548/1548 [==============================] - 0s 80us/step - loss: 18.6842 - mean_absolute_error: 2.5185 - acc: 0.1660 - val_loss: 28.7879 - val_mean_absolute_error: 2.7998 - val_acc: 0.1134\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 26.83473\n",
      "Epoch 286/500\n",
      "1548/1548 [==============================] - 0s 74us/step - loss: 18.7422 - mean_absolute_error: 2.5201 - acc: 0.1589 - val_loss: 27.3314 - val_mean_absolute_error: 2.6620 - val_acc: 0.1649\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 26.83473\n",
      "Epoch 287/500\n",
      "1548/1548 [==============================] - 0s 97us/step - loss: 18.6901 - mean_absolute_error: 2.4972 - acc: 0.1628 - val_loss: 26.4911 - val_mean_absolute_error: 2.7086 - val_acc: 0.1727\n",
      "\n",
      "Epoch 00287: val_loss improved from 26.83473 to 26.49106, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 288/500\n",
      "1548/1548 [==============================] - 0s 103us/step - loss: 18.3811 - mean_absolute_error: 2.4400 - acc: 0.1680 - val_loss: 31.4101 - val_mean_absolute_error: 2.7505 - val_acc: 0.1418\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 26.49106\n",
      "Epoch 289/500\n",
      "1548/1548 [==============================] - 0s 89us/step - loss: 18.4544 - mean_absolute_error: 2.4825 - acc: 0.1570 - val_loss: 30.7129 - val_mean_absolute_error: 2.8263 - val_acc: 0.1237\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 26.49106\n",
      "Epoch 290/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 18.4287 - mean_absolute_error: 2.4844 - acc: 0.1641 - val_loss: 30.4504 - val_mean_absolute_error: 2.8350 - val_acc: 0.1186\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 26.49106\n",
      "Epoch 291/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 18.4487 - mean_absolute_error: 2.4788 - acc: 0.1699 - val_loss: 30.7411 - val_mean_absolute_error: 2.7971 - val_acc: 0.1237\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 26.49106\n",
      "Epoch 292/500\n",
      "1548/1548 [==============================] - 0s 93us/step - loss: 18.2946 - mean_absolute_error: 2.4588 - acc: 0.1718 - val_loss: 30.4663 - val_mean_absolute_error: 2.8067 - val_acc: 0.1263\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 26.49106\n",
      "Epoch 293/500\n",
      "1548/1548 [==============================] - 0s 92us/step - loss: 18.7345 - mean_absolute_error: 2.5355 - acc: 0.1615 - val_loss: 28.0934 - val_mean_absolute_error: 2.6949 - val_acc: 0.1495\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 26.49106\n",
      "Epoch 294/500\n",
      "1548/1548 [==============================] - 0s 67us/step - loss: 18.1931 - mean_absolute_error: 2.4316 - acc: 0.1667 - val_loss: 29.8129 - val_mean_absolute_error: 2.7909 - val_acc: 0.1237\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 26.49106\n",
      "Epoch 295/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 18.3980 - mean_absolute_error: 2.4707 - acc: 0.1602 - val_loss: 31.2575 - val_mean_absolute_error: 2.7913 - val_acc: 0.1263\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 26.49106\n",
      "Epoch 296/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 18.3195 - mean_absolute_error: 2.4704 - acc: 0.1654 - val_loss: 30.4846 - val_mean_absolute_error: 2.8179 - val_acc: 0.1237\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 26.49106\n",
      "Epoch 297/500\n",
      "1548/1548 [==============================] - 0s 88us/step - loss: 18.4131 - mean_absolute_error: 2.4858 - acc: 0.1641 - val_loss: 30.5645 - val_mean_absolute_error: 2.8354 - val_acc: 0.1237\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 26.49106\n",
      "Epoch 298/500\n",
      "1548/1548 [==============================] - 0s 92us/step - loss: 18.3099 - mean_absolute_error: 2.4704 - acc: 0.1673 - val_loss: 30.3139 - val_mean_absolute_error: 2.8239 - val_acc: 0.1237\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 26.49106\n",
      "Epoch 299/500\n",
      "1548/1548 [==============================] - 0s 80us/step - loss: 18.5470 - mean_absolute_error: 2.5125 - acc: 0.1609 - val_loss: 29.2506 - val_mean_absolute_error: 2.9122 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 26.49106\n",
      "Epoch 300/500\n",
      "1548/1548 [==============================] - 0s 80us/step - loss: 18.5478 - mean_absolute_error: 2.5166 - acc: 0.1557 - val_loss: 30.1898 - val_mean_absolute_error: 2.8593 - val_acc: 0.1160\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 26.49106\n",
      "Epoch 301/500\n",
      "1548/1548 [==============================] - 0s 73us/step - loss: 18.4037 - mean_absolute_error: 2.4896 - acc: 0.1589 - val_loss: 30.4232 - val_mean_absolute_error: 2.8683 - val_acc: 0.1134\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 26.49106\n",
      "Epoch 302/500\n",
      "1548/1548 [==============================] - 0s 74us/step - loss: 18.3848 - mean_absolute_error: 2.4905 - acc: 0.1634 - val_loss: 29.4828 - val_mean_absolute_error: 2.8870 - val_acc: 0.1108\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 26.49106\n",
      "Epoch 303/500\n",
      "1548/1548 [==============================] - 0s 100us/step - loss: 18.5074 - mean_absolute_error: 2.5085 - acc: 0.1602 - val_loss: 30.0442 - val_mean_absolute_error: 2.8592 - val_acc: 0.1186\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 26.49106\n",
      "Epoch 304/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 18.4587 - mean_absolute_error: 2.5005 - acc: 0.1628 - val_loss: 29.7505 - val_mean_absolute_error: 2.8886 - val_acc: 0.1160\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 26.49106\n",
      "Epoch 305/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 18.4688 - mean_absolute_error: 2.5081 - acc: 0.1570 - val_loss: 29.0357 - val_mean_absolute_error: 2.9241 - val_acc: 0.1160\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 26.49106\n",
      "Epoch 306/500\n",
      "1548/1548 [==============================] - 0s 101us/step - loss: 18.4936 - mean_absolute_error: 2.5104 - acc: 0.1576 - val_loss: 29.8873 - val_mean_absolute_error: 2.8568 - val_acc: 0.1186\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 26.49106\n",
      "Epoch 307/500\n",
      "1548/1548 [==============================] - 0s 112us/step - loss: 18.4911 - mean_absolute_error: 2.5050 - acc: 0.1602 - val_loss: 29.2646 - val_mean_absolute_error: 2.9142 - val_acc: 0.1160\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 26.49106\n",
      "Epoch 308/500\n",
      "1548/1548 [==============================] - 0s 75us/step - loss: 18.4502 - mean_absolute_error: 2.5022 - acc: 0.1621 - val_loss: 29.8931 - val_mean_absolute_error: 2.8543 - val_acc: 0.1237\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 26.49106\n",
      "Epoch 309/500\n",
      "1548/1548 [==============================] - 0s 73us/step - loss: 18.5023 - mean_absolute_error: 2.5072 - acc: 0.1570 - val_loss: 29.1155 - val_mean_absolute_error: 2.9270 - val_acc: 0.1186\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 26.49106\n",
      "Epoch 310/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 18.4491 - mean_absolute_error: 2.5035 - acc: 0.1621 - val_loss: 29.9619 - val_mean_absolute_error: 2.8525 - val_acc: 0.1237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00310: val_loss did not improve from 26.49106\n",
      "Epoch 311/500\n",
      "1548/1548 [==============================] - 0s 91us/step - loss: 18.6436 - mean_absolute_error: 2.5276 - acc: 0.1641 - val_loss: 27.7575 - val_mean_absolute_error: 2.6877 - val_acc: 0.1624\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 26.49106\n",
      "Epoch 312/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 18.5468 - mean_absolute_error: 2.4815 - acc: 0.1725 - val_loss: 26.4839 - val_mean_absolute_error: 2.6587 - val_acc: 0.1675\n",
      "\n",
      "Epoch 00312: val_loss improved from 26.49106 to 26.48388, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 313/500\n",
      "1548/1548 [==============================] - 0s 82us/step - loss: 18.9132 - mean_absolute_error: 2.5041 - acc: 0.1634 - val_loss: 26.0812 - val_mean_absolute_error: 2.7376 - val_acc: 0.1675\n",
      "\n",
      "Epoch 00313: val_loss improved from 26.48388 to 26.08119, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 314/500\n",
      "1548/1548 [==============================] - 0s 79us/step - loss: 18.3258 - mean_absolute_error: 2.4488 - acc: 0.1731 - val_loss: 31.5123 - val_mean_absolute_error: 2.7715 - val_acc: 0.1366\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 26.08119\n",
      "Epoch 315/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 18.2567 - mean_absolute_error: 2.4543 - acc: 0.1751 - val_loss: 31.4698 - val_mean_absolute_error: 2.7856 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 26.08119\n",
      "Epoch 316/500\n",
      "1548/1548 [==============================] - 0s 68us/step - loss: 18.2957 - mean_absolute_error: 2.4711 - acc: 0.1680 - val_loss: 30.9159 - val_mean_absolute_error: 2.8224 - val_acc: 0.1263\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 26.08119\n",
      "Epoch 317/500\n",
      "1548/1548 [==============================] - 0s 73us/step - loss: 18.5983 - mean_absolute_error: 2.5268 - acc: 0.1647 - val_loss: 27.8233 - val_mean_absolute_error: 2.8665 - val_acc: 0.1160\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 26.08119\n",
      "Epoch 318/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 18.1300 - mean_absolute_error: 2.4438 - acc: 0.1680 - val_loss: 30.7763 - val_mean_absolute_error: 2.7640 - val_acc: 0.1340\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 26.08119\n",
      "Epoch 319/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 18.2655 - mean_absolute_error: 2.4677 - acc: 0.1634 - val_loss: 30.7045 - val_mean_absolute_error: 2.8307 - val_acc: 0.1263\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 26.08119\n",
      "Epoch 320/500\n",
      "1548/1548 [==============================] - 0s 68us/step - loss: 18.6063 - mean_absolute_error: 2.5298 - acc: 0.1615 - val_loss: 27.8055 - val_mean_absolute_error: 2.8789 - val_acc: 0.1160\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 26.08119\n",
      "Epoch 321/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 18.1305 - mean_absolute_error: 2.4458 - acc: 0.1654 - val_loss: 30.8187 - val_mean_absolute_error: 2.7649 - val_acc: 0.1392\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 26.08119\n",
      "Epoch 322/500\n",
      "1548/1548 [==============================] - 0s 74us/step - loss: 18.2418 - mean_absolute_error: 2.4639 - acc: 0.1654 - val_loss: 30.8400 - val_mean_absolute_error: 2.8240 - val_acc: 0.1263\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 26.08119\n",
      "Epoch 323/500\n",
      "1548/1548 [==============================] - 0s 79us/step - loss: 18.3022 - mean_absolute_error: 2.4819 - acc: 0.1744 - val_loss: 29.6793 - val_mean_absolute_error: 2.8821 - val_acc: 0.1082\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 26.08119\n",
      "Epoch 324/500\n",
      "1548/1548 [==============================] - 0s 78us/step - loss: 18.3258 - mean_absolute_error: 2.4836 - acc: 0.1654 - val_loss: 30.1426 - val_mean_absolute_error: 2.8567 - val_acc: 0.1237\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 26.08119\n",
      "Epoch 325/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 18.2285 - mean_absolute_error: 2.4689 - acc: 0.1757 - val_loss: 30.0914 - val_mean_absolute_error: 2.8273 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 26.08119\n",
      "Epoch 326/500\n",
      "1548/1548 [==============================] - 0s 81us/step - loss: 18.2614 - mean_absolute_error: 2.4696 - acc: 0.1718 - val_loss: 30.4731 - val_mean_absolute_error: 2.8260 - val_acc: 0.1263\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 26.08119\n",
      "Epoch 327/500\n",
      "1548/1548 [==============================] - ETA: 0s - loss: 18.8222 - mean_absolute_error: 2.4889 - acc: 0.17 - 0s 82us/step - loss: 18.1728 - mean_absolute_error: 2.4576 - acc: 0.1783 - val_loss: 30.5164 - val_mean_absolute_error: 2.8372 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 26.08119\n",
      "Epoch 328/500\n",
      "1548/1548 [==============================] - 0s 68us/step - loss: 18.1908 - mean_absolute_error: 2.4627 - acc: 0.1744 - val_loss: 30.5372 - val_mean_absolute_error: 2.8335 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 26.08119\n",
      "Epoch 329/500\n",
      "1548/1548 [==============================] - 0s 60us/step - loss: 18.4400 - mean_absolute_error: 2.5092 - acc: 0.1667 - val_loss: 27.1356 - val_mean_absolute_error: 2.8310 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 26.08119\n",
      "Epoch 330/500\n",
      "1548/1548 [==============================] - 0s 61us/step - loss: 18.0381 - mean_absolute_error: 2.4339 - acc: 0.1680 - val_loss: 30.5892 - val_mean_absolute_error: 2.7775 - val_acc: 0.1263\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 26.08119\n",
      "Epoch 331/500\n",
      "1548/1548 [==============================] - 0s 73us/step - loss: 18.2710 - mean_absolute_error: 2.4786 - acc: 0.1686 - val_loss: 29.6737 - val_mean_absolute_error: 2.8862 - val_acc: 0.1082\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 26.08119\n",
      "Epoch 332/500\n",
      "1548/1548 [==============================] - 0s 63us/step - loss: 18.2854 - mean_absolute_error: 2.4809 - acc: 0.1699 - val_loss: 30.0383 - val_mean_absolute_error: 2.8326 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 26.08119\n",
      "Epoch 333/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 18.2430 - mean_absolute_error: 2.4697 - acc: 0.1712 - val_loss: 30.4863 - val_mean_absolute_error: 2.8574 - val_acc: 0.1263\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 26.08119\n",
      "Epoch 334/500\n",
      "1548/1548 [==============================] - 0s 74us/step - loss: 18.1324 - mean_absolute_error: 2.4556 - acc: 0.1783 - val_loss: 30.5349 - val_mean_absolute_error: 2.8137 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 26.08119\n",
      "Epoch 335/500\n",
      "1548/1548 [==============================] - 0s 65us/step - loss: 18.3026 - mean_absolute_error: 2.4874 - acc: 0.1705 - val_loss: 28.8419 - val_mean_absolute_error: 2.9303 - val_acc: 0.1108\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 26.08119\n",
      "Epoch 336/500\n",
      "1548/1548 [==============================] - 0s 78us/step - loss: 18.3543 - mean_absolute_error: 2.4966 - acc: 0.1609 - val_loss: 29.8883 - val_mean_absolute_error: 2.8713 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 26.08119\n",
      "Epoch 337/500\n",
      "1548/1548 [==============================] - 0s 56us/step - loss: 18.1959 - mean_absolute_error: 2.4711 - acc: 0.1718 - val_loss: 29.7270 - val_mean_absolute_error: 2.8679 - val_acc: 0.1186\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 26.08119\n",
      "Epoch 338/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 18.2278 - mean_absolute_error: 2.4751 - acc: 0.1680 - val_loss: 29.7742 - val_mean_absolute_error: 2.8666 - val_acc: 0.1237\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 26.08119\n",
      "Epoch 339/500\n",
      "1548/1548 [==============================] - 0s 92us/step - loss: 18.1856 - mean_absolute_error: 2.4655 - acc: 0.1680 - val_loss: 30.2288 - val_mean_absolute_error: 2.8358 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 26.08119\n",
      "Epoch 340/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 18.1122 - mean_absolute_error: 2.4514 - acc: 0.1783 - val_loss: 30.1292 - val_mean_absolute_error: 2.7996 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 26.08119\n",
      "Epoch 341/500\n",
      "1548/1548 [==============================] - 0s 76us/step - loss: 18.4461 - mean_absolute_error: 2.5086 - acc: 0.1757 - val_loss: 27.1622 - val_mean_absolute_error: 2.7887 - val_acc: 0.1340\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 26.08119\n",
      "Epoch 342/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 0s 77us/step - loss: 18.0277 - mean_absolute_error: 2.4393 - acc: 0.1705 - val_loss: 29.8982 - val_mean_absolute_error: 2.8062 - val_acc: 0.1366\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 26.08119\n",
      "Epoch 343/500\n",
      "1548/1548 [==============================] - 0s 86us/step - loss: 18.1536 - mean_absolute_error: 2.4592 - acc: 0.1757 - val_loss: 29.9370 - val_mean_absolute_error: 2.8109 - val_acc: 0.1366\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 26.08119\n",
      "Epoch 344/500\n",
      "1548/1548 [==============================] - 0s 86us/step - loss: 18.1542 - mean_absolute_error: 2.4602 - acc: 0.1757 - val_loss: 30.0374 - val_mean_absolute_error: 2.8383 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 26.08119\n",
      "Epoch 345/500\n",
      "1548/1548 [==============================] - 0s 69us/step - loss: 18.0908 - mean_absolute_error: 2.4529 - acc: 0.1809 - val_loss: 29.9595 - val_mean_absolute_error: 2.8186 - val_acc: 0.1366\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 26.08119\n",
      "Epoch 346/500\n",
      "1548/1548 [==============================] - 0s 59us/step - loss: 18.1733 - mean_absolute_error: 2.4672 - acc: 0.1744 - val_loss: 30.4504 - val_mean_absolute_error: 2.8343 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 26.08119\n",
      "Epoch 347/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 18.1112 - mean_absolute_error: 2.4547 - acc: 0.1757 - val_loss: 30.3687 - val_mean_absolute_error: 2.8358 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 26.08119\n",
      "Epoch 348/500\n",
      "1548/1548 [==============================] - 0s 70us/step - loss: 18.0774 - mean_absolute_error: 2.4497 - acc: 0.1789 - val_loss: 30.2732 - val_mean_absolute_error: 2.8263 - val_acc: 0.1340\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 26.08119\n",
      "Epoch 349/500\n",
      "1548/1548 [==============================] - 0s 95us/step - loss: 18.0707 - mean_absolute_error: 2.4501 - acc: 0.1796 - val_loss: 30.3700 - val_mean_absolute_error: 2.8337 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 26.08119\n",
      "Epoch 350/500\n",
      "1548/1548 [==============================] - 0s 80us/step - loss: 18.0638 - mean_absolute_error: 2.4501 - acc: 0.1776 - val_loss: 30.3971 - val_mean_absolute_error: 2.8304 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 26.08119\n",
      "Epoch 351/500\n",
      "1548/1548 [==============================] - 0s 73us/step - loss: 18.0791 - mean_absolute_error: 2.4530 - acc: 0.1776 - val_loss: 30.2330 - val_mean_absolute_error: 2.8343 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 26.08119\n",
      "Epoch 352/500\n",
      "1548/1548 [==============================] - 0s 73us/step - loss: 18.0413 - mean_absolute_error: 2.4468 - acc: 0.1802 - val_loss: 30.3703 - val_mean_absolute_error: 2.8261 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 26.08119\n",
      "Epoch 353/500\n",
      "1548/1548 [==============================] - 0s 63us/step - loss: 18.0328 - mean_absolute_error: 2.4461 - acc: 0.1815 - val_loss: 30.6137 - val_mean_absolute_error: 2.8235 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 26.08119\n",
      "Epoch 354/500\n",
      "1548/1548 [==============================] - 0s 61us/step - loss: 18.0318 - mean_absolute_error: 2.4466 - acc: 0.1796 - val_loss: 30.5390 - val_mean_absolute_error: 2.8288 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 26.08119\n",
      "Epoch 355/500\n",
      "1548/1548 [==============================] - 0s 68us/step - loss: 18.3096 - mean_absolute_error: 2.4996 - acc: 0.1686 - val_loss: 26.5792 - val_mean_absolute_error: 2.7959 - val_acc: 0.1392\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 26.08119\n",
      "Epoch 356/500\n",
      "1548/1548 [==============================] - 0s 107us/step - loss: 18.2447 - mean_absolute_error: 2.4833 - acc: 0.1660 - val_loss: 27.3681 - val_mean_absolute_error: 2.8791 - val_acc: 0.1186\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 26.08119\n",
      "Epoch 357/500\n",
      "1548/1548 [==============================] - 0s 85us/step - loss: 18.0721 - mean_absolute_error: 2.4476 - acc: 0.1757 - val_loss: 30.1665 - val_mean_absolute_error: 2.7696 - val_acc: 0.1314\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 26.08119\n",
      "Epoch 358/500\n",
      "1548/1548 [==============================] - 0s 74us/step - loss: 18.0619 - mean_absolute_error: 2.4551 - acc: 0.1693 - val_loss: 30.0738 - val_mean_absolute_error: 2.8765 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 26.08119\n",
      "Epoch 359/500\n",
      "1548/1548 [==============================] - 0s 77us/step - loss: 18.1696 - mean_absolute_error: 2.4719 - acc: 0.1660 - val_loss: 31.0165 - val_mean_absolute_error: 2.8393 - val_acc: 0.1340\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 26.08119\n",
      "Epoch 360/500\n",
      "1548/1548 [==============================] - 0s 74us/step - loss: 18.0106 - mean_absolute_error: 2.4444 - acc: 0.1744 - val_loss: 31.4469 - val_mean_absolute_error: 2.8301 - val_acc: 0.1263\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 26.08119\n",
      "Epoch 361/500\n",
      "1548/1548 [==============================] - 0s 90us/step - loss: 18.0514 - mean_absolute_error: 2.4545 - acc: 0.1744 - val_loss: 31.1822 - val_mean_absolute_error: 2.8401 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 26.08119\n",
      "Epoch 362/500\n",
      "1548/1548 [==============================] - 0s 99us/step - loss: 18.2767 - mean_absolute_error: 2.4992 - acc: 0.1673 - val_loss: 27.9404 - val_mean_absolute_error: 2.9426 - val_acc: 0.1108\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 26.08119\n",
      "Epoch 363/500\n",
      "1548/1548 [==============================] - 0s 72us/step - loss: 18.1030 - mean_absolute_error: 2.4610 - acc: 0.1667 - val_loss: 30.5814 - val_mean_absolute_error: 2.7919 - val_acc: 0.1289\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 26.08119\n",
      "Epoch 00363: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1a2aab17f0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN_baseline(X, y_VFI, 'VFI')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
