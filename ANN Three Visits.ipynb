{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# pd.reset_option('display.max_rows')\n",
    "\n",
    "\n",
    "# Importing the dataset\n",
    "X_dataset = pd.read_csv('X_delta_visit_ones.csv')\n",
    "Y_RNFL = pd.read_csv('Y_visit_threes_RNFL.csv')\n",
    "Y_GCA = pd.read_csv('Y_visit_threes_GCA.csv')\n",
    "Y_VFI = pd.read_csv('Y_visit_threes_VFI.csv')\n",
    "Y_MD = pd.read_csv('Y_visit_threes_MD.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#label encoding dx: 3 total\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X_dataset.iloc[:, 1] = labelencoder_X_1.fit_transform(X_dataset.iloc[:, 1])\n",
    "\n",
    "#label encoding gender: 2 total\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X_dataset.iloc[:, 2] = labelencoder_X_2.fit_transform(X_dataset.iloc[:, 2])\n",
    "\n",
    "#label encoding race: 3 total\n",
    "labelencoder_X_3 = LabelEncoder()\n",
    "X_dataset.iloc[:, 3] = labelencoder_X_3.fit_transform(X_dataset.iloc[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2274\n",
      "1     951\n",
      "2      13\n",
      "Name: primary_dx, dtype: int64\n",
      "0    1877\n",
      "1    1361\n",
      "Name: gender, dtype: int64\n",
      "2    2462\n",
      "1     618\n",
      "0     158\n",
      "Name: race, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_dataset['primary_dx'].value_counts())\n",
    "print(X_dataset['gender'].value_counts())\n",
    "print(X_dataset['race'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = pd.get_dummies(X_dataset, columns=['primary_dx', 'race'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 gender\n",
       "1           avg_cd_ratio\n",
       "2            gca_average\n",
       "3            gca_tempsup\n",
       "4                gca_sup\n",
       "5             gca_nassup\n",
       "6             gca_nasinf\n",
       "7                gca_inf\n",
       "8            gca_tempinf\n",
       "9           rnfl_average\n",
       "10          rnfl_tempsup\n",
       "11              rnfl_sup\n",
       "12           rnfl_nassup\n",
       "13           rnfl_nasinf\n",
       "14              rnfl_inf\n",
       "15          rnfl_tempinf\n",
       "16                    md\n",
       "17                  p_md\n",
       "18                   psd\n",
       "19                 p_psd\n",
       "20                   vfi\n",
       "21                   age\n",
       "22    avg_cd_ratio_delta\n",
       "23     gca_average_delta\n",
       "24     gca_tempsup_delta\n",
       "25         gca_sup_delta\n",
       "26      gca_nassup_delta\n",
       "27      gca_nasinf_delta\n",
       "28         gca_inf_delta\n",
       "29     gca_tempinf_delta\n",
       "30    rnfl_average_delta\n",
       "31    rnfl_tempsup_delta\n",
       "32        rnfl_sup_delta\n",
       "33     rnfl_nassup_delta\n",
       "34     rnfl_nasinf_delta\n",
       "35        rnfl_inf_delta\n",
       "36    rnfl_tempinf_delta\n",
       "37              md_delta\n",
       "38            p_md_delta\n",
       "39             psd_delta\n",
       "40           p_psd_delta\n",
       "41             vfi_delta\n",
       "42                    GS\n",
       "43                  OHTN\n",
       "44                 black\n",
       "45                 white\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#primary_dx_1 = glaucoma suspect\n",
    "#primary_dx_2 = OHTN\n",
    "#race_1 = black\n",
    "#race_2 = white\n",
    "\n",
    "X_dataset.rename(columns={'race_1':'black', 'race_2':'white', 'primary_dx_1':'GS','primary_dx_2':'OHTN'}, inplace=True)\n",
    "\n",
    "X_dataset = X_dataset.iloc[:, 1:]\n",
    "Y_RNFL = Y_RNFL.iloc[:, 1:]\n",
    "Y_VFI = Y_VFI.iloc[:, 1:]\n",
    "Y_MD = Y_MD.iloc[:, 1:]\n",
    "Y_GCA = Y_GCA.iloc[:, 1:]\n",
    "\n",
    "listing = pd.Series(X_dataset.columns.values)\n",
    "listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Splitting the dataset into the Training set and Test set\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train_RNFL, X_test_RNFL, y_train_RNFL, y_test_RNFL = train_test_split(X_dataset, Y_RNFL, test_size = 0.2, random_state = 200)\n",
    "# X_train_VFI, X_test_VFI, y_train_VFI, y_test_VFI = train_test_split(X_dataset, Y_VFI, test_size = 0.2, random_state = 200)\n",
    "# X_train_MD, X_test_MD, y_train_MD, y_test_MD = train_test_split(X_dataset, Y_MD, test_size = 0.2, random_state = 200)\n",
    "# X_train_GCA, X_test_GCA, y_train_GCA, y_test_GCA = train_test_split(X_dataset, Y_GCA, test_size = 0.2, random_state = 200)\n",
    "\n",
    "# # Feature Scaling\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc_RNFL = StandardScaler()\n",
    "# X_train_RNFL = sc_RNFL.fit_transform(X_train_RNFL)\n",
    "# X_test_RNFL = sc_RNFL.transform(X_test_RNFL)\n",
    "\n",
    "# sc_VFI = StandardScaler()\n",
    "# X_train_VFI = sc_VFI.fit_transform(X_train_VFI)\n",
    "# X_test_VFI = sc_VFI.transform(X_test_VFI)\n",
    "\n",
    "# sc_MD = StandardScaler()\n",
    "# X_train_MD = sc_MD.fit_transform(X_train_MD)\n",
    "# X_test_MD = sc_MD.transform(X_test_MD)\n",
    "\n",
    "# sc_GCA = StandardScaler()\n",
    "# X_train_GCA = sc_GCA.fit_transform(X_train_GCA)\n",
    "# X_test_GCA = sc_GCA.transform(X_test_GCA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_model():\n",
    "    # Initialising the ANN\n",
    "    classifier = Sequential()\n",
    "    \n",
    "    #Batch normalization\n",
    "#     classifier.add(BatchNormalization(axis = 1))\n",
    "    \n",
    "    # Adding the input layer and the first hidden layer\n",
    "    classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'linear', input_dim = 46))\n",
    "    classifier.add(LeakyReLU(alpha = 0.001))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'linear'))\n",
    "    classifier.add(LeakyReLU(alpha = 0.001))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'linear'))\n",
    "    classifier.add(LeakyReLU(alpha = 0.001))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'linear'))\n",
    "    classifier.add(LeakyReLU(alpha = 0.001))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'linear'))\n",
    "    classifier.add(LeakyReLU(alpha = 0.001))\n",
    "\n",
    "    #dropout layer\n",
    "    classifier.add(Dropout(0.2))\n",
    "    \n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'linear'))\n",
    "    classifier.add(LeakyReLU(alpha = 0.1))\n",
    "\n",
    "    # # Adding the input layer and the first hidden layer\n",
    "    # classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', input_dim = 46))\n",
    "\n",
    "    # # Adding the second hidden layer\n",
    "    # classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    # # Adding the third hidden layer\n",
    "    # classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    # # Adding the third hidden layer\n",
    "    # classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    # # # Adding the third hidden layer\n",
    "    # # classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    \n",
    "    # # # Adding the third hidden layer\n",
    "    # # classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    # # # Adding the third hidden layer\n",
    "    # # classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    # # Adding the third hidden layer\n",
    "    # classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    # # Adding the output layer\n",
    "    # classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    \n",
    "    # Compiling the ANN\n",
    "    classifier.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['MAE', 'accuracy'])\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "def ANN_baseline(X, y, name):\n",
    "#     scaler = MinMaxScaler()\n",
    "#     X = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 200)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 200)\n",
    "    y_train = y_train.ravel()\n",
    "    y_test = y_test.ravel()\n",
    "    y_val = y_val.ravel()\n",
    "    model = ann_model()\n",
    "\n",
    "    weight_path=\"ANN_Interval_best_{}.hdf5\".format(name)\n",
    "    checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "    callbacks_list = [checkpoint, early_stop]\n",
    "        \n",
    "    #fit the model\n",
    "    history = model.fit(X_train, y_train, epochs=500, validation_data=(X_val, y_val), shuffle=False, callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "    # plot train and validation loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model train vs validation loss for {}'.format(name))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "#     plt.ylim(top = y_limit)\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.savefig('loss_plot_{}.png'.format(name), dpi = 300)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    model.load_weights(weight_path)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_pred = y_pred.tolist()\n",
    "  \n",
    "    dictionary_DF = {'predicted':y_pred, 'actual':y_test}\n",
    "    data = pd.DataFrame(dictionary_DF)\n",
    "    data.to_csv('Predicted_vs_Actual_of_{}'.format(name))\n",
    "    \n",
    "    mean_absolute_error = abs(data['predicted']-data['actual'])\n",
    "    mean_absolute_error = mean_absolute_error.describe()\n",
    "    mean_absolute_error.to_csv('MAE_of_{}_Predicted_vs_Actual'.format(name))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3238, 46)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X_dataset)\n",
    "y_MD = np.array(Y_MD)\n",
    "y_GCA = np.array(Y_GCA)\n",
    "y_VFI = np.array(Y_VFI)\n",
    "y_RNFL = np.array(Y_RNFL)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN for RNFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2072 samples, validate on 518 samples\n",
      "Epoch 1/500\n",
      "2072/2072 [==============================] - 1s 320us/step - loss: 0.3083 - mean_absolute_error: 0.4406 - acc: 9.6525e-04 - val_loss: 0.1394 - val_mean_absolute_error: 0.3029 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13940, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 2/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 0.1271 - mean_absolute_error: 0.2929 - acc: 9.6525e-04 - val_loss: 0.1062 - val_mean_absolute_error: 0.2620 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13940 to 0.10615, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 3/500\n",
      "2072/2072 [==============================] - 0s 66us/step - loss: 0.0918 - mean_absolute_error: 0.2376 - acc: 9.6525e-04 - val_loss: 0.0605 - val_mean_absolute_error: 0.1784 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.10615 to 0.06045, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 4/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 0.0635 - mean_absolute_error: 0.1843 - acc: 9.6525e-04 - val_loss: 0.0549 - val_mean_absolute_error: 0.1707 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.06045 to 0.05490, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 5/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 0.0599 - mean_absolute_error: 0.1793 - acc: 9.6525e-04 - val_loss: 0.0532 - val_mean_absolute_error: 0.1675 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.05490 to 0.05315, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 6/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 0.0579 - mean_absolute_error: 0.1765 - acc: 9.6525e-04 - val_loss: 0.0521 - val_mean_absolute_error: 0.1658 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.05315 to 0.05214, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 7/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 0.0570 - mean_absolute_error: 0.1755 - acc: 9.6525e-04 - val_loss: 0.0522 - val_mean_absolute_error: 0.1667 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05214\n",
      "Epoch 8/500\n",
      "2072/2072 [==============================] - 0s 55us/step - loss: 0.0559 - mean_absolute_error: 0.1737 - acc: 9.6525e-04 - val_loss: 0.0523 - val_mean_absolute_error: 0.1676 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05214\n",
      "Epoch 9/500\n",
      "2072/2072 [==============================] - 0s 55us/step - loss: 0.0558 - mean_absolute_error: 0.1735 - acc: 9.6525e-04 - val_loss: 0.0530 - val_mean_absolute_error: 0.1699 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05214\n",
      "Epoch 10/500\n",
      "2072/2072 [==============================] - 0s 54us/step - loss: 0.0552 - mean_absolute_error: 0.1723 - acc: 9.6525e-04 - val_loss: 0.0540 - val_mean_absolute_error: 0.1725 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05214\n",
      "Epoch 11/500\n",
      "2072/2072 [==============================] - 0s 52us/step - loss: 0.0545 - mean_absolute_error: 0.1711 - acc: 9.6525e-04 - val_loss: 0.0541 - val_mean_absolute_error: 0.1727 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.05214\n",
      "Epoch 12/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 0.0541 - mean_absolute_error: 0.1704 - acc: 9.6525e-04 - val_loss: 0.0544 - val_mean_absolute_error: 0.1734 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.05214\n",
      "Epoch 13/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 0.0537 - mean_absolute_error: 0.1696 - acc: 9.6525e-04 - val_loss: 0.0542 - val_mean_absolute_error: 0.1732 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.05214\n",
      "Epoch 14/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 0.0535 - mean_absolute_error: 0.1691 - acc: 9.6525e-04 - val_loss: 0.0544 - val_mean_absolute_error: 0.1736 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.05214\n",
      "Epoch 15/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 0.0530 - mean_absolute_error: 0.1682 - acc: 9.6525e-04 - val_loss: 0.0541 - val_mean_absolute_error: 0.1730 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.05214\n",
      "Epoch 16/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 0.0529 - mean_absolute_error: 0.1680 - acc: 9.6525e-04 - val_loss: 0.0537 - val_mean_absolute_error: 0.1723 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.05214\n",
      "Epoch 17/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 0.0527 - mean_absolute_error: 0.1676 - acc: 9.6525e-04 - val_loss: 0.0535 - val_mean_absolute_error: 0.1717 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.05214\n",
      "Epoch 18/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 0.0523 - mean_absolute_error: 0.1670 - acc: 9.6525e-04 - val_loss: 0.0534 - val_mean_absolute_error: 0.1718 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.05214\n",
      "Epoch 19/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 0.0522 - mean_absolute_error: 0.1667 - acc: 9.6525e-04 - val_loss: 0.0528 - val_mean_absolute_error: 0.1705 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.05214\n",
      "Epoch 20/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 0.0519 - mean_absolute_error: 0.1662 - acc: 9.6525e-04 - val_loss: 0.0528 - val_mean_absolute_error: 0.1706 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.05214\n",
      "Epoch 21/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 0.0517 - mean_absolute_error: 0.1657 - acc: 9.6525e-04 - val_loss: 0.0525 - val_mean_absolute_error: 0.1700 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.05214\n",
      "Epoch 22/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 0.0515 - mean_absolute_error: 0.1652 - acc: 9.6525e-04 - val_loss: 0.0521 - val_mean_absolute_error: 0.1693 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.05214 to 0.05210, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 23/500\n",
      "2072/2072 [==============================] - 0s 64us/step - loss: 0.0513 - mean_absolute_error: 0.1648 - acc: 9.6525e-04 - val_loss: 0.0520 - val_mean_absolute_error: 0.1694 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.05210 to 0.05204, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 24/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 0.0512 - mean_absolute_error: 0.1647 - acc: 9.6525e-04 - val_loss: 0.0514 - val_mean_absolute_error: 0.1682 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.05204 to 0.05139, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 25/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 0.0509 - mean_absolute_error: 0.1641 - acc: 9.6525e-04 - val_loss: 0.0515 - val_mean_absolute_error: 0.1682 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.05139\n",
      "Epoch 26/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 0.0508 - mean_absolute_error: 0.1638 - acc: 9.6525e-04 - val_loss: 0.0510 - val_mean_absolute_error: 0.1674 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.05139 to 0.05104, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 27/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 0.0505 - mean_absolute_error: 0.1633 - acc: 9.6525e-04 - val_loss: 0.0508 - val_mean_absolute_error: 0.1668 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.05104 to 0.05079, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 28/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 0.0504 - mean_absolute_error: 0.1631 - acc: 9.6525e-04 - val_loss: 0.0502 - val_mean_absolute_error: 0.1658 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.05079 to 0.05021, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 29/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 0.0501 - mean_absolute_error: 0.1625 - acc: 9.6525e-04 - val_loss: 0.0499 - val_mean_absolute_error: 0.1651 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.05021 to 0.04988, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 30/500\n",
      "2072/2072 [==============================] - 0s 66us/step - loss: 0.0501 - mean_absolute_error: 0.1625 - acc: 9.6525e-04 - val_loss: 0.0497 - val_mean_absolute_error: 0.1650 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.04988 to 0.04973, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 31/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 0.0499 - mean_absolute_error: 0.1620 - acc: 9.6525e-04 - val_loss: 0.0484 - val_mean_absolute_error: 0.1621 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.04973 to 0.04840, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 32/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 0.0498 - mean_absolute_error: 0.1620 - acc: 9.6525e-04 - val_loss: 0.0480 - val_mean_absolute_error: 0.1609 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.04840 to 0.04800, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 33/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 0.0498 - mean_absolute_error: 0.1621 - acc: 9.6525e-04 - val_loss: 0.0489 - val_mean_absolute_error: 0.1654 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.04800\n",
      "Epoch 34/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 0.0495 - mean_absolute_error: 0.1614 - acc: 9.6525e-04 - val_loss: 0.0490 - val_mean_absolute_error: 0.1632 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.04800\n",
      "Epoch 35/500\n",
      "2072/2072 [==============================] - 0s 54us/step - loss: 0.0493 - mean_absolute_error: 0.1608 - acc: 9.6525e-04 - val_loss: 0.0485 - val_mean_absolute_error: 0.1623 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.04800\n",
      "Epoch 36/500\n",
      "2072/2072 [==============================] - 0s 90us/step - loss: 0.0492 - mean_absolute_error: 0.1605 - acc: 9.6525e-04 - val_loss: 0.0477 - val_mean_absolute_error: 0.1606 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.04800 to 0.04766, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 37/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 0.0489 - mean_absolute_error: 0.1601 - acc: 9.6525e-04 - val_loss: 0.0466 - val_mean_absolute_error: 0.1599 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.04766 to 0.04663, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 38/500\n",
      "2072/2072 [==============================] - 0s 91us/step - loss: 0.0489 - mean_absolute_error: 0.1601 - acc: 9.6525e-04 - val_loss: 0.0466 - val_mean_absolute_error: 0.1582 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.04663 to 0.04662, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 39/500\n",
      "2072/2072 [==============================] - 0s 89us/step - loss: 0.0488 - mean_absolute_error: 0.1599 - acc: 9.6525e-04 - val_loss: 0.0465 - val_mean_absolute_error: 0.1588 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.04662 to 0.04650, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 40/500\n",
      "2072/2072 [==============================] - 0s 93us/step - loss: 0.0486 - mean_absolute_error: 0.1596 - acc: 9.6525e-04 - val_loss: 0.0460 - val_mean_absolute_error: 0.1569 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.04650 to 0.04603, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 41/500\n",
      "2072/2072 [==============================] - 0s 95us/step - loss: 0.0484 - mean_absolute_error: 0.1592 - acc: 9.6525e-04 - val_loss: 0.0452 - val_mean_absolute_error: 0.1561 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.04603 to 0.04521, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 42/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 0.0483 - mean_absolute_error: 0.1590 - acc: 9.6525e-04 - val_loss: 0.0453 - val_mean_absolute_error: 0.1553 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.04521\n",
      "Epoch 43/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 0.0483 - mean_absolute_error: 0.1588 - acc: 9.6525e-04 - val_loss: 0.0449 - val_mean_absolute_error: 0.1548 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.04521 to 0.04491, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 44/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 0.0481 - mean_absolute_error: 0.1584 - acc: 9.6525e-04 - val_loss: 0.0446 - val_mean_absolute_error: 0.1546 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.04491 to 0.04463, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 45/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 0.0479 - mean_absolute_error: 0.1582 - acc: 9.6525e-04 - val_loss: 0.0442 - val_mean_absolute_error: 0.1537 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.04463 to 0.04417, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 46/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 0.0478 - mean_absolute_error: 0.1579 - acc: 9.6525e-04 - val_loss: 0.0441 - val_mean_absolute_error: 0.1535 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.04417 to 0.04409, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 47/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0476 - mean_absolute_error: 0.1576 - acc: 9.6525e-04 - val_loss: 0.0436 - val_mean_absolute_error: 0.1523 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.04409 to 0.04359, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 48/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0476 - mean_absolute_error: 0.1576 - acc: 9.6525e-04 - val_loss: 0.0436 - val_mean_absolute_error: 0.1530 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.04359\n",
      "Epoch 49/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 0.0474 - mean_absolute_error: 0.1570 - acc: 9.6525e-04 - val_loss: 0.0436 - val_mean_absolute_error: 0.1525 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.04359 to 0.04356, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 50/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0473 - mean_absolute_error: 0.1569 - acc: 9.6525e-04 - val_loss: 0.0438 - val_mean_absolute_error: 0.1541 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.04356\n",
      "Epoch 51/500\n",
      "2072/2072 [==============================] - 0s 45us/step - loss: 0.0470 - mean_absolute_error: 0.1566 - acc: 9.6525e-04 - val_loss: 0.0431 - val_mean_absolute_error: 0.1528 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.04356 to 0.04312, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 52/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0470 - mean_absolute_error: 0.1566 - acc: 9.6525e-04 - val_loss: 0.0430 - val_mean_absolute_error: 0.1517 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.04312 to 0.04303, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 53/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 0.0470 - mean_absolute_error: 0.1564 - acc: 9.6525e-04 - val_loss: 0.0441 - val_mean_absolute_error: 0.1536 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.04303\n",
      "Epoch 54/500\n",
      "2072/2072 [==============================] - 0s 54us/step - loss: 0.0466 - mean_absolute_error: 0.1556 - acc: 9.6525e-04 - val_loss: 0.0421 - val_mean_absolute_error: 0.1500 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.04303 to 0.04206, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 55/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0466 - mean_absolute_error: 0.1554 - acc: 9.6525e-04 - val_loss: 0.0418 - val_mean_absolute_error: 0.1490 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.04206 to 0.04178, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 56/500\n",
      "2072/2072 [==============================] - 0s 55us/step - loss: 0.0465 - mean_absolute_error: 0.1553 - acc: 9.6525e-04 - val_loss: 0.0415 - val_mean_absolute_error: 0.1488 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.04178 to 0.04155, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 57/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 0.0464 - mean_absolute_error: 0.1550 - acc: 9.6525e-04 - val_loss: 0.0417 - val_mean_absolute_error: 0.1490 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.04155\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2072/2072 [==============================] - 0s 62us/step - loss: 0.0460 - mean_absolute_error: 0.1546 - acc: 9.6525e-04 - val_loss: 0.0414 - val_mean_absolute_error: 0.1493 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.04155 to 0.04139, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 59/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0462 - mean_absolute_error: 0.1547 - acc: 9.6525e-04 - val_loss: 0.0413 - val_mean_absolute_error: 0.1482 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.04139 to 0.04126, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 60/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0459 - mean_absolute_error: 0.1540 - acc: 9.6525e-04 - val_loss: 0.0409 - val_mean_absolute_error: 0.1475 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.04126 to 0.04091, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 61/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 0.0457 - mean_absolute_error: 0.1537 - acc: 9.6525e-04 - val_loss: 0.0411 - val_mean_absolute_error: 0.1478 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.04091\n",
      "Epoch 62/500\n",
      "2072/2072 [==============================] - 0s 55us/step - loss: 0.0457 - mean_absolute_error: 0.1534 - acc: 9.6525e-04 - val_loss: 0.0407 - val_mean_absolute_error: 0.1474 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.04091 to 0.04074, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 63/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 0.0455 - mean_absolute_error: 0.1531 - acc: 9.6525e-04 - val_loss: 0.0404 - val_mean_absolute_error: 0.1462 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.04074 to 0.04039, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 64/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0455 - mean_absolute_error: 0.1532 - acc: 9.6525e-04 - val_loss: 0.0405 - val_mean_absolute_error: 0.1475 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.04039\n",
      "Epoch 65/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0453 - mean_absolute_error: 0.1531 - acc: 9.6525e-04 - val_loss: 0.0403 - val_mean_absolute_error: 0.1471 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.04039 to 0.04034, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 66/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0454 - mean_absolute_error: 0.1532 - acc: 9.6525e-04 - val_loss: 0.0403 - val_mean_absolute_error: 0.1463 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.04034 to 0.04029, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 67/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0451 - mean_absolute_error: 0.1525 - acc: 9.6525e-04 - val_loss: 0.0401 - val_mean_absolute_error: 0.1464 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.04029 to 0.04007, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 68/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0450 - mean_absolute_error: 0.1525 - acc: 9.6525e-04 - val_loss: 0.0400 - val_mean_absolute_error: 0.1463 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.04007 to 0.03996, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 69/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0448 - mean_absolute_error: 0.1519 - acc: 9.6525e-04 - val_loss: 0.0397 - val_mean_absolute_error: 0.1456 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.03996 to 0.03972, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 70/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0446 - mean_absolute_error: 0.1517 - acc: 9.6525e-04 - val_loss: 0.0397 - val_mean_absolute_error: 0.1458 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.03972 to 0.03972, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 71/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 0.0447 - mean_absolute_error: 0.1519 - acc: 9.6525e-04 - val_loss: 0.0397 - val_mean_absolute_error: 0.1459 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.03972 to 0.03971, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 72/500\n",
      "2072/2072 [==============================] - 0s 52us/step - loss: 0.0446 - mean_absolute_error: 0.1515 - acc: 9.6525e-04 - val_loss: 0.0395 - val_mean_absolute_error: 0.1450 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.03971 to 0.03950, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 73/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 0.0443 - mean_absolute_error: 0.1509 - acc: 9.6525e-04 - val_loss: 0.0391 - val_mean_absolute_error: 0.1441 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.03950 to 0.03909, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 74/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 0.0441 - mean_absolute_error: 0.1505 - acc: 9.6525e-04 - val_loss: 0.0392 - val_mean_absolute_error: 0.1451 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.03909\n",
      "Epoch 75/500\n",
      "2072/2072 [==============================] - 0s 55us/step - loss: 0.0441 - mean_absolute_error: 0.1504 - acc: 9.6525e-04 - val_loss: 0.0390 - val_mean_absolute_error: 0.1443 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.03909 to 0.03902, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 76/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0438 - mean_absolute_error: 0.1503 - acc: 9.6525e-04 - val_loss: 0.0389 - val_mean_absolute_error: 0.1447 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.03902 to 0.03890, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 77/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 0.0442 - mean_absolute_error: 0.1503 - acc: 9.6525e-04 - val_loss: 0.0390 - val_mean_absolute_error: 0.1436 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.03890\n",
      "Epoch 78/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 0.0440 - mean_absolute_error: 0.1503 - acc: 9.6525e-04 - val_loss: 0.0391 - val_mean_absolute_error: 0.1443 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.03890\n",
      "Epoch 79/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 0.0437 - mean_absolute_error: 0.1502 - acc: 9.6525e-04 - val_loss: 0.0386 - val_mean_absolute_error: 0.1445 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.03890 to 0.03860, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 80/500\n",
      "2072/2072 [==============================] - 0s 53us/step - loss: 0.0440 - mean_absolute_error: 0.1505 - acc: 9.6525e-04 - val_loss: 0.0385 - val_mean_absolute_error: 0.1424 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.03860 to 0.03847, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 81/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 0.0433 - mean_absolute_error: 0.1492 - acc: 9.6525e-04 - val_loss: 0.0385 - val_mean_absolute_error: 0.1424 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.03847\n",
      "Epoch 82/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 0.0433 - mean_absolute_error: 0.1488 - acc: 9.6525e-04 - val_loss: 0.0386 - val_mean_absolute_error: 0.1431 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.03847\n",
      "Epoch 83/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 0.0435 - mean_absolute_error: 0.1491 - acc: 9.6525e-04 - val_loss: 0.0382 - val_mean_absolute_error: 0.1417 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.03847 to 0.03816, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 84/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0429 - mean_absolute_error: 0.1477 - acc: 9.6525e-04 - val_loss: 0.0383 - val_mean_absolute_error: 0.1436 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.03816\n",
      "Epoch 85/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0428 - mean_absolute_error: 0.1476 - acc: 9.6525e-04 - val_loss: 0.0381 - val_mean_absolute_error: 0.1429 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.03816 to 0.03806, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 86/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0429 - mean_absolute_error: 0.1484 - acc: 9.6525e-04 - val_loss: 0.0382 - val_mean_absolute_error: 0.1421 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.03806\n",
      "Epoch 87/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 0.0427 - mean_absolute_error: 0.1473 - acc: 9.6525e-04 - val_loss: 0.0381 - val_mean_absolute_error: 0.1428 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.03806\n",
      "Epoch 88/500\n",
      "2072/2072 [==============================] - 0s 54us/step - loss: 0.0429 - mean_absolute_error: 0.1477 - acc: 9.6525e-04 - val_loss: 0.0378 - val_mean_absolute_error: 0.1422 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.03806 to 0.03776, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 89/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 0.0431 - mean_absolute_error: 0.1487 - acc: 9.6525e-04 - val_loss: 0.0378 - val_mean_absolute_error: 0.1424 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.03776\n",
      "Epoch 90/500\n",
      "2072/2072 [==============================] - 0s 52us/step - loss: 0.0426 - mean_absolute_error: 0.1477 - acc: 9.6525e-04 - val_loss: 0.0378 - val_mean_absolute_error: 0.1409 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.03776 to 0.03775, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 91/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0420 - mean_absolute_error: 0.1462 - acc: 9.6525e-04 - val_loss: 0.0374 - val_mean_absolute_error: 0.1402 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.03775 to 0.03736, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 92/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0424 - mean_absolute_error: 0.1471 - acc: 9.6525e-04 - val_loss: 0.0375 - val_mean_absolute_error: 0.1424 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.03736\n",
      "Epoch 93/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 0.0433 - mean_absolute_error: 0.1484 - acc: 9.6525e-04 - val_loss: 0.0375 - val_mean_absolute_error: 0.1407 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.03736\n",
      "Epoch 94/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0425 - mean_absolute_error: 0.1472 - acc: 9.6525e-04 - val_loss: 0.0373 - val_mean_absolute_error: 0.1417 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.03736 to 0.03729, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 95/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0421 - mean_absolute_error: 0.1466 - acc: 9.6525e-04 - val_loss: 0.0375 - val_mean_absolute_error: 0.1430 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.03729\n",
      "Epoch 96/500\n",
      "2072/2072 [==============================] - 0s 44us/step - loss: 0.0422 - mean_absolute_error: 0.1467 - acc: 9.6525e-04 - val_loss: 0.0376 - val_mean_absolute_error: 0.1411 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.03729\n",
      "Epoch 97/500\n",
      "2072/2072 [==============================] - 0s 45us/step - loss: 0.0418 - mean_absolute_error: 0.1463 - acc: 9.6525e-04 - val_loss: 0.0375 - val_mean_absolute_error: 0.1433 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.03729\n",
      "Epoch 98/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 0.0429 - mean_absolute_error: 0.1481 - acc: 9.6525e-04 - val_loss: 0.0379 - val_mean_absolute_error: 0.1420 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.03729\n",
      "Epoch 99/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 0.0422 - mean_absolute_error: 0.1471 - acc: 9.6525e-04 - val_loss: 0.0375 - val_mean_absolute_error: 0.1413 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.03729\n",
      "Epoch 100/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 0.0416 - mean_absolute_error: 0.1454 - acc: 9.6525e-04 - val_loss: 0.0370 - val_mean_absolute_error: 0.1398 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.03729 to 0.03703, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 101/500\n",
      "2072/2072 [==============================] - 0s 45us/step - loss: 0.0422 - mean_absolute_error: 0.1467 - acc: 9.6525e-04 - val_loss: 0.0369 - val_mean_absolute_error: 0.1414 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.03703 to 0.03695, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 102/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 0.0425 - mean_absolute_error: 0.1468 - acc: 9.6525e-04 - val_loss: 0.0369 - val_mean_absolute_error: 0.1398 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.03695 to 0.03695, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 103/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 0.0418 - mean_absolute_error: 0.1458 - acc: 9.6525e-04 - val_loss: 0.0372 - val_mean_absolute_error: 0.1415 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.03695\n",
      "Epoch 104/500\n",
      "2072/2072 [==============================] - 0s 45us/step - loss: 0.0424 - mean_absolute_error: 0.1470 - acc: 9.6525e-04 - val_loss: 0.0372 - val_mean_absolute_error: 0.1415 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.03695\n",
      "Epoch 105/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0419 - mean_absolute_error: 0.1465 - acc: 9.6525e-04 - val_loss: 0.0369 - val_mean_absolute_error: 0.1415 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.03695 to 0.03689, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 106/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0415 - mean_absolute_error: 0.1452 - acc: 9.6525e-04 - val_loss: 0.0371 - val_mean_absolute_error: 0.1412 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.03689\n",
      "Epoch 107/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0414 - mean_absolute_error: 0.1451 - acc: 9.6525e-04 - val_loss: 0.0369 - val_mean_absolute_error: 0.1412 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.03689 to 0.03686, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 108/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 0.0419 - mean_absolute_error: 0.1461 - acc: 9.6525e-04 - val_loss: 0.0370 - val_mean_absolute_error: 0.1413 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.03686\n",
      "Epoch 109/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0416 - mean_absolute_error: 0.1454 - acc: 9.6525e-04 - val_loss: 0.0372 - val_mean_absolute_error: 0.1419 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.03686\n",
      "Epoch 110/500\n",
      "2072/2072 [==============================] - 0s 45us/step - loss: 0.0423 - mean_absolute_error: 0.1467 - acc: 9.6525e-04 - val_loss: 0.0373 - val_mean_absolute_error: 0.1434 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.03686\n",
      "Epoch 111/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 0.0416 - mean_absolute_error: 0.1460 - acc: 9.6525e-04 - val_loss: 0.0372 - val_mean_absolute_error: 0.1413 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.03686\n",
      "Epoch 112/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 0.0422 - mean_absolute_error: 0.1469 - acc: 9.6525e-04 - val_loss: 0.0374 - val_mean_absolute_error: 0.1438 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.03686\n",
      "Epoch 113/500\n",
      "2072/2072 [==============================] - 0s 64us/step - loss: 0.0419 - mean_absolute_error: 0.1468 - acc: 9.6525e-04 - val_loss: 0.0370 - val_mean_absolute_error: 0.1401 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.03686\n",
      "Epoch 114/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0421 - mean_absolute_error: 0.1466 - acc: 9.6525e-04 - val_loss: 0.0370 - val_mean_absolute_error: 0.1399 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.03686\n",
      "Epoch 115/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0421 - mean_absolute_error: 0.1465 - acc: 9.6525e-04 - val_loss: 0.0378 - val_mean_absolute_error: 0.1447 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.03686\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0416 - mean_absolute_error: 0.1455 - acc: 9.6525e-04 - val_loss: 0.0370 - val_mean_absolute_error: 0.1409 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.03686\n",
      "Epoch 117/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 0.0414 - mean_absolute_error: 0.1453 - acc: 9.6525e-04 - val_loss: 0.0372 - val_mean_absolute_error: 0.1426 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.03686\n",
      "Epoch 118/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 0.0414 - mean_absolute_error: 0.1454 - acc: 9.6525e-04 - val_loss: 0.0377 - val_mean_absolute_error: 0.1417 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.03686\n",
      "Epoch 119/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0415 - mean_absolute_error: 0.1452 - acc: 9.6525e-04 - val_loss: 0.0378 - val_mean_absolute_error: 0.1436 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.03686\n",
      "Epoch 120/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0414 - mean_absolute_error: 0.1453 - acc: 9.6525e-04 - val_loss: 0.0366 - val_mean_absolute_error: 0.1413 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.03686 to 0.03656, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 121/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0417 - mean_absolute_error: 0.1459 - acc: 9.6525e-04 - val_loss: 0.0390 - val_mean_absolute_error: 0.1456 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.03656\n",
      "Epoch 122/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 0.0413 - mean_absolute_error: 0.1451 - acc: 9.6525e-04 - val_loss: 0.0371 - val_mean_absolute_error: 0.1420 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.03656\n",
      "Epoch 123/500\n",
      "2072/2072 [==============================] - 0s 59us/step - loss: 0.0415 - mean_absolute_error: 0.1458 - acc: 9.6525e-04 - val_loss: 0.0367 - val_mean_absolute_error: 0.1418 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.03656\n",
      "Epoch 124/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 0.0413 - mean_absolute_error: 0.1460 - acc: 9.6525e-04 - val_loss: 0.0377 - val_mean_absolute_error: 0.1420 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.03656\n",
      "Epoch 125/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0417 - mean_absolute_error: 0.1454 - acc: 9.6525e-04 - val_loss: 0.0378 - val_mean_absolute_error: 0.1430 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.03656\n",
      "Epoch 126/500\n",
      "2072/2072 [==============================] - 0s 52us/step - loss: 0.0417 - mean_absolute_error: 0.1455 - acc: 9.6525e-04 - val_loss: 0.0368 - val_mean_absolute_error: 0.1421 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.03656\n",
      "Epoch 127/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 0.0414 - mean_absolute_error: 0.1453 - acc: 9.6525e-04 - val_loss: 0.0378 - val_mean_absolute_error: 0.1422 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.03656\n",
      "Epoch 128/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 0.0412 - mean_absolute_error: 0.1445 - acc: 9.6525e-04 - val_loss: 0.0374 - val_mean_absolute_error: 0.1418 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.03656\n",
      "Epoch 129/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0410 - mean_absolute_error: 0.1441 - acc: 9.6525e-04 - val_loss: 0.0376 - val_mean_absolute_error: 0.1439 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.03656\n",
      "Epoch 130/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0407 - mean_absolute_error: 0.1438 - acc: 9.6525e-04 - val_loss: 0.0368 - val_mean_absolute_error: 0.1397 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.03656\n",
      "Epoch 131/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0414 - mean_absolute_error: 0.1444 - acc: 9.6525e-04 - val_loss: 0.0386 - val_mean_absolute_error: 0.1460 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.03656\n",
      "Epoch 132/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0404 - mean_absolute_error: 0.1433 - acc: 9.6525e-04 - val_loss: 0.0369 - val_mean_absolute_error: 0.1405 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.03656\n",
      "Epoch 133/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0414 - mean_absolute_error: 0.1445 - acc: 9.6525e-04 - val_loss: 0.0374 - val_mean_absolute_error: 0.1454 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.03656\n",
      "Epoch 134/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0411 - mean_absolute_error: 0.1450 - acc: 9.6525e-04 - val_loss: 0.0374 - val_mean_absolute_error: 0.1411 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.03656\n",
      "Epoch 135/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 0.0412 - mean_absolute_error: 0.1446 - acc: 9.6525e-04 - val_loss: 0.0370 - val_mean_absolute_error: 0.1420 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.03656\n",
      "Epoch 136/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0409 - mean_absolute_error: 0.1441 - acc: 9.6525e-04 - val_loss: 0.0372 - val_mean_absolute_error: 0.1413 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.03656\n",
      "Epoch 137/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0412 - mean_absolute_error: 0.1443 - acc: 9.6525e-04 - val_loss: 0.0371 - val_mean_absolute_error: 0.1409 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.03656\n",
      "Epoch 138/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0411 - mean_absolute_error: 0.1445 - acc: 9.6525e-04 - val_loss: 0.0365 - val_mean_absolute_error: 0.1403 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.03656 to 0.03645, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 139/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0414 - mean_absolute_error: 0.1451 - acc: 9.6525e-04 - val_loss: 0.0372 - val_mean_absolute_error: 0.1405 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.03645\n",
      "Epoch 140/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 0.0417 - mean_absolute_error: 0.1452 - acc: 9.6525e-04 - val_loss: 0.0367 - val_mean_absolute_error: 0.1408 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.03645\n",
      "Epoch 141/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 0.0410 - mean_absolute_error: 0.1448 - acc: 9.6525e-04 - val_loss: 0.0369 - val_mean_absolute_error: 0.1396 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.03645\n",
      "Epoch 142/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 0.0409 - mean_absolute_error: 0.1438 - acc: 9.6525e-04 - val_loss: 0.0375 - val_mean_absolute_error: 0.1425 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.03645\n",
      "Epoch 143/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0403 - mean_absolute_error: 0.1428 - acc: 9.6525e-04 - val_loss: 0.0365 - val_mean_absolute_error: 0.1400 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.03645\n",
      "Epoch 144/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0409 - mean_absolute_error: 0.1442 - acc: 9.6525e-04 - val_loss: 0.0364 - val_mean_absolute_error: 0.1400 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.03645 to 0.03641, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 145/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0409 - mean_absolute_error: 0.1441 - acc: 9.6525e-04 - val_loss: 0.0367 - val_mean_absolute_error: 0.1392 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.03641\n",
      "Epoch 146/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0416 - mean_absolute_error: 0.1451 - acc: 9.6525e-04 - val_loss: 0.0373 - val_mean_absolute_error: 0.1416 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.03641\n",
      "Epoch 147/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0416 - mean_absolute_error: 0.1453 - acc: 9.6525e-04 - val_loss: 0.0388 - val_mean_absolute_error: 0.1460 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.03641\n",
      "Epoch 148/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0410 - mean_absolute_error: 0.1440 - acc: 9.6525e-04 - val_loss: 0.0373 - val_mean_absolute_error: 0.1432 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.03641\n",
      "Epoch 149/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0413 - mean_absolute_error: 0.1445 - acc: 9.6525e-04 - val_loss: 0.0378 - val_mean_absolute_error: 0.1430 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.03641\n",
      "Epoch 150/500\n",
      "2072/2072 [==============================] - 0s 55us/step - loss: 0.0410 - mean_absolute_error: 0.1443 - acc: 9.6525e-04 - val_loss: 0.0363 - val_mean_absolute_error: 0.1389 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.03641 to 0.03630, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 151/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0416 - mean_absolute_error: 0.1452 - acc: 9.6525e-04 - val_loss: 0.0367 - val_mean_absolute_error: 0.1404 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.03630\n",
      "Epoch 152/500\n",
      "2072/2072 [==============================] - 0s 44us/step - loss: 0.0418 - mean_absolute_error: 0.1461 - acc: 9.6525e-04 - val_loss: 0.0393 - val_mean_absolute_error: 0.1458 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.03630\n",
      "Epoch 153/500\n",
      "2072/2072 [==============================] - 0s 45us/step - loss: 0.0404 - mean_absolute_error: 0.1431 - acc: 9.6525e-04 - val_loss: 0.0377 - val_mean_absolute_error: 0.1429 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.03630\n",
      "Epoch 154/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0402 - mean_absolute_error: 0.1430 - acc: 9.6525e-04 - val_loss: 0.0374 - val_mean_absolute_error: 0.1417 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.03630\n",
      "Epoch 155/500\n",
      "2072/2072 [==============================] - 0s 64us/step - loss: 0.0416 - mean_absolute_error: 0.1450 - acc: 9.6525e-04 - val_loss: 0.0388 - val_mean_absolute_error: 0.1449 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.03630\n",
      "Epoch 156/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 0.0410 - mean_absolute_error: 0.1441 - acc: 9.6525e-04 - val_loss: 0.0388 - val_mean_absolute_error: 0.1457 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.03630\n",
      "Epoch 157/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 0.0408 - mean_absolute_error: 0.1436 - acc: 9.6525e-04 - val_loss: 0.0373 - val_mean_absolute_error: 0.1425 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.03630\n",
      "Epoch 158/500\n",
      "2072/2072 [==============================] - 0s 52us/step - loss: 0.0410 - mean_absolute_error: 0.1444 - acc: 9.6525e-04 - val_loss: 0.0366 - val_mean_absolute_error: 0.1403 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.03630\n",
      "Epoch 159/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0415 - mean_absolute_error: 0.1455 - acc: 9.6525e-04 - val_loss: 0.0376 - val_mean_absolute_error: 0.1440 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.03630\n",
      "Epoch 160/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0406 - mean_absolute_error: 0.1437 - acc: 9.6525e-04 - val_loss: 0.0397 - val_mean_absolute_error: 0.1470 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.03630\n",
      "Epoch 161/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0407 - mean_absolute_error: 0.1436 - acc: 9.6525e-04 - val_loss: 0.0387 - val_mean_absolute_error: 0.1454 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.03630\n",
      "Epoch 162/500\n",
      "2072/2072 [==============================] - 0s 53us/step - loss: 0.0409 - mean_absolute_error: 0.1442 - acc: 9.6525e-04 - val_loss: 0.0382 - val_mean_absolute_error: 0.1452 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.03630\n",
      "Epoch 163/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0408 - mean_absolute_error: 0.1444 - acc: 9.6525e-04 - val_loss: 0.0375 - val_mean_absolute_error: 0.1454 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.03630\n",
      "Epoch 164/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 0.0401 - mean_absolute_error: 0.1428 - acc: 9.6525e-04 - val_loss: 0.0386 - val_mean_absolute_error: 0.1443 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.03630\n",
      "Epoch 165/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0398 - mean_absolute_error: 0.1422 - acc: 9.6525e-04 - val_loss: 0.0366 - val_mean_absolute_error: 0.1389 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.03630\n",
      "Epoch 166/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0406 - mean_absolute_error: 0.1433 - acc: 9.6525e-04 - val_loss: 0.0382 - val_mean_absolute_error: 0.1433 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.03630\n",
      "Epoch 167/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0409 - mean_absolute_error: 0.1442 - acc: 9.6525e-04 - val_loss: 0.0399 - val_mean_absolute_error: 0.1484 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.03630\n",
      "Epoch 168/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0400 - mean_absolute_error: 0.1422 - acc: 9.6525e-04 - val_loss: 0.0371 - val_mean_absolute_error: 0.1402 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.03630\n",
      "Epoch 169/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0406 - mean_absolute_error: 0.1436 - acc: 9.6525e-04 - val_loss: 0.0367 - val_mean_absolute_error: 0.1398 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.03630\n",
      "Epoch 170/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0406 - mean_absolute_error: 0.1435 - acc: 9.6525e-04 - val_loss: 0.0365 - val_mean_absolute_error: 0.1404 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.03630\n",
      "Epoch 171/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0404 - mean_absolute_error: 0.1430 - acc: 9.6525e-04 - val_loss: 0.0383 - val_mean_absolute_error: 0.1439 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.03630\n",
      "Epoch 172/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0404 - mean_absolute_error: 0.1433 - acc: 9.6525e-04 - val_loss: 0.0372 - val_mean_absolute_error: 0.1413 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.03630\n",
      "Epoch 173/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0407 - mean_absolute_error: 0.1438 - acc: 9.6525e-04 - val_loss: 0.0368 - val_mean_absolute_error: 0.1394 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.03630\n",
      "Epoch 174/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0409 - mean_absolute_error: 0.1443 - acc: 9.6525e-04 - val_loss: 0.0381 - val_mean_absolute_error: 0.1432 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.03630\n",
      "Epoch 175/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 0.0408 - mean_absolute_error: 0.1437 - acc: 9.6525e-04 - val_loss: 0.0381 - val_mean_absolute_error: 0.1437 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.03630\n",
      "Epoch 176/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 0.0406 - mean_absolute_error: 0.1437 - acc: 9.6525e-04 - val_loss: 0.0389 - val_mean_absolute_error: 0.1450 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.03630\n",
      "Epoch 177/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 0.0399 - mean_absolute_error: 0.1423 - acc: 9.6525e-04 - val_loss: 0.0404 - val_mean_absolute_error: 0.1497 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.03630\n",
      "Epoch 178/500\n",
      "2072/2072 [==============================] - 0s 54us/step - loss: 0.0395 - mean_absolute_error: 0.1414 - acc: 9.6525e-04 - val_loss: 0.0376 - val_mean_absolute_error: 0.1417 - val_acc: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00178: val_loss did not improve from 0.03630\n",
      "Epoch 179/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0403 - mean_absolute_error: 0.1429 - acc: 9.6525e-04 - val_loss: 0.0383 - val_mean_absolute_error: 0.1443 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.03630\n",
      "Epoch 180/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0400 - mean_absolute_error: 0.1421 - acc: 9.6525e-04 - val_loss: 0.0383 - val_mean_absolute_error: 0.1443 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.03630\n",
      "Epoch 181/500\n",
      "2072/2072 [==============================] - 0s 54us/step - loss: 0.0397 - mean_absolute_error: 0.1418 - acc: 9.6525e-04 - val_loss: 0.0363 - val_mean_absolute_error: 0.1388 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.03630 to 0.03626, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 182/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0409 - mean_absolute_error: 0.1445 - acc: 9.6525e-04 - val_loss: 0.0376 - val_mean_absolute_error: 0.1436 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.03626\n",
      "Epoch 183/500\n",
      "2072/2072 [==============================] - 0s 45us/step - loss: 0.0408 - mean_absolute_error: 0.1445 - acc: 9.6525e-04 - val_loss: 0.0389 - val_mean_absolute_error: 0.1438 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.03626\n",
      "Epoch 184/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0400 - mean_absolute_error: 0.1425 - acc: 9.6525e-04 - val_loss: 0.0378 - val_mean_absolute_error: 0.1432 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.03626\n",
      "Epoch 185/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0396 - mean_absolute_error: 0.1414 - acc: 9.6525e-04 - val_loss: 0.0372 - val_mean_absolute_error: 0.1410 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.03626\n",
      "Epoch 186/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0394 - mean_absolute_error: 0.1414 - acc: 9.6525e-04 - val_loss: 0.0379 - val_mean_absolute_error: 0.1428 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.03626\n",
      "Epoch 187/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0401 - mean_absolute_error: 0.1434 - acc: 9.6525e-04 - val_loss: 0.0419 - val_mean_absolute_error: 0.1529 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.03626\n",
      "Epoch 188/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0392 - mean_absolute_error: 0.1409 - acc: 9.6525e-04 - val_loss: 0.0365 - val_mean_absolute_error: 0.1409 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.03626\n",
      "Epoch 189/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0399 - mean_absolute_error: 0.1426 - acc: 9.6525e-04 - val_loss: 0.0389 - val_mean_absolute_error: 0.1447 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.03626\n",
      "Epoch 190/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0399 - mean_absolute_error: 0.1421 - acc: 9.6525e-04 - val_loss: 0.0409 - val_mean_absolute_error: 0.1499 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.03626\n",
      "Epoch 191/500\n",
      "2072/2072 [==============================] - 0s 44us/step - loss: 0.0392 - mean_absolute_error: 0.1407 - acc: 9.6525e-04 - val_loss: 0.0374 - val_mean_absolute_error: 0.1416 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.03626\n",
      "Epoch 192/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0396 - mean_absolute_error: 0.1412 - acc: 9.6525e-04 - val_loss: 0.0384 - val_mean_absolute_error: 0.1445 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.03626\n",
      "Epoch 193/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 0.0389 - mean_absolute_error: 0.1401 - acc: 9.6525e-04 - val_loss: 0.0383 - val_mean_absolute_error: 0.1443 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.03626\n",
      "Epoch 194/500\n",
      "2072/2072 [==============================] - 0s 45us/step - loss: 0.0390 - mean_absolute_error: 0.1402 - acc: 9.6525e-04 - val_loss: 0.0364 - val_mean_absolute_error: 0.1393 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.03626\n",
      "Epoch 195/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0389 - mean_absolute_error: 0.1399 - acc: 9.6525e-04 - val_loss: 0.0367 - val_mean_absolute_error: 0.1401 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.03626\n",
      "Epoch 196/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0391 - mean_absolute_error: 0.1400 - acc: 9.6525e-04 - val_loss: 0.0366 - val_mean_absolute_error: 0.1399 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.03626\n",
      "Epoch 197/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0392 - mean_absolute_error: 0.1401 - acc: 9.6525e-04 - val_loss: 0.0369 - val_mean_absolute_error: 0.1402 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.03626\n",
      "Epoch 198/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0388 - mean_absolute_error: 0.1401 - acc: 9.6525e-04 - val_loss: 0.0386 - val_mean_absolute_error: 0.1443 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.03626\n",
      "Epoch 199/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0393 - mean_absolute_error: 0.1403 - acc: 9.6525e-04 - val_loss: 0.0379 - val_mean_absolute_error: 0.1432 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.03626\n",
      "Epoch 200/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0388 - mean_absolute_error: 0.1399 - acc: 9.6525e-04 - val_loss: 0.0371 - val_mean_absolute_error: 0.1405 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.03626\n",
      "Epoch 201/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0389 - mean_absolute_error: 0.1396 - acc: 9.6525e-04 - val_loss: 0.0374 - val_mean_absolute_error: 0.1422 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.03626\n",
      "Epoch 202/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0388 - mean_absolute_error: 0.1396 - acc: 9.6525e-04 - val_loss: 0.0360 - val_mean_absolute_error: 0.1403 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.03626 to 0.03603, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 203/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0395 - mean_absolute_error: 0.1413 - acc: 9.6525e-04 - val_loss: 0.0388 - val_mean_absolute_error: 0.1455 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.03603\n",
      "Epoch 204/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0389 - mean_absolute_error: 0.1401 - acc: 9.6525e-04 - val_loss: 0.0368 - val_mean_absolute_error: 0.1398 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.03603\n",
      "Epoch 205/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0388 - mean_absolute_error: 0.1396 - acc: 9.6525e-04 - val_loss: 0.0370 - val_mean_absolute_error: 0.1408 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.03603\n",
      "Epoch 206/500\n",
      "2072/2072 [==============================] - 0s 52us/step - loss: 0.0384 - mean_absolute_error: 0.1389 - acc: 9.6525e-04 - val_loss: 0.0362 - val_mean_absolute_error: 0.1391 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.03603\n",
      "Epoch 207/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 0.0392 - mean_absolute_error: 0.1398 - acc: 9.6525e-04 - val_loss: 0.0368 - val_mean_absolute_error: 0.1404 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.03603\n",
      "Epoch 208/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 0.0391 - mean_absolute_error: 0.1402 - acc: 9.6525e-04 - val_loss: 0.0367 - val_mean_absolute_error: 0.1403 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.03603\n",
      "Epoch 209/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 0.0400 - mean_absolute_error: 0.1419 - acc: 9.6525e-04 - val_loss: 0.0372 - val_mean_absolute_error: 0.1439 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.03603\n",
      "Epoch 210/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 0.0393 - mean_absolute_error: 0.1415 - acc: 9.6525e-04 - val_loss: 0.0377 - val_mean_absolute_error: 0.1424 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.03603\n",
      "Epoch 211/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0386 - mean_absolute_error: 0.1397 - acc: 9.6525e-04 - val_loss: 0.0361 - val_mean_absolute_error: 0.1384 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.03603\n",
      "Epoch 212/500\n",
      "2072/2072 [==============================] - 0s 52us/step - loss: 0.0386 - mean_absolute_error: 0.1391 - acc: 9.6525e-04 - val_loss: 0.0385 - val_mean_absolute_error: 0.1445 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.03603\n",
      "Epoch 213/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0382 - mean_absolute_error: 0.1386 - acc: 9.6525e-04 - val_loss: 0.0366 - val_mean_absolute_error: 0.1408 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.03603\n",
      "Epoch 214/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0385 - mean_absolute_error: 0.1393 - acc: 9.6525e-04 - val_loss: 0.0379 - val_mean_absolute_error: 0.1434 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.03603\n",
      "Epoch 215/500\n",
      "2072/2072 [==============================] - 0s 42us/step - loss: 0.0383 - mean_absolute_error: 0.1385 - acc: 9.6525e-04 - val_loss: 0.0371 - val_mean_absolute_error: 0.1407 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.03603\n",
      "Epoch 216/500\n",
      "2072/2072 [==============================] - 0s 44us/step - loss: 0.0382 - mean_absolute_error: 0.1381 - acc: 9.6525e-04 - val_loss: 0.0361 - val_mean_absolute_error: 0.1393 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.03603\n",
      "Epoch 217/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0385 - mean_absolute_error: 0.1392 - acc: 9.6525e-04 - val_loss: 0.0364 - val_mean_absolute_error: 0.1389 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.03603\n",
      "Epoch 218/500\n",
      "2072/2072 [==============================] - 0s 54us/step - loss: 0.0382 - mean_absolute_error: 0.1391 - acc: 9.6525e-04 - val_loss: 0.0363 - val_mean_absolute_error: 0.1396 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.03603\n",
      "Epoch 219/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0387 - mean_absolute_error: 0.1395 - acc: 9.6525e-04 - val_loss: 0.0382 - val_mean_absolute_error: 0.1445 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.03603\n",
      "Epoch 220/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0398 - mean_absolute_error: 0.1413 - acc: 9.6525e-04 - val_loss: 0.0383 - val_mean_absolute_error: 0.1445 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.03603\n",
      "Epoch 221/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 0.0383 - mean_absolute_error: 0.1390 - acc: 9.6525e-04 - val_loss: 0.0381 - val_mean_absolute_error: 0.1438 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.03603\n",
      "Epoch 222/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0377 - mean_absolute_error: 0.1383 - acc: 9.6525e-04 - val_loss: 0.0382 - val_mean_absolute_error: 0.1448 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.03603\n",
      "Epoch 223/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 0.0379 - mean_absolute_error: 0.1380 - acc: 9.6525e-04 - val_loss: 0.0397 - val_mean_absolute_error: 0.1485 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.03603\n",
      "Epoch 224/500\n",
      "2072/2072 [==============================] - 0s 55us/step - loss: 0.0383 - mean_absolute_error: 0.1393 - acc: 9.6525e-04 - val_loss: 0.0385 - val_mean_absolute_error: 0.1449 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.03603\n",
      "Epoch 225/500\n",
      "2072/2072 [==============================] - 0s 53us/step - loss: 0.0378 - mean_absolute_error: 0.1381 - acc: 9.6525e-04 - val_loss: 0.0379 - val_mean_absolute_error: 0.1425 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.03603\n",
      "Epoch 226/500\n",
      "2072/2072 [==============================] - 0s 52us/step - loss: 0.0379 - mean_absolute_error: 0.1379 - acc: 9.6525e-04 - val_loss: 0.0392 - val_mean_absolute_error: 0.1467 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.03603\n",
      "Epoch 227/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0380 - mean_absolute_error: 0.1386 - acc: 9.6525e-04 - val_loss: 0.0363 - val_mean_absolute_error: 0.1403 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.03603\n",
      "Epoch 228/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0384 - mean_absolute_error: 0.1398 - acc: 9.6525e-04 - val_loss: 0.0391 - val_mean_absolute_error: 0.1504 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.03603\n",
      "Epoch 229/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 0.0386 - mean_absolute_error: 0.1411 - acc: 9.6525e-04 - val_loss: 0.0380 - val_mean_absolute_error: 0.1446 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.03603\n",
      "Epoch 230/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 0.0383 - mean_absolute_error: 0.1398 - acc: 9.6525e-04 - val_loss: 0.0371 - val_mean_absolute_error: 0.1415 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.03603\n",
      "Epoch 231/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0381 - mean_absolute_error: 0.1396 - acc: 9.6525e-04 - val_loss: 0.0412 - val_mean_absolute_error: 0.1514 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.03603\n",
      "Epoch 232/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 0.0378 - mean_absolute_error: 0.1378 - acc: 9.6525e-04 - val_loss: 0.0391 - val_mean_absolute_error: 0.1462 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.03603\n",
      "Epoch 233/500\n",
      "2072/2072 [==============================] - 0s 55us/step - loss: 0.0380 - mean_absolute_error: 0.1386 - acc: 9.6525e-04 - val_loss: 0.0370 - val_mean_absolute_error: 0.1404 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.03603\n",
      "Epoch 234/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0372 - mean_absolute_error: 0.1368 - acc: 9.6525e-04 - val_loss: 0.0393 - val_mean_absolute_error: 0.1459 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.03603\n",
      "Epoch 235/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0371 - mean_absolute_error: 0.1369 - acc: 9.6525e-04 - val_loss: 0.0368 - val_mean_absolute_error: 0.1405 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.03603\n",
      "Epoch 236/500\n",
      "2072/2072 [==============================] - 0s 52us/step - loss: 0.0373 - mean_absolute_error: 0.1372 - acc: 9.6525e-04 - val_loss: 0.0367 - val_mean_absolute_error: 0.1388 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.03603\n",
      "Epoch 237/500\n",
      "2072/2072 [==============================] - 0s 59us/step - loss: 0.0378 - mean_absolute_error: 0.1379 - acc: 9.6525e-04 - val_loss: 0.0372 - val_mean_absolute_error: 0.1418 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.03603\n",
      "Epoch 238/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 0.0372 - mean_absolute_error: 0.1364 - acc: 9.6525e-04 - val_loss: 0.0360 - val_mean_absolute_error: 0.1386 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.03603 to 0.03600, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 239/500\n",
      "2072/2072 [==============================] - 0s 64us/step - loss: 0.0379 - mean_absolute_error: 0.1387 - acc: 9.6525e-04 - val_loss: 0.0393 - val_mean_absolute_error: 0.1461 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.03600\n",
      "Epoch 240/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 0.0374 - mean_absolute_error: 0.1370 - acc: 9.6525e-04 - val_loss: 0.0365 - val_mean_absolute_error: 0.1393 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.03600\n",
      "Epoch 241/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 0.0377 - mean_absolute_error: 0.1378 - acc: 9.6525e-04 - val_loss: 0.0395 - val_mean_absolute_error: 0.1461 - val_acc: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00241: val_loss did not improve from 0.03600\n",
      "Epoch 242/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 0.0375 - mean_absolute_error: 0.1377 - acc: 9.6525e-04 - val_loss: 0.0411 - val_mean_absolute_error: 0.1508 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.03600\n",
      "Epoch 243/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 0.0374 - mean_absolute_error: 0.1365 - acc: 9.6525e-04 - val_loss: 0.0370 - val_mean_absolute_error: 0.1408 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.03600\n",
      "Epoch 244/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0377 - mean_absolute_error: 0.1379 - acc: 9.6525e-04 - val_loss: 0.0358 - val_mean_absolute_error: 0.1386 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00244: val_loss improved from 0.03600 to 0.03579, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 245/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 0.0380 - mean_absolute_error: 0.1386 - acc: 9.6525e-04 - val_loss: 0.0382 - val_mean_absolute_error: 0.1460 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.03579\n",
      "Epoch 246/500\n",
      "2072/2072 [==============================] - 0s 53us/step - loss: 0.0373 - mean_absolute_error: 0.1373 - acc: 9.6525e-04 - val_loss: 0.0367 - val_mean_absolute_error: 0.1396 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.03579\n",
      "Epoch 247/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0376 - mean_absolute_error: 0.1371 - acc: 9.6525e-04 - val_loss: 0.0380 - val_mean_absolute_error: 0.1431 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.03579\n",
      "Epoch 248/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 0.0379 - mean_absolute_error: 0.1381 - acc: 9.6525e-04 - val_loss: 0.0359 - val_mean_absolute_error: 0.1383 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.03579\n",
      "Epoch 249/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0370 - mean_absolute_error: 0.1360 - acc: 9.6525e-04 - val_loss: 0.0378 - val_mean_absolute_error: 0.1423 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.03579\n",
      "Epoch 250/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0374 - mean_absolute_error: 0.1374 - acc: 9.6525e-04 - val_loss: 0.0373 - val_mean_absolute_error: 0.1428 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.03579\n",
      "Epoch 251/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0371 - mean_absolute_error: 0.1366 - acc: 9.6525e-04 - val_loss: 0.0377 - val_mean_absolute_error: 0.1422 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.03579\n",
      "Epoch 252/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0387 - mean_absolute_error: 0.1392 - acc: 9.6525e-04 - val_loss: 0.0387 - val_mean_absolute_error: 0.1449 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.03579\n",
      "Epoch 253/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0368 - mean_absolute_error: 0.1357 - acc: 9.6525e-04 - val_loss: 0.0397 - val_mean_absolute_error: 0.1474 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.03579\n",
      "Epoch 254/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 0.0366 - mean_absolute_error: 0.1356 - acc: 9.6525e-04 - val_loss: 0.0379 - val_mean_absolute_error: 0.1433 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.03579\n",
      "Epoch 255/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0368 - mean_absolute_error: 0.1368 - acc: 9.6525e-04 - val_loss: 0.0382 - val_mean_absolute_error: 0.1436 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.03579\n",
      "Epoch 256/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0382 - mean_absolute_error: 0.1380 - acc: 9.6525e-04 - val_loss: 0.0382 - val_mean_absolute_error: 0.1446 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.03579\n",
      "Epoch 257/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0381 - mean_absolute_error: 0.1381 - acc: 9.6525e-04 - val_loss: 0.0395 - val_mean_absolute_error: 0.1494 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.03579\n",
      "Epoch 258/500\n",
      "2072/2072 [==============================] - 0s 55us/step - loss: 0.0371 - mean_absolute_error: 0.1362 - acc: 9.6525e-04 - val_loss: 0.0382 - val_mean_absolute_error: 0.1437 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.03579\n",
      "Epoch 259/500\n",
      "2072/2072 [==============================] - 0s 66us/step - loss: 0.0372 - mean_absolute_error: 0.1367 - acc: 9.6525e-04 - val_loss: 0.0389 - val_mean_absolute_error: 0.1448 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.03579\n",
      "Epoch 260/500\n",
      "2072/2072 [==============================] - 0s 55us/step - loss: 0.0372 - mean_absolute_error: 0.1371 - acc: 9.6525e-04 - val_loss: 0.0402 - val_mean_absolute_error: 0.1478 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.03579\n",
      "Epoch 261/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0371 - mean_absolute_error: 0.1360 - acc: 9.6525e-04 - val_loss: 0.0391 - val_mean_absolute_error: 0.1486 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.03579\n",
      "Epoch 262/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0383 - mean_absolute_error: 0.1395 - acc: 9.6525e-04 - val_loss: 0.0392 - val_mean_absolute_error: 0.1466 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.03579\n",
      "Epoch 263/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0365 - mean_absolute_error: 0.1347 - acc: 9.6525e-04 - val_loss: 0.0368 - val_mean_absolute_error: 0.1407 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.03579\n",
      "Epoch 264/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0372 - mean_absolute_error: 0.1364 - acc: 9.6525e-04 - val_loss: 0.0388 - val_mean_absolute_error: 0.1449 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.03579\n",
      "Epoch 265/500\n",
      "2072/2072 [==============================] - 0s 55us/step - loss: 0.0372 - mean_absolute_error: 0.1367 - acc: 9.6525e-04 - val_loss: 0.0398 - val_mean_absolute_error: 0.1474 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.03579\n",
      "Epoch 266/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0371 - mean_absolute_error: 0.1359 - acc: 9.6525e-04 - val_loss: 0.0374 - val_mean_absolute_error: 0.1424 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.03579\n",
      "Epoch 267/500\n",
      "2072/2072 [==============================] - 0s 52us/step - loss: 0.0370 - mean_absolute_error: 0.1366 - acc: 9.6525e-04 - val_loss: 0.0395 - val_mean_absolute_error: 0.1466 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.03579\n",
      "Epoch 268/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 0.0366 - mean_absolute_error: 0.1348 - acc: 9.6525e-04 - val_loss: 0.0406 - val_mean_absolute_error: 0.1492 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.03579\n",
      "Epoch 269/500\n",
      "2072/2072 [==============================] - 0s 66us/step - loss: 0.0368 - mean_absolute_error: 0.1352 - acc: 9.6525e-04 - val_loss: 0.0387 - val_mean_absolute_error: 0.1449 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.03579\n",
      "Epoch 270/500\n",
      "2072/2072 [==============================] - 0s 55us/step - loss: 0.0370 - mean_absolute_error: 0.1360 - acc: 9.6525e-04 - val_loss: 0.0382 - val_mean_absolute_error: 0.1439 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.03579\n",
      "Epoch 271/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0367 - mean_absolute_error: 0.1354 - acc: 9.6525e-04 - val_loss: 0.0377 - val_mean_absolute_error: 0.1434 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.03579\n",
      "Epoch 272/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0371 - mean_absolute_error: 0.1358 - acc: 9.6525e-04 - val_loss: 0.0376 - val_mean_absolute_error: 0.1431 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.03579\n",
      "Epoch 273/500\n",
      "2072/2072 [==============================] - 0s 52us/step - loss: 0.0365 - mean_absolute_error: 0.1345 - acc: 9.6525e-04 - val_loss: 0.0381 - val_mean_absolute_error: 0.1437 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.03579\n",
      "Epoch 274/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0362 - mean_absolute_error: 0.1331 - acc: 9.6525e-04 - val_loss: 0.0375 - val_mean_absolute_error: 0.1422 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.03579\n",
      "Epoch 275/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0368 - mean_absolute_error: 0.1356 - acc: 9.6525e-04 - val_loss: 0.0398 - val_mean_absolute_error: 0.1482 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.03579\n",
      "Epoch 276/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0377 - mean_absolute_error: 0.1380 - acc: 9.6525e-04 - val_loss: 0.0427 - val_mean_absolute_error: 0.1554 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.03579\n",
      "Epoch 277/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0401 - mean_absolute_error: 0.1451 - acc: 9.6525e-04 - val_loss: 0.0397 - val_mean_absolute_error: 0.1478 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.03579\n",
      "Epoch 278/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0372 - mean_absolute_error: 0.1369 - acc: 9.6525e-04 - val_loss: 0.0384 - val_mean_absolute_error: 0.1452 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.03579\n",
      "Epoch 279/500\n",
      "2072/2072 [==============================] - 0s 55us/step - loss: 0.0380 - mean_absolute_error: 0.1382 - acc: 9.6525e-04 - val_loss: 0.0404 - val_mean_absolute_error: 0.1488 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.03579\n",
      "Epoch 280/500\n",
      "2072/2072 [==============================] - 0s 45us/step - loss: 0.0379 - mean_absolute_error: 0.1389 - acc: 9.6525e-04 - val_loss: 0.0423 - val_mean_absolute_error: 0.1535 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.03579\n",
      "Epoch 281/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0368 - mean_absolute_error: 0.1363 - acc: 9.6525e-04 - val_loss: 0.0381 - val_mean_absolute_error: 0.1437 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.03579\n",
      "Epoch 282/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0373 - mean_absolute_error: 0.1364 - acc: 9.6525e-04 - val_loss: 0.0389 - val_mean_absolute_error: 0.1460 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.03579\n",
      "Epoch 283/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0363 - mean_absolute_error: 0.1337 - acc: 9.6525e-04 - val_loss: 0.0380 - val_mean_absolute_error: 0.1436 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.03579\n",
      "Epoch 284/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 0.0359 - mean_absolute_error: 0.1341 - acc: 9.6525e-04 - val_loss: 0.0373 - val_mean_absolute_error: 0.1427 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.03579\n",
      "Epoch 285/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0363 - mean_absolute_error: 0.1346 - acc: 9.6525e-04 - val_loss: 0.0378 - val_mean_absolute_error: 0.1431 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.03579\n",
      "Epoch 286/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0366 - mean_absolute_error: 0.1346 - acc: 9.6525e-04 - val_loss: 0.0404 - val_mean_absolute_error: 0.1495 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.03579\n",
      "Epoch 287/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0371 - mean_absolute_error: 0.1377 - acc: 9.6525e-04 - val_loss: 0.0376 - val_mean_absolute_error: 0.1422 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.03579\n",
      "Epoch 288/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 0.0371 - mean_absolute_error: 0.1363 - acc: 9.6525e-04 - val_loss: 0.0372 - val_mean_absolute_error: 0.1410 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.03579\n",
      "Epoch 289/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0372 - mean_absolute_error: 0.1359 - acc: 9.6525e-04 - val_loss: 0.0386 - val_mean_absolute_error: 0.1444 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.03579\n",
      "Epoch 290/500\n",
      "2072/2072 [==============================] - 0s 54us/step - loss: 0.0359 - mean_absolute_error: 0.1328 - acc: 9.6525e-04 - val_loss: 0.0389 - val_mean_absolute_error: 0.1447 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.03579\n",
      "Epoch 291/500\n",
      "2072/2072 [==============================] - 0s 66us/step - loss: 0.0364 - mean_absolute_error: 0.1343 - acc: 9.6525e-04 - val_loss: 0.0360 - val_mean_absolute_error: 0.1390 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.03579\n",
      "Epoch 292/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0371 - mean_absolute_error: 0.1354 - acc: 9.6525e-04 - val_loss: 0.0382 - val_mean_absolute_error: 0.1439 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.03579\n",
      "Epoch 293/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0361 - mean_absolute_error: 0.1344 - acc: 9.6525e-04 - val_loss: 0.0356 - val_mean_absolute_error: 0.1384 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00293: val_loss improved from 0.03579 to 0.03563, saving model to ANN_Interval_best_MD.hdf5\n",
      "Epoch 294/500\n",
      "2072/2072 [==============================] - 0s 53us/step - loss: 0.0368 - mean_absolute_error: 0.1357 - acc: 9.6525e-04 - val_loss: 0.0412 - val_mean_absolute_error: 0.1514 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.03563\n",
      "Epoch 295/500\n",
      "2072/2072 [==============================] - 0s 53us/step - loss: 0.0371 - mean_absolute_error: 0.1353 - acc: 9.6525e-04 - val_loss: 0.0372 - val_mean_absolute_error: 0.1409 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.03563\n",
      "Epoch 296/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0368 - mean_absolute_error: 0.1353 - acc: 9.6525e-04 - val_loss: 0.0384 - val_mean_absolute_error: 0.1432 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.03563\n",
      "Epoch 297/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0367 - mean_absolute_error: 0.1341 - acc: 9.6525e-04 - val_loss: 0.0403 - val_mean_absolute_error: 0.1483 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.03563\n",
      "Epoch 298/500\n",
      "2072/2072 [==============================] - 0s 54us/step - loss: 0.0357 - mean_absolute_error: 0.1330 - acc: 9.6525e-04 - val_loss: 0.0377 - val_mean_absolute_error: 0.1427 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.03563\n",
      "Epoch 299/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0366 - mean_absolute_error: 0.1346 - acc: 9.6525e-04 - val_loss: 0.0399 - val_mean_absolute_error: 0.1482 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.03563\n",
      "Epoch 300/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0381 - mean_absolute_error: 0.1368 - acc: 9.6525e-04 - val_loss: 0.0374 - val_mean_absolute_error: 0.1418 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.03563\n",
      "Epoch 301/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0378 - mean_absolute_error: 0.1378 - acc: 9.6525e-04 - val_loss: 0.0374 - val_mean_absolute_error: 0.1407 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.03563\n",
      "Epoch 302/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0372 - mean_absolute_error: 0.1353 - acc: 9.6525e-04 - val_loss: 0.0378 - val_mean_absolute_error: 0.1426 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.03563\n",
      "Epoch 303/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0368 - mean_absolute_error: 0.1341 - acc: 9.6525e-04 - val_loss: 0.0371 - val_mean_absolute_error: 0.1412 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.03563\n",
      "Epoch 304/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 0.0357 - mean_absolute_error: 0.1326 - acc: 9.6525e-04 - val_loss: 0.0427 - val_mean_absolute_error: 0.1527 - val_acc: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00304: val_loss did not improve from 0.03563\n",
      "Epoch 305/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0380 - mean_absolute_error: 0.1392 - acc: 9.6525e-04 - val_loss: 0.0393 - val_mean_absolute_error: 0.1447 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.03563\n",
      "Epoch 306/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 0.0370 - mean_absolute_error: 0.1360 - acc: 9.6525e-04 - val_loss: 0.0401 - val_mean_absolute_error: 0.1469 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.03563\n",
      "Epoch 307/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 0.0364 - mean_absolute_error: 0.1344 - acc: 9.6525e-04 - val_loss: 0.0363 - val_mean_absolute_error: 0.1384 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.03563\n",
      "Epoch 308/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0363 - mean_absolute_error: 0.1344 - acc: 9.6525e-04 - val_loss: 0.0383 - val_mean_absolute_error: 0.1437 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.03563\n",
      "Epoch 309/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 0.0364 - mean_absolute_error: 0.1341 - acc: 9.6525e-04 - val_loss: 0.0368 - val_mean_absolute_error: 0.1398 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.03563\n",
      "Epoch 310/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 0.0359 - mean_absolute_error: 0.1334 - acc: 9.6525e-04 - val_loss: 0.0393 - val_mean_absolute_error: 0.1459 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.03563\n",
      "Epoch 311/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 0.0364 - mean_absolute_error: 0.1342 - acc: 9.6525e-04 - val_loss: 0.0387 - val_mean_absolute_error: 0.1446 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.03563\n",
      "Epoch 312/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 0.0367 - mean_absolute_error: 0.1352 - acc: 9.6525e-04 - val_loss: 0.0420 - val_mean_absolute_error: 0.1513 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.03563\n",
      "Epoch 313/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 0.0359 - mean_absolute_error: 0.1334 - acc: 9.6525e-04 - val_loss: 0.0392 - val_mean_absolute_error: 0.1451 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.03563\n",
      "Epoch 314/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 0.0365 - mean_absolute_error: 0.1342 - acc: 9.6525e-04 - val_loss: 0.0376 - val_mean_absolute_error: 0.1421 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.03563\n",
      "Epoch 315/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 0.0362 - mean_absolute_error: 0.1336 - acc: 9.6525e-04 - val_loss: 0.0410 - val_mean_absolute_error: 0.1496 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.03563\n",
      "Epoch 316/500\n",
      "2072/2072 [==============================] - 0s 59us/step - loss: 0.0364 - mean_absolute_error: 0.1337 - acc: 9.6525e-04 - val_loss: 0.0396 - val_mean_absolute_error: 0.1458 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.03563\n",
      "Epoch 317/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 0.0358 - mean_absolute_error: 0.1331 - acc: 9.6525e-04 - val_loss: 0.0385 - val_mean_absolute_error: 0.1464 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.03563\n",
      "Epoch 318/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 0.0364 - mean_absolute_error: 0.1341 - acc: 9.6525e-04 - val_loss: 0.0420 - val_mean_absolute_error: 0.1535 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.03563\n",
      "Epoch 319/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0359 - mean_absolute_error: 0.1335 - acc: 9.6525e-04 - val_loss: 0.0413 - val_mean_absolute_error: 0.1493 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.03563\n",
      "Epoch 320/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 0.0360 - mean_absolute_error: 0.1337 - acc: 9.6525e-04 - val_loss: 0.0386 - val_mean_absolute_error: 0.1439 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.03563\n",
      "Epoch 321/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 0.0357 - mean_absolute_error: 0.1331 - acc: 9.6525e-04 - val_loss: 0.0384 - val_mean_absolute_error: 0.1438 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.03563\n",
      "Epoch 322/500\n",
      "2072/2072 [==============================] - 0s 66us/step - loss: 0.0380 - mean_absolute_error: 0.1383 - acc: 9.6525e-04 - val_loss: 0.0412 - val_mean_absolute_error: 0.1495 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.03563\n",
      "Epoch 323/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 0.0374 - mean_absolute_error: 0.1365 - acc: 9.6525e-04 - val_loss: 0.0399 - val_mean_absolute_error: 0.1462 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.03563\n",
      "Epoch 324/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0362 - mean_absolute_error: 0.1336 - acc: 9.6525e-04 - val_loss: 0.0415 - val_mean_absolute_error: 0.1504 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.03563\n",
      "Epoch 325/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 0.0367 - mean_absolute_error: 0.1343 - acc: 9.6525e-04 - val_loss: 0.0393 - val_mean_absolute_error: 0.1454 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.03563\n",
      "Epoch 326/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0367 - mean_absolute_error: 0.1339 - acc: 9.6525e-04 - val_loss: 0.0443 - val_mean_absolute_error: 0.1555 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.03563\n",
      "Epoch 327/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 0.0351 - mean_absolute_error: 0.1324 - acc: 9.6525e-04 - val_loss: 0.0428 - val_mean_absolute_error: 0.1524 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.03563\n",
      "Epoch 328/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 0.0364 - mean_absolute_error: 0.1345 - acc: 9.6525e-04 - val_loss: 0.0403 - val_mean_absolute_error: 0.1488 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.03563\n",
      "Epoch 329/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 0.0373 - mean_absolute_error: 0.1365 - acc: 9.6525e-04 - val_loss: 0.0420 - val_mean_absolute_error: 0.1500 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.03563\n",
      "Epoch 330/500\n",
      "2072/2072 [==============================] - 0s 55us/step - loss: 0.0363 - mean_absolute_error: 0.1337 - acc: 9.6525e-04 - val_loss: 0.0452 - val_mean_absolute_error: 0.1576 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.03563\n",
      "Epoch 331/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0366 - mean_absolute_error: 0.1347 - acc: 9.6525e-04 - val_loss: 0.0463 - val_mean_absolute_error: 0.1590 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.03563\n",
      "Epoch 332/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 0.0372 - mean_absolute_error: 0.1358 - acc: 9.6525e-04 - val_loss: 0.0399 - val_mean_absolute_error: 0.1463 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.03563\n",
      "Epoch 333/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0378 - mean_absolute_error: 0.1368 - acc: 9.6525e-04 - val_loss: 0.0465 - val_mean_absolute_error: 0.1598 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.03563\n",
      "Epoch 334/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 0.0381 - mean_absolute_error: 0.1378 - acc: 9.6525e-04 - val_loss: 0.0497 - val_mean_absolute_error: 0.1662 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.03563\n",
      "Epoch 335/500\n",
      "2072/2072 [==============================] - 0s 66us/step - loss: 0.0414 - mean_absolute_error: 0.1445 - acc: 9.6525e-04 - val_loss: 0.0553 - val_mean_absolute_error: 0.1760 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.03563\n",
      "Epoch 336/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 0.0488 - mean_absolute_error: 0.1581 - acc: 9.6525e-04 - val_loss: 0.0416 - val_mean_absolute_error: 0.1493 - val_acc: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00336: val_loss did not improve from 0.03563\n",
      "Epoch 337/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0495 - mean_absolute_error: 0.1608 - acc: 9.6525e-04 - val_loss: 0.0402 - val_mean_absolute_error: 0.1450 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.03563\n",
      "Epoch 338/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 0.0442 - mean_absolute_error: 0.1510 - acc: 9.6525e-04 - val_loss: 0.0387 - val_mean_absolute_error: 0.1433 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.03563\n",
      "Epoch 339/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 0.0447 - mean_absolute_error: 0.1516 - acc: 9.6525e-04 - val_loss: 0.0396 - val_mean_absolute_error: 0.1450 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.03563\n",
      "Epoch 340/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0433 - mean_absolute_error: 0.1485 - acc: 9.6525e-04 - val_loss: 0.0432 - val_mean_absolute_error: 0.1542 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.03563\n",
      "Epoch 341/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 0.0457 - mean_absolute_error: 0.1549 - acc: 9.6525e-04 - val_loss: 0.0380 - val_mean_absolute_error: 0.1418 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.03563\n",
      "Epoch 342/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 0.0444 - mean_absolute_error: 0.1511 - acc: 9.6525e-04 - val_loss: 0.0378 - val_mean_absolute_error: 0.1399 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.03563\n",
      "Epoch 343/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 0.0417 - mean_absolute_error: 0.1458 - acc: 9.6525e-04 - val_loss: 0.0389 - val_mean_absolute_error: 0.1441 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.03563\n",
      "Epoch 00343: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1a1ecb5940>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN_baseline(X, y_MD, 'MD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2072 samples, validate on 518 samples\n",
      "Epoch 1/500\n",
      "2072/2072 [==============================] - 1s 317us/step - loss: 4065.3045 - mean_absolute_error: 57.4866 - acc: 0.0039 - val_loss: 170.6302 - val_mean_absolute_error: 10.8866 - val_acc: 0.0290\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 170.63021, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 2/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 101.5144 - mean_absolute_error: 7.7217 - acc: 0.0410 - val_loss: 61.5753 - val_mean_absolute_error: 6.0368 - val_acc: 0.0598\n",
      "\n",
      "Epoch 00002: val_loss improved from 170.63021 to 61.57529, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 3/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 69.8286 - mean_absolute_error: 6.3521 - acc: 0.0589 - val_loss: 60.6561 - val_mean_absolute_error: 5.9412 - val_acc: 0.0714\n",
      "\n",
      "Epoch 00003: val_loss improved from 61.57529 to 60.65615, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 4/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 67.9939 - mean_absolute_error: 6.2509 - acc: 0.0569 - val_loss: 58.9418 - val_mean_absolute_error: 5.8419 - val_acc: 0.0714\n",
      "\n",
      "Epoch 00004: val_loss improved from 60.65615 to 58.94182, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 5/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 66.0069 - mean_absolute_error: 6.1397 - acc: 0.0598 - val_loss: 56.8144 - val_mean_absolute_error: 5.7251 - val_acc: 0.0676\n",
      "\n",
      "Epoch 00005: val_loss improved from 58.94182 to 56.81444, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 6/500\n",
      "2072/2072 [==============================] - 0s 85us/step - loss: 63.9999 - mean_absolute_error: 6.0297 - acc: 0.0594 - val_loss: 54.7448 - val_mean_absolute_error: 5.6098 - val_acc: 0.0714\n",
      "\n",
      "Epoch 00006: val_loss improved from 56.81444 to 54.74477, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 7/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 61.9654 - mean_absolute_error: 5.9185 - acc: 0.0613 - val_loss: 52.7030 - val_mean_absolute_error: 5.4941 - val_acc: 0.0753\n",
      "\n",
      "Epoch 00007: val_loss improved from 54.74477 to 52.70302, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 8/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 59.8803 - mean_absolute_error: 5.8045 - acc: 0.0613 - val_loss: 50.6186 - val_mean_absolute_error: 5.3735 - val_acc: 0.0734\n",
      "\n",
      "Epoch 00008: val_loss improved from 52.70302 to 50.61855, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 9/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 57.7262 - mean_absolute_error: 5.6858 - acc: 0.0632 - val_loss: 48.4138 - val_mean_absolute_error: 5.2466 - val_acc: 0.0753\n",
      "\n",
      "Epoch 00009: val_loss improved from 50.61855 to 48.41384, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 10/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 55.4887 - mean_absolute_error: 5.5604 - acc: 0.0642 - val_loss: 46.0591 - val_mean_absolute_error: 5.1116 - val_acc: 0.0772\n",
      "\n",
      "Epoch 00010: val_loss improved from 48.41384 to 46.05914, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 11/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 53.1515 - mean_absolute_error: 5.4289 - acc: 0.0676 - val_loss: 43.5601 - val_mean_absolute_error: 4.9689 - val_acc: 0.0830\n",
      "\n",
      "Epoch 00011: val_loss improved from 46.05914 to 43.56006, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 12/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 50.6918 - mean_absolute_error: 5.2889 - acc: 0.0642 - val_loss: 40.9127 - val_mean_absolute_error: 4.8166 - val_acc: 0.0888\n",
      "\n",
      "Epoch 00012: val_loss improved from 43.56006 to 40.91268, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 13/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 48.0829 - mean_absolute_error: 5.1366 - acc: 0.0613 - val_loss: 38.1136 - val_mean_absolute_error: 4.6495 - val_acc: 0.0946\n",
      "\n",
      "Epoch 00013: val_loss improved from 40.91268 to 38.11358, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 14/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 45.2991 - mean_absolute_error: 4.9678 - acc: 0.0685 - val_loss: 35.1696 - val_mean_absolute_error: 4.4677 - val_acc: 0.1004\n",
      "\n",
      "Epoch 00014: val_loss improved from 38.11358 to 35.16958, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 15/500\n",
      "2072/2072 [==============================] - 0s 53us/step - loss: 42.3212 - mean_absolute_error: 4.7794 - acc: 0.0782 - val_loss: 32.0944 - val_mean_absolute_error: 4.2743 - val_acc: 0.1081\n",
      "\n",
      "Epoch 00015: val_loss improved from 35.16958 to 32.09443, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 16/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 39.1511 - mean_absolute_error: 4.5726 - acc: 0.0792 - val_loss: 28.8989 - val_mean_absolute_error: 4.0679 - val_acc: 0.0927\n",
      "\n",
      "Epoch 00016: val_loss improved from 32.09443 to 28.89890, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 17/500\n",
      "2072/2072 [==============================] - 0s 52us/step - loss: 35.8310 - mean_absolute_error: 4.3452 - acc: 0.0787 - val_loss: 25.6157 - val_mean_absolute_error: 3.8421 - val_acc: 0.0792\n",
      "\n",
      "Epoch 00017: val_loss improved from 28.89890 to 25.61572, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 18/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 32.4678 - mean_absolute_error: 4.0999 - acc: 0.0849 - val_loss: 22.3461 - val_mean_absolute_error: 3.6078 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00018: val_loss improved from 25.61572 to 22.34612, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 19/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 29.2544 - mean_absolute_error: 3.8449 - acc: 0.0999 - val_loss: 19.3037 - val_mean_absolute_error: 3.3749 - val_acc: 0.0907\n",
      "\n",
      "Epoch 00019: val_loss improved from 22.34612 to 19.30374, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 20/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 26.4614 - mean_absolute_error: 3.6127 - acc: 0.1076 - val_loss: 16.7488 - val_mean_absolute_error: 3.1517 - val_acc: 0.1004\n",
      "\n",
      "Epoch 00020: val_loss improved from 19.30374 to 16.74878, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 21/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 24.3473 - mean_absolute_error: 3.4230 - acc: 0.1110 - val_loss: 14.8189 - val_mean_absolute_error: 2.9600 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00021: val_loss improved from 16.74878 to 14.81886, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 22/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 22.9512 - mean_absolute_error: 3.2914 - acc: 0.1125 - val_loss: 13.5528 - val_mean_absolute_error: 2.8163 - val_acc: 0.1062\n",
      "\n",
      "Epoch 00022: val_loss improved from 14.81886 to 13.55277, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 23/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 22.0856 - mean_absolute_error: 3.2141 - acc: 0.1047 - val_loss: 12.9663 - val_mean_absolute_error: 2.7333 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00023: val_loss improved from 13.55277 to 12.96626, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 24/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 21.5543 - mean_absolute_error: 3.1644 - acc: 0.1125 - val_loss: 12.7982 - val_mean_absolute_error: 2.7048 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00024: val_loss improved from 12.96626 to 12.79823, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 25/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 21.1653 - mean_absolute_error: 3.1255 - acc: 0.1144 - val_loss: 12.7047 - val_mean_absolute_error: 2.6890 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00025: val_loss improved from 12.79823 to 12.70471, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 26/500\n",
      "2072/2072 [==============================] - 0s 52us/step - loss: 20.8892 - mean_absolute_error: 3.0955 - acc: 0.1139 - val_loss: 12.6600 - val_mean_absolute_error: 2.6813 - val_acc: 0.1158\n",
      "\n",
      "Epoch 00026: val_loss improved from 12.70471 to 12.66003, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 27/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 20.6857 - mean_absolute_error: 3.0729 - acc: 0.1076 - val_loss: 12.6379 - val_mean_absolute_error: 2.6810 - val_acc: 0.1178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00027: val_loss improved from 12.66003 to 12.63791, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 28/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 20.5189 - mean_absolute_error: 3.0524 - acc: 0.1125 - val_loss: 12.6158 - val_mean_absolute_error: 2.6787 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00028: val_loss improved from 12.63791 to 12.61577, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 29/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 20.3990 - mean_absolute_error: 3.0375 - acc: 0.1134 - val_loss: 12.5988 - val_mean_absolute_error: 2.6771 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00029: val_loss improved from 12.61577 to 12.59883, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 30/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 20.2988 - mean_absolute_error: 3.0246 - acc: 0.1139 - val_loss: 12.5733 - val_mean_absolute_error: 2.6749 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00030: val_loss improved from 12.59883 to 12.57334, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 31/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 20.2151 - mean_absolute_error: 3.0137 - acc: 0.1139 - val_loss: 12.5593 - val_mean_absolute_error: 2.6730 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00031: val_loss improved from 12.57334 to 12.55930, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 32/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 20.1477 - mean_absolute_error: 3.0060 - acc: 0.1153 - val_loss: 12.5332 - val_mean_absolute_error: 2.6698 - val_acc: 0.1216\n",
      "\n",
      "Epoch 00032: val_loss improved from 12.55930 to 12.53325, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 33/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 20.0837 - mean_absolute_error: 2.9967 - acc: 0.1134 - val_loss: 12.5248 - val_mean_absolute_error: 2.6691 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00033: val_loss improved from 12.53325 to 12.52483, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 34/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 20.0245 - mean_absolute_error: 2.9892 - acc: 0.1144 - val_loss: 12.5232 - val_mean_absolute_error: 2.6692 - val_acc: 0.1216\n",
      "\n",
      "Epoch 00034: val_loss improved from 12.52483 to 12.52319, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 35/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 19.9728 - mean_absolute_error: 2.9823 - acc: 0.1120 - val_loss: 12.5151 - val_mean_absolute_error: 2.6684 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00035: val_loss improved from 12.52319 to 12.51506, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 36/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 19.9254 - mean_absolute_error: 2.9759 - acc: 0.1125 - val_loss: 12.5243 - val_mean_absolute_error: 2.6700 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 12.51506\n",
      "Epoch 37/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 19.8794 - mean_absolute_error: 2.9699 - acc: 0.1163 - val_loss: 12.5240 - val_mean_absolute_error: 2.6701 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 12.51506\n",
      "Epoch 38/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 19.8416 - mean_absolute_error: 2.9643 - acc: 0.1178 - val_loss: 12.5097 - val_mean_absolute_error: 2.6683 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00038: val_loss improved from 12.51506 to 12.50974, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 39/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 19.8070 - mean_absolute_error: 2.9598 - acc: 0.1216 - val_loss: 12.5083 - val_mean_absolute_error: 2.6681 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00039: val_loss improved from 12.50974 to 12.50828, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 40/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 19.7805 - mean_absolute_error: 2.9561 - acc: 0.1245 - val_loss: 12.5070 - val_mean_absolute_error: 2.6679 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00040: val_loss improved from 12.50828 to 12.50695, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 41/500\n",
      "2072/2072 [==============================] - 0s 59us/step - loss: 19.7512 - mean_absolute_error: 2.9519 - acc: 0.1245 - val_loss: 12.4834 - val_mean_absolute_error: 2.6656 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00041: val_loss improved from 12.50695 to 12.48341, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 42/500\n",
      "2072/2072 [==============================] - 0s 59us/step - loss: 19.7259 - mean_absolute_error: 2.9484 - acc: 0.1211 - val_loss: 12.4610 - val_mean_absolute_error: 2.6629 - val_acc: 0.1158\n",
      "\n",
      "Epoch 00042: val_loss improved from 12.48341 to 12.46100, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 43/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 19.7028 - mean_absolute_error: 2.9460 - acc: 0.1221 - val_loss: 12.4493 - val_mean_absolute_error: 2.6615 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00043: val_loss improved from 12.46100 to 12.44929, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 44/500\n",
      "2072/2072 [==============================] - 0s 64us/step - loss: 19.6835 - mean_absolute_error: 2.9437 - acc: 0.1211 - val_loss: 12.4504 - val_mean_absolute_error: 2.6619 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 12.44929\n",
      "Epoch 45/500\n",
      "2072/2072 [==============================] - 0s 64us/step - loss: 19.6655 - mean_absolute_error: 2.9420 - acc: 0.1221 - val_loss: 12.4489 - val_mean_absolute_error: 2.6617 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00045: val_loss improved from 12.44929 to 12.44891, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 46/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 19.6538 - mean_absolute_error: 2.9407 - acc: 0.1236 - val_loss: 12.4507 - val_mean_absolute_error: 2.6620 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 12.44891\n",
      "Epoch 47/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 19.6379 - mean_absolute_error: 2.9393 - acc: 0.1236 - val_loss: 12.4405 - val_mean_absolute_error: 2.6611 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00047: val_loss improved from 12.44891 to 12.44054, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 48/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 19.6263 - mean_absolute_error: 2.9385 - acc: 0.1221 - val_loss: 12.4486 - val_mean_absolute_error: 2.6619 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 12.44054\n",
      "Epoch 49/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 19.6159 - mean_absolute_error: 2.9378 - acc: 0.1240 - val_loss: 12.4382 - val_mean_absolute_error: 2.6609 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00049: val_loss improved from 12.44054 to 12.43822, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 50/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 19.6058 - mean_absolute_error: 2.9372 - acc: 0.1231 - val_loss: 12.4345 - val_mean_absolute_error: 2.6605 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00050: val_loss improved from 12.43822 to 12.43453, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 51/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 19.5957 - mean_absolute_error: 2.9365 - acc: 0.1236 - val_loss: 12.4403 - val_mean_absolute_error: 2.6616 - val_acc: 0.1100\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 12.43453\n",
      "Epoch 52/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 19.5859 - mean_absolute_error: 2.9360 - acc: 0.1240 - val_loss: 12.4411 - val_mean_absolute_error: 2.6620 - val_acc: 0.1100\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 12.43453\n",
      "Epoch 53/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 19.5761 - mean_absolute_error: 2.9355 - acc: 0.1236 - val_loss: 12.4367 - val_mean_absolute_error: 2.6615 - val_acc: 0.1100\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 12.43453\n",
      "Epoch 54/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 19.5670 - mean_absolute_error: 2.9352 - acc: 0.1226 - val_loss: 12.4382 - val_mean_absolute_error: 2.6619 - val_acc: 0.1100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 12.43453\n",
      "Epoch 55/500\n",
      "2072/2072 [==============================] - 0s 59us/step - loss: 19.5568 - mean_absolute_error: 2.9349 - acc: 0.1207 - val_loss: 12.4388 - val_mean_absolute_error: 2.6622 - val_acc: 0.1100\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 12.43453\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2072/2072 [==============================] - 0s 57us/step - loss: 19.5470 - mean_absolute_error: 2.9347 - acc: 0.1216 - val_loss: 12.4391 - val_mean_absolute_error: 2.6624 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 12.43453\n",
      "Epoch 57/500\n",
      "2072/2072 [==============================] - 0s 64us/step - loss: 19.5365 - mean_absolute_error: 2.9345 - acc: 0.1211 - val_loss: 12.4413 - val_mean_absolute_error: 2.6630 - val_acc: 0.1100\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 12.43453\n",
      "Epoch 58/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 19.5251 - mean_absolute_error: 2.9339 - acc: 0.1226 - val_loss: 12.4208 - val_mean_absolute_error: 2.6601 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00058: val_loss improved from 12.43453 to 12.42082, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 59/500\n",
      "2072/2072 [==============================] - 0s 53us/step - loss: 19.5187 - mean_absolute_error: 2.9343 - acc: 0.1221 - val_loss: 12.4397 - val_mean_absolute_error: 2.6634 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 12.42082\n",
      "Epoch 60/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 19.5038 - mean_absolute_error: 2.9337 - acc: 0.1207 - val_loss: 12.4270 - val_mean_absolute_error: 2.6618 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 12.42082\n",
      "Epoch 61/500\n",
      "2072/2072 [==============================] - 0s 59us/step - loss: 19.4949 - mean_absolute_error: 2.9334 - acc: 0.1202 - val_loss: 12.4194 - val_mean_absolute_error: 2.6609 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00061: val_loss improved from 12.42082 to 12.41941, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 62/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 19.4852 - mean_absolute_error: 2.9330 - acc: 0.1202 - val_loss: 12.4276 - val_mean_absolute_error: 2.6628 - val_acc: 0.1158\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 12.41941\n",
      "Epoch 63/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 19.4702 - mean_absolute_error: 2.9329 - acc: 0.1192 - val_loss: 12.4279 - val_mean_absolute_error: 2.6628 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 12.41941\n",
      "Epoch 64/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 19.4626 - mean_absolute_error: 2.9322 - acc: 0.1197 - val_loss: 12.4280 - val_mean_absolute_error: 2.6634 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 12.41941\n",
      "Epoch 65/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 19.4513 - mean_absolute_error: 2.9330 - acc: 0.1192 - val_loss: 12.4486 - val_mean_absolute_error: 2.6669 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 12.41941\n",
      "Epoch 66/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 19.4367 - mean_absolute_error: 2.9321 - acc: 0.1197 - val_loss: 12.4330 - val_mean_absolute_error: 2.6654 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 12.41941\n",
      "Epoch 67/500\n",
      "2072/2072 [==============================] - 0s 87us/step - loss: 19.4235 - mean_absolute_error: 2.9318 - acc: 0.1207 - val_loss: 12.4461 - val_mean_absolute_error: 2.6676 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 12.41941\n",
      "Epoch 68/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 19.4105 - mean_absolute_error: 2.9311 - acc: 0.1211 - val_loss: 12.4359 - val_mean_absolute_error: 2.6665 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 12.41941\n",
      "Epoch 69/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 19.4004 - mean_absolute_error: 2.9309 - acc: 0.1221 - val_loss: 12.4363 - val_mean_absolute_error: 2.6671 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 12.41941\n",
      "Epoch 70/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 19.3861 - mean_absolute_error: 2.9300 - acc: 0.1216 - val_loss: 12.4457 - val_mean_absolute_error: 2.6689 - val_acc: 0.1216\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 12.41941\n",
      "Epoch 71/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 19.3715 - mean_absolute_error: 2.9293 - acc: 0.1207 - val_loss: 12.4454 - val_mean_absolute_error: 2.6694 - val_acc: 0.1216\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 12.41941\n",
      "Epoch 72/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 19.3567 - mean_absolute_error: 2.9285 - acc: 0.1207 - val_loss: 12.4400 - val_mean_absolute_error: 2.6691 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 12.41941\n",
      "Epoch 73/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 19.3439 - mean_absolute_error: 2.9282 - acc: 0.1202 - val_loss: 12.4283 - val_mean_absolute_error: 2.6682 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 12.41941\n",
      "Epoch 74/500\n",
      "2072/2072 [==============================] - 0s 89us/step - loss: 19.3291 - mean_absolute_error: 2.9277 - acc: 0.1221 - val_loss: 12.4477 - val_mean_absolute_error: 2.6711 - val_acc: 0.1216\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 12.41941\n",
      "Epoch 75/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 19.3169 - mean_absolute_error: 2.9272 - acc: 0.1207 - val_loss: 12.4608 - val_mean_absolute_error: 2.6736 - val_acc: 0.1216\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 12.41941\n",
      "Epoch 76/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 19.3011 - mean_absolute_error: 2.9266 - acc: 0.1207 - val_loss: 12.4671 - val_mean_absolute_error: 2.6749 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 12.41941\n",
      "Epoch 77/500\n",
      "2072/2072 [==============================] - 0s 99us/step - loss: 19.2857 - mean_absolute_error: 2.9256 - acc: 0.1202 - val_loss: 12.4407 - val_mean_absolute_error: 2.6720 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 12.41941\n",
      "Epoch 78/500\n",
      "2072/2072 [==============================] - 0s 100us/step - loss: 19.2719 - mean_absolute_error: 2.9250 - acc: 0.1202 - val_loss: 12.4700 - val_mean_absolute_error: 2.6761 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 12.41941\n",
      "Epoch 79/500\n",
      "2072/2072 [==============================] - 0s 118us/step - loss: 19.2606 - mean_absolute_error: 2.9253 - acc: 0.1197 - val_loss: 12.4617 - val_mean_absolute_error: 2.6756 - val_acc: 0.1216\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 12.41941\n",
      "Epoch 80/500\n",
      "2072/2072 [==============================] - 0s 91us/step - loss: 19.2438 - mean_absolute_error: 2.9242 - acc: 0.1207 - val_loss: 12.4620 - val_mean_absolute_error: 2.6761 - val_acc: 0.1216\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 12.41941\n",
      "Epoch 81/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 19.2269 - mean_absolute_error: 2.9233 - acc: 0.1207 - val_loss: 12.4587 - val_mean_absolute_error: 2.6761 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 12.41941\n",
      "Epoch 82/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 19.2122 - mean_absolute_error: 2.9230 - acc: 0.1221 - val_loss: 12.4525 - val_mean_absolute_error: 2.6754 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 12.41941\n",
      "Epoch 83/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 19.2024 - mean_absolute_error: 2.9229 - acc: 0.1226 - val_loss: 12.4552 - val_mean_absolute_error: 2.6761 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 12.41941\n",
      "Epoch 84/500\n",
      "2072/2072 [==============================] - 0s 85us/step - loss: 19.1867 - mean_absolute_error: 2.9220 - acc: 0.1236 - val_loss: 12.4539 - val_mean_absolute_error: 2.6765 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 12.41941\n",
      "Epoch 85/500\n",
      "2072/2072 [==============================] - 0s 93us/step - loss: 19.1709 - mean_absolute_error: 2.9214 - acc: 0.1236 - val_loss: 12.4595 - val_mean_absolute_error: 2.6772 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 12.41941\n",
      "Epoch 86/500\n",
      "2072/2072 [==============================] - 0s 113us/step - loss: 19.1611 - mean_absolute_error: 2.9210 - acc: 0.1240 - val_loss: 12.4571 - val_mean_absolute_error: 2.6772 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 12.41941\n",
      "Epoch 87/500\n",
      "2072/2072 [==============================] - 0s 112us/step - loss: 19.1475 - mean_absolute_error: 2.9205 - acc: 0.1226 - val_loss: 12.4564 - val_mean_absolute_error: 2.6774 - val_acc: 0.1178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00087: val_loss did not improve from 12.41941\n",
      "Epoch 88/500\n",
      "2072/2072 [==============================] - 0s 102us/step - loss: 19.1329 - mean_absolute_error: 2.9199 - acc: 0.1226 - val_loss: 12.4559 - val_mean_absolute_error: 2.6779 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 12.41941\n",
      "Epoch 89/500\n",
      "2072/2072 [==============================] - 0s 92us/step - loss: 19.1196 - mean_absolute_error: 2.9182 - acc: 0.1250 - val_loss: 12.4516 - val_mean_absolute_error: 2.6776 - val_acc: 0.1158\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 12.41941\n",
      "Epoch 90/500\n",
      "2072/2072 [==============================] - 0s 87us/step - loss: 19.1023 - mean_absolute_error: 2.9179 - acc: 0.1240 - val_loss: 12.4446 - val_mean_absolute_error: 2.6770 - val_acc: 0.1158\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 12.41941\n",
      "Epoch 91/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 19.0892 - mean_absolute_error: 2.9173 - acc: 0.1236 - val_loss: 12.4307 - val_mean_absolute_error: 2.6747 - val_acc: 0.1158\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 12.41941\n",
      "Epoch 92/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 19.0763 - mean_absolute_error: 2.9167 - acc: 0.1236 - val_loss: 12.4298 - val_mean_absolute_error: 2.6748 - val_acc: 0.1158\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 12.41941\n",
      "Epoch 93/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 19.0635 - mean_absolute_error: 2.9162 - acc: 0.1236 - val_loss: 12.4307 - val_mean_absolute_error: 2.6750 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 12.41941\n",
      "Epoch 94/500\n",
      "2072/2072 [==============================] - 0s 97us/step - loss: 19.0499 - mean_absolute_error: 2.9156 - acc: 0.1236 - val_loss: 12.4272 - val_mean_absolute_error: 2.6748 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 12.41941\n",
      "Epoch 95/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 19.0360 - mean_absolute_error: 2.9151 - acc: 0.1236 - val_loss: 12.4243 - val_mean_absolute_error: 2.6749 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 12.41941\n",
      "Epoch 96/500\n",
      "2072/2072 [==============================] - 0s 89us/step - loss: 19.0222 - mean_absolute_error: 2.9145 - acc: 0.1231 - val_loss: 12.4218 - val_mean_absolute_error: 2.6749 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 12.41941\n",
      "Epoch 97/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 19.0083 - mean_absolute_error: 2.9140 - acc: 0.1226 - val_loss: 12.4490 - val_mean_absolute_error: 2.6787 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 12.41941\n",
      "Epoch 98/500\n",
      "2072/2072 [==============================] - 0s 66us/step - loss: 18.9926 - mean_absolute_error: 2.9134 - acc: 0.1240 - val_loss: 12.4477 - val_mean_absolute_error: 2.6789 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 12.41941\n",
      "Epoch 99/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 18.9809 - mean_absolute_error: 2.9130 - acc: 0.1240 - val_loss: 12.4478 - val_mean_absolute_error: 2.6792 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 12.41941\n",
      "Epoch 100/500\n",
      "2072/2072 [==============================] - 0s 91us/step - loss: 18.9664 - mean_absolute_error: 2.9123 - acc: 0.1231 - val_loss: 12.4449 - val_mean_absolute_error: 2.6793 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 12.41941\n",
      "Epoch 101/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 18.9538 - mean_absolute_error: 2.9118 - acc: 0.1236 - val_loss: 12.4419 - val_mean_absolute_error: 2.6793 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 12.41941\n",
      "Epoch 102/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 18.9363 - mean_absolute_error: 2.9110 - acc: 0.1231 - val_loss: 12.3993 - val_mean_absolute_error: 2.6757 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00102: val_loss improved from 12.41941 to 12.39934, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 103/500\n",
      "2072/2072 [==============================] - 0s 87us/step - loss: 18.9281 - mean_absolute_error: 2.9109 - acc: 0.1255 - val_loss: 12.4378 - val_mean_absolute_error: 2.6792 - val_acc: 0.1100\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 12.39934\n",
      "Epoch 104/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 18.9196 - mean_absolute_error: 2.9110 - acc: 0.1236 - val_loss: 12.4393 - val_mean_absolute_error: 2.6795 - val_acc: 0.1100\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 12.39934\n",
      "Epoch 105/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 18.9060 - mean_absolute_error: 2.9103 - acc: 0.1245 - val_loss: 12.4374 - val_mean_absolute_error: 2.6797 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 12.39934\n",
      "Epoch 106/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 18.8910 - mean_absolute_error: 2.9096 - acc: 0.1250 - val_loss: 12.4395 - val_mean_absolute_error: 2.6804 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 12.39934\n",
      "Epoch 107/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 18.8800 - mean_absolute_error: 2.9094 - acc: 0.1250 - val_loss: 12.4369 - val_mean_absolute_error: 2.6801 - val_acc: 0.1100\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 12.39934\n",
      "Epoch 108/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 18.8690 - mean_absolute_error: 2.9092 - acc: 0.1236 - val_loss: 12.4355 - val_mean_absolute_error: 2.6802 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 12.39934\n",
      "Epoch 109/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 18.8566 - mean_absolute_error: 2.9086 - acc: 0.1236 - val_loss: 12.4342 - val_mean_absolute_error: 2.6804 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 12.39934\n",
      "Epoch 110/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 18.8434 - mean_absolute_error: 2.9081 - acc: 0.1245 - val_loss: 12.4333 - val_mean_absolute_error: 2.6808 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 12.39934\n",
      "Epoch 111/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 18.8329 - mean_absolute_error: 2.9079 - acc: 0.1245 - val_loss: 12.4345 - val_mean_absolute_error: 2.6812 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 12.39934\n",
      "Epoch 112/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 18.8226 - mean_absolute_error: 2.9049 - acc: 0.1231 - val_loss: 12.1892 - val_mean_absolute_error: 2.6511 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00112: val_loss improved from 12.39934 to 12.18919, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 113/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 18.7925 - mean_absolute_error: 2.9056 - acc: 0.1264 - val_loss: 12.4142 - val_mean_absolute_error: 2.6794 - val_acc: 0.1158\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 12.18919\n",
      "Epoch 114/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 18.7919 - mean_absolute_error: 2.9062 - acc: 0.1255 - val_loss: 12.4221 - val_mean_absolute_error: 2.6807 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 12.18919\n",
      "Epoch 115/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 18.7818 - mean_absolute_error: 2.9061 - acc: 0.1231 - val_loss: 12.4187 - val_mean_absolute_error: 2.6806 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 12.18919\n",
      "Epoch 116/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 18.7699 - mean_absolute_error: 2.9059 - acc: 0.1231 - val_loss: 12.4186 - val_mean_absolute_error: 2.6808 - val_acc: 0.1158\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 12.18919\n",
      "Epoch 117/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 18.7570 - mean_absolute_error: 2.9052 - acc: 0.1221 - val_loss: 12.4167 - val_mean_absolute_error: 2.6808 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 12.18919\n",
      "Epoch 118/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 18.7470 - mean_absolute_error: 2.9041 - acc: 0.1226 - val_loss: 12.3878 - val_mean_absolute_error: 2.6772 - val_acc: 0.1158\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 12.18919\n",
      "Epoch 119/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 18.7297 - mean_absolute_error: 2.9042 - acc: 0.1231 - val_loss: 12.3979 - val_mean_absolute_error: 2.6793 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 12.18919\n",
      "Epoch 120/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 18.7198 - mean_absolute_error: 2.9038 - acc: 0.1240 - val_loss: 12.3992 - val_mean_absolute_error: 2.6795 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 12.18919\n",
      "Epoch 121/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 18.7091 - mean_absolute_error: 2.9034 - acc: 0.1240 - val_loss: 12.3972 - val_mean_absolute_error: 2.6795 - val_acc: 0.1158\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 12.18919\n",
      "Epoch 122/500\n",
      "2072/2072 [==============================] - 0s 91us/step - loss: 18.6974 - mean_absolute_error: 2.9029 - acc: 0.1236 - val_loss: 12.3955 - val_mean_absolute_error: 2.6795 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 12.18919\n",
      "Epoch 123/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 18.6866 - mean_absolute_error: 2.9027 - acc: 0.1240 - val_loss: 12.3947 - val_mean_absolute_error: 2.6796 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 12.18919\n",
      "Epoch 124/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 18.6735 - mean_absolute_error: 2.9018 - acc: 0.1245 - val_loss: 12.3930 - val_mean_absolute_error: 2.6797 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 12.18919\n",
      "Epoch 125/500\n",
      "2072/2072 [==============================] - 0s 92us/step - loss: 18.6620 - mean_absolute_error: 2.9017 - acc: 0.1255 - val_loss: 12.3878 - val_mean_absolute_error: 2.6795 - val_acc: 0.1100\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 12.18919\n",
      "Epoch 126/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 18.6502 - mean_absolute_error: 2.9009 - acc: 0.1260 - val_loss: 12.3885 - val_mean_absolute_error: 2.6795 - val_acc: 0.1100\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 12.18919\n",
      "Epoch 127/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 18.6370 - mean_absolute_error: 2.9006 - acc: 0.1260 - val_loss: 12.3842 - val_mean_absolute_error: 2.6792 - val_acc: 0.1100\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 12.18919\n",
      "Epoch 128/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 18.6243 - mean_absolute_error: 2.8999 - acc: 0.1264 - val_loss: 12.3820 - val_mean_absolute_error: 2.6791 - val_acc: 0.1100\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 12.18919\n",
      "Epoch 129/500\n",
      "2072/2072 [==============================] - 0s 95us/step - loss: 18.6117 - mean_absolute_error: 2.8993 - acc: 0.1260 - val_loss: 12.3815 - val_mean_absolute_error: 2.6796 - val_acc: 0.1100\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 12.18919\n",
      "Epoch 130/500\n",
      "2072/2072 [==============================] - 0s 104us/step - loss: 18.6002 - mean_absolute_error: 2.8989 - acc: 0.1260 - val_loss: 12.3728 - val_mean_absolute_error: 2.6787 - val_acc: 0.1100\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 12.18919\n",
      "Epoch 131/500\n",
      "2072/2072 [==============================] - 0s 90us/step - loss: 18.5888 - mean_absolute_error: 2.8983 - acc: 0.1274 - val_loss: 12.3734 - val_mean_absolute_error: 2.6791 - val_acc: 0.1100\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 12.18919\n",
      "Epoch 132/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 18.5773 - mean_absolute_error: 2.8980 - acc: 0.1269 - val_loss: 12.3648 - val_mean_absolute_error: 2.6780 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 12.18919\n",
      "Epoch 133/500\n",
      "2072/2072 [==============================] - 0s 96us/step - loss: 18.5618 - mean_absolute_error: 2.8970 - acc: 0.1274 - val_loss: 12.3213 - val_mean_absolute_error: 2.6745 - val_acc: 0.1100\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 12.18919\n",
      "Epoch 134/500\n",
      "2072/2072 [==============================] - 0s 101us/step - loss: 18.5513 - mean_absolute_error: 2.8964 - acc: 0.1260 - val_loss: 12.3148 - val_mean_absolute_error: 2.6740 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 12.18919\n",
      "Epoch 135/500\n",
      "2072/2072 [==============================] - 0s 93us/step - loss: 18.5370 - mean_absolute_error: 2.8958 - acc: 0.1274 - val_loss: 12.3083 - val_mean_absolute_error: 2.6733 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 12.18919\n",
      "Epoch 136/500\n",
      "2072/2072 [==============================] - 0s 97us/step - loss: 18.5282 - mean_absolute_error: 2.8956 - acc: 0.1269 - val_loss: 12.3494 - val_mean_absolute_error: 2.6771 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 12.18919\n",
      "Epoch 137/500\n",
      "2072/2072 [==============================] - 0s 102us/step - loss: 18.5141 - mean_absolute_error: 2.8949 - acc: 0.1279 - val_loss: 12.3005 - val_mean_absolute_error: 2.6726 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 12.18919\n",
      "Epoch 138/500\n",
      "2072/2072 [==============================] - 0s 97us/step - loss: 18.5013 - mean_absolute_error: 2.8942 - acc: 0.1289 - val_loss: 12.2950 - val_mean_absolute_error: 2.6722 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 12.18919\n",
      "Epoch 139/500\n",
      "2072/2072 [==============================] - 0s 95us/step - loss: 18.4907 - mean_absolute_error: 2.8937 - acc: 0.1293 - val_loss: 12.2898 - val_mean_absolute_error: 2.6718 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 12.18919\n",
      "Epoch 140/500\n",
      "2072/2072 [==============================] - 0s 99us/step - loss: 18.4818 - mean_absolute_error: 2.8935 - acc: 0.1284 - val_loss: 12.3211 - val_mean_absolute_error: 2.6747 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 12.18919\n",
      "Epoch 141/500\n",
      "2072/2072 [==============================] - 0s 93us/step - loss: 18.4657 - mean_absolute_error: 2.8926 - acc: 0.1289 - val_loss: 12.2811 - val_mean_absolute_error: 2.6710 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 12.18919\n",
      "Epoch 142/500\n",
      "2072/2072 [==============================] - 0s 93us/step - loss: 18.4526 - mean_absolute_error: 2.8914 - acc: 0.1274 - val_loss: 12.2583 - val_mean_absolute_error: 2.6681 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 12.18919\n",
      "Epoch 143/500\n",
      "2072/2072 [==============================] - 0s 98us/step - loss: 18.4379 - mean_absolute_error: 2.8901 - acc: 0.1279 - val_loss: 12.2575 - val_mean_absolute_error: 2.6664 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 12.18919\n",
      "Epoch 144/500\n",
      "2072/2072 [==============================] - 0s 95us/step - loss: 18.4352 - mean_absolute_error: 2.8921 - acc: 0.1298 - val_loss: 12.3145 - val_mean_absolute_error: 2.6747 - val_acc: 0.1120\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 12.18919\n",
      "Epoch 145/500\n",
      "2072/2072 [==============================] - 0s 100us/step - loss: 18.4283 - mean_absolute_error: 2.8907 - acc: 0.1279 - val_loss: 12.2502 - val_mean_absolute_error: 2.6647 - val_acc: 0.1158\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 12.18919\n",
      "Epoch 146/500\n",
      "2072/2072 [==============================] - 0s 95us/step - loss: 18.4206 - mean_absolute_error: 2.8925 - acc: 0.1274 - val_loss: 12.3035 - val_mean_absolute_error: 2.6739 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 12.18919\n",
      "Epoch 147/500\n",
      "2072/2072 [==============================] - 0s 96us/step - loss: 18.4050 - mean_absolute_error: 2.8905 - acc: 0.1308 - val_loss: 12.2971 - val_mean_absolute_error: 2.6730 - val_acc: 0.1158\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 12.18919\n",
      "Epoch 148/500\n",
      "2072/2072 [==============================] - 0s 88us/step - loss: 18.3984 - mean_absolute_error: 2.8904 - acc: 0.1274 - val_loss: 12.2699 - val_mean_absolute_error: 2.6687 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 12.18919\n",
      "Epoch 149/500\n",
      "2072/2072 [==============================] - 0s 97us/step - loss: 18.3918 - mean_absolute_error: 2.8911 - acc: 0.1269 - val_loss: 12.2866 - val_mean_absolute_error: 2.6722 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 12.18919\n",
      "Epoch 150/500\n",
      "2072/2072 [==============================] - 0s 96us/step - loss: 18.3733 - mean_absolute_error: 2.8899 - acc: 0.1279 - val_loss: 12.2545 - val_mean_absolute_error: 2.6683 - val_acc: 0.1158\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 12.18919\n",
      "Epoch 151/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2072/2072 [==============================] - 0s 97us/step - loss: 18.3680 - mean_absolute_error: 2.8890 - acc: 0.1289 - val_loss: 12.2757 - val_mean_absolute_error: 2.6707 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 12.18919\n",
      "Epoch 152/500\n",
      "2072/2072 [==============================] - 0s 95us/step - loss: 18.3557 - mean_absolute_error: 2.8884 - acc: 0.1269 - val_loss: 12.2520 - val_mean_absolute_error: 2.6671 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 12.18919\n",
      "Epoch 153/500\n",
      "2072/2072 [==============================] - 0s 89us/step - loss: 18.3468 - mean_absolute_error: 2.8890 - acc: 0.1274 - val_loss: 12.2649 - val_mean_absolute_error: 2.6700 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 12.18919\n",
      "Epoch 154/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 18.3320 - mean_absolute_error: 2.8878 - acc: 0.1279 - val_loss: 12.2635 - val_mean_absolute_error: 2.6700 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 12.18919\n",
      "Epoch 155/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 18.3181 - mean_absolute_error: 2.8868 - acc: 0.1279 - val_loss: 12.2164 - val_mean_absolute_error: 2.6651 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 12.18919\n",
      "Epoch 156/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 18.3105 - mean_absolute_error: 2.8866 - acc: 0.1284 - val_loss: 12.1834 - val_mean_absolute_error: 2.6612 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00156: val_loss improved from 12.18919 to 12.18340, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 157/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 18.3012 - mean_absolute_error: 2.8861 - acc: 0.1318 - val_loss: 12.2578 - val_mean_absolute_error: 2.6698 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 12.18340\n",
      "Epoch 158/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 18.2732 - mean_absolute_error: 2.8835 - acc: 0.1303 - val_loss: 12.1904 - val_mean_absolute_error: 2.6625 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 12.18340\n",
      "Epoch 159/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 18.2554 - mean_absolute_error: 2.8816 - acc: 0.1293 - val_loss: 12.1809 - val_mean_absolute_error: 2.6611 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00159: val_loss improved from 12.18340 to 12.18089, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 160/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 18.2478 - mean_absolute_error: 2.8821 - acc: 0.1293 - val_loss: 12.1701 - val_mean_absolute_error: 2.6598 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00160: val_loss improved from 12.18089 to 12.17015, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 161/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 18.2385 - mean_absolute_error: 2.8817 - acc: 0.1298 - val_loss: 12.1605 - val_mean_absolute_error: 2.6587 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00161: val_loss improved from 12.17015 to 12.16049, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 162/500\n",
      "2072/2072 [==============================] - 0s 66us/step - loss: 18.2280 - mean_absolute_error: 2.8812 - acc: 0.1298 - val_loss: 12.1518 - val_mean_absolute_error: 2.6578 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00162: val_loss improved from 12.16049 to 12.15175, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 163/500\n",
      "2072/2072 [==============================] - 0s 64us/step - loss: 18.2176 - mean_absolute_error: 2.8808 - acc: 0.1298 - val_loss: 12.1420 - val_mean_absolute_error: 2.6566 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00163: val_loss improved from 12.15175 to 12.14199, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 164/500\n",
      "2072/2072 [==============================] - 0s 66us/step - loss: 18.2069 - mean_absolute_error: 2.8803 - acc: 0.1303 - val_loss: 12.1326 - val_mean_absolute_error: 2.6555 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00164: val_loss improved from 12.14199 to 12.13256, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 165/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 18.1961 - mean_absolute_error: 2.8798 - acc: 0.1308 - val_loss: 12.1231 - val_mean_absolute_error: 2.6544 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00165: val_loss improved from 12.13256 to 12.12308, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 166/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 18.1866 - mean_absolute_error: 2.8795 - acc: 0.1327 - val_loss: 12.1169 - val_mean_absolute_error: 2.6539 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00166: val_loss improved from 12.12308 to 12.11693, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 167/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 18.1761 - mean_absolute_error: 2.8791 - acc: 0.1313 - val_loss: 12.1080 - val_mean_absolute_error: 2.6529 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00167: val_loss improved from 12.11693 to 12.10800, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 168/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 18.1658 - mean_absolute_error: 2.8786 - acc: 0.1318 - val_loss: 12.0994 - val_mean_absolute_error: 2.6519 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00168: val_loss improved from 12.10800 to 12.09936, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 169/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 18.1554 - mean_absolute_error: 2.8782 - acc: 0.1303 - val_loss: 12.0906 - val_mean_absolute_error: 2.6509 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00169: val_loss improved from 12.09936 to 12.09062, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 170/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 18.1467 - mean_absolute_error: 2.8783 - acc: 0.1303 - val_loss: 12.0810 - val_mean_absolute_error: 2.6497 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00170: val_loss improved from 12.09062 to 12.08097, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 171/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 18.1368 - mean_absolute_error: 2.8774 - acc: 0.1318 - val_loss: 12.0781 - val_mean_absolute_error: 2.6496 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00171: val_loss improved from 12.08097 to 12.07806, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 172/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 18.1250 - mean_absolute_error: 2.8765 - acc: 0.1298 - val_loss: 12.0539 - val_mean_absolute_error: 2.6458 - val_acc: 0.1216\n",
      "\n",
      "Epoch 00172: val_loss improved from 12.07806 to 12.05387, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 173/500\n",
      "2072/2072 [==============================] - 0s 59us/step - loss: 18.1118 - mean_absolute_error: 2.8767 - acc: 0.1298 - val_loss: 12.0552 - val_mean_absolute_error: 2.6466 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 12.05387\n",
      "Epoch 174/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 18.1065 - mean_absolute_error: 2.8759 - acc: 0.1303 - val_loss: 12.0396 - val_mean_absolute_error: 2.6441 - val_acc: 0.1216\n",
      "\n",
      "Epoch 00174: val_loss improved from 12.05387 to 12.03964, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 175/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 18.0903 - mean_absolute_error: 2.8756 - acc: 0.1322 - val_loss: 12.0424 - val_mean_absolute_error: 2.6454 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 12.03964\n",
      "Epoch 176/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 18.0820 - mean_absolute_error: 2.8743 - acc: 0.1298 - val_loss: 11.9737 - val_mean_absolute_error: 2.6365 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00176: val_loss improved from 12.03964 to 11.97374, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 177/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 18.0705 - mean_absolute_error: 2.8750 - acc: 0.1303 - val_loss: 12.0204 - val_mean_absolute_error: 2.6429 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 11.97374\n",
      "Epoch 178/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 18.0639 - mean_absolute_error: 2.8745 - acc: 0.1308 - val_loss: 12.0176 - val_mean_absolute_error: 2.6427 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 11.97374\n",
      "Epoch 179/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 18.0547 - mean_absolute_error: 2.8742 - acc: 0.1313 - val_loss: 12.0122 - val_mean_absolute_error: 2.6422 - val_acc: 0.1197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00179: val_loss did not improve from 11.97374\n",
      "Epoch 180/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 18.0438 - mean_absolute_error: 2.8732 - acc: 0.1303 - val_loss: 11.9713 - val_mean_absolute_error: 2.6363 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00180: val_loss improved from 11.97374 to 11.97134, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 181/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 18.0310 - mean_absolute_error: 2.8731 - acc: 0.1298 - val_loss: 11.9953 - val_mean_absolute_error: 2.6403 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 11.97134\n",
      "Epoch 182/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 18.0232 - mean_absolute_error: 2.8722 - acc: 0.1313 - val_loss: 11.9384 - val_mean_absolute_error: 2.6331 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00182: val_loss improved from 11.97134 to 11.93839, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 183/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 18.0085 - mean_absolute_error: 2.8711 - acc: 0.1303 - val_loss: 11.9142 - val_mean_absolute_error: 2.6300 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00183: val_loss improved from 11.93839 to 11.91420, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 184/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 17.9934 - mean_absolute_error: 2.8706 - acc: 0.1298 - val_loss: 11.9035 - val_mean_absolute_error: 2.6288 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00184: val_loss improved from 11.91420 to 11.90347, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 185/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 17.9852 - mean_absolute_error: 2.8711 - acc: 0.1303 - val_loss: 11.9426 - val_mean_absolute_error: 2.6342 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 11.90347\n",
      "Epoch 186/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 17.9778 - mean_absolute_error: 2.8700 - acc: 0.1289 - val_loss: 11.8845 - val_mean_absolute_error: 2.6267 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00186: val_loss improved from 11.90347 to 11.88450, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 187/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 17.9651 - mean_absolute_error: 2.8698 - acc: 0.1293 - val_loss: 11.8692 - val_mean_absolute_error: 2.6249 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00187: val_loss improved from 11.88450 to 11.86917, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 188/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 17.9551 - mean_absolute_error: 2.8693 - acc: 0.1293 - val_loss: 11.8589 - val_mean_absolute_error: 2.6237 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00188: val_loss improved from 11.86917 to 11.85889, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 189/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 17.9448 - mean_absolute_error: 2.8688 - acc: 0.1289 - val_loss: 11.8484 - val_mean_absolute_error: 2.6225 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00189: val_loss improved from 11.85889 to 11.84843, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 190/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 17.9346 - mean_absolute_error: 2.8683 - acc: 0.1289 - val_loss: 11.8374 - val_mean_absolute_error: 2.6212 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00190: val_loss improved from 11.84843 to 11.83736, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 191/500\n",
      "2072/2072 [==============================] - 0s 92us/step - loss: 17.9248 - mean_absolute_error: 2.8679 - acc: 0.1293 - val_loss: 11.8265 - val_mean_absolute_error: 2.6199 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00191: val_loss improved from 11.83736 to 11.82646, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 192/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 17.9157 - mean_absolute_error: 2.8678 - acc: 0.1298 - val_loss: 11.8171 - val_mean_absolute_error: 2.6189 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00192: val_loss improved from 11.82646 to 11.81711, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 193/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 17.9046 - mean_absolute_error: 2.8672 - acc: 0.1298 - val_loss: 11.8065 - val_mean_absolute_error: 2.6177 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00193: val_loss improved from 11.81711 to 11.80648, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 194/500\n",
      "2072/2072 [==============================] - 0s 64us/step - loss: 17.8964 - mean_absolute_error: 2.8669 - acc: 0.1303 - val_loss: 11.7990 - val_mean_absolute_error: 2.6168 - val_acc: 0.1332\n",
      "\n",
      "Epoch 00194: val_loss improved from 11.80648 to 11.79897, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 195/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 17.8850 - mean_absolute_error: 2.8663 - acc: 0.1313 - val_loss: 11.7877 - val_mean_absolute_error: 2.6155 - val_acc: 0.1332\n",
      "\n",
      "Epoch 00195: val_loss improved from 11.79897 to 11.78768, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 196/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 17.8754 - mean_absolute_error: 2.8658 - acc: 0.1303 - val_loss: 11.7778 - val_mean_absolute_error: 2.6144 - val_acc: 0.1332\n",
      "\n",
      "Epoch 00196: val_loss improved from 11.78768 to 11.77779, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 197/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 17.8652 - mean_absolute_error: 2.8653 - acc: 0.1298 - val_loss: 11.7671 - val_mean_absolute_error: 2.6132 - val_acc: 0.1351\n",
      "\n",
      "Epoch 00197: val_loss improved from 11.77779 to 11.76714, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 198/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 17.8554 - mean_absolute_error: 2.8648 - acc: 0.1298 - val_loss: 11.7576 - val_mean_absolute_error: 2.6121 - val_acc: 0.1351\n",
      "\n",
      "Epoch 00198: val_loss improved from 11.76714 to 11.75761, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 199/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 17.8449 - mean_absolute_error: 2.8643 - acc: 0.1298 - val_loss: 11.7478 - val_mean_absolute_error: 2.6110 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00199: val_loss improved from 11.75761 to 11.74783, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 200/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 17.8346 - mean_absolute_error: 2.8638 - acc: 0.1308 - val_loss: 11.7378 - val_mean_absolute_error: 2.6099 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00200: val_loss improved from 11.74783 to 11.73785, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 201/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 17.8225 - mean_absolute_error: 2.8629 - acc: 0.1313 - val_loss: 11.7281 - val_mean_absolute_error: 2.6088 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00201: val_loss improved from 11.73785 to 11.72807, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 202/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 17.8156 - mean_absolute_error: 2.8626 - acc: 0.1313 - val_loss: 11.7015 - val_mean_absolute_error: 2.6054 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00202: val_loss improved from 11.72807 to 11.70149, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 203/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 17.8056 - mean_absolute_error: 2.8622 - acc: 0.1313 - val_loss: 11.6798 - val_mean_absolute_error: 2.6023 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00203: val_loss improved from 11.70149 to 11.67981, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 204/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 17.7937 - mean_absolute_error: 2.8614 - acc: 0.1318 - val_loss: 11.6683 - val_mean_absolute_error: 2.6009 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00204: val_loss improved from 11.67981 to 11.66825, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 205/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 17.7836 - mean_absolute_error: 2.8609 - acc: 0.1322 - val_loss: 11.6562 - val_mean_absolute_error: 2.5995 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00205: val_loss improved from 11.66825 to 11.65615, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 206/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 17.7734 - mean_absolute_error: 2.8604 - acc: 0.1332 - val_loss: 11.6435 - val_mean_absolute_error: 2.5980 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00206: val_loss improved from 11.65615 to 11.64351, saving model to ANN_Interval_best_cRNFL.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 17.7655 - mean_absolute_error: 2.8600 - acc: 0.1342 - val_loss: 11.6337 - val_mean_absolute_error: 2.5968 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00207: val_loss improved from 11.64351 to 11.63368, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 208/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 17.7537 - mean_absolute_error: 2.8593 - acc: 0.1337 - val_loss: 11.6208 - val_mean_absolute_error: 2.5953 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00208: val_loss improved from 11.63368 to 11.62075, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 209/500\n",
      "2072/2072 [==============================] - 0s 102us/step - loss: 17.7436 - mean_absolute_error: 2.8588 - acc: 0.1337 - val_loss: 11.6085 - val_mean_absolute_error: 2.5939 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00209: val_loss improved from 11.62075 to 11.60849, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 210/500\n",
      "2072/2072 [==============================] - 0s 100us/step - loss: 17.7366 - mean_absolute_error: 2.8588 - acc: 0.1337 - val_loss: 11.5982 - val_mean_absolute_error: 2.5928 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00210: val_loss improved from 11.60849 to 11.59819, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 211/500\n",
      "2072/2072 [==============================] - 0s 100us/step - loss: 17.7283 - mean_absolute_error: 2.8584 - acc: 0.1347 - val_loss: 11.5884 - val_mean_absolute_error: 2.5916 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00211: val_loss improved from 11.59819 to 11.58842, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 212/500\n",
      "2072/2072 [==============================] - 0s 90us/step - loss: 17.7163 - mean_absolute_error: 2.8579 - acc: 0.1347 - val_loss: 11.5745 - val_mean_absolute_error: 2.5900 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00212: val_loss improved from 11.58842 to 11.57446, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 213/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 17.7070 - mean_absolute_error: 2.8575 - acc: 0.1342 - val_loss: 11.5631 - val_mean_absolute_error: 2.5887 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00213: val_loss improved from 11.57446 to 11.56314, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 214/500\n",
      "2072/2072 [==============================] - 0s 88us/step - loss: 17.6966 - mean_absolute_error: 2.8569 - acc: 0.1337 - val_loss: 11.5545 - val_mean_absolute_error: 2.5876 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00214: val_loss improved from 11.56314 to 11.55451, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 215/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 17.6859 - mean_absolute_error: 2.8563 - acc: 0.1332 - val_loss: 11.5443 - val_mean_absolute_error: 2.5865 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00215: val_loss improved from 11.55451 to 11.54432, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 216/500\n",
      "2072/2072 [==============================] - 0s 92us/step - loss: 17.6759 - mean_absolute_error: 2.8558 - acc: 0.1327 - val_loss: 11.5328 - val_mean_absolute_error: 2.5852 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00216: val_loss improved from 11.54432 to 11.53279, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 217/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 17.6659 - mean_absolute_error: 2.8554 - acc: 0.1327 - val_loss: 11.5226 - val_mean_absolute_error: 2.5840 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00217: val_loss improved from 11.53279 to 11.52264, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 218/500\n",
      "2072/2072 [==============================] - 0s 93us/step - loss: 17.6553 - mean_absolute_error: 2.8548 - acc: 0.1313 - val_loss: 11.5118 - val_mean_absolute_error: 2.5828 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00218: val_loss improved from 11.52264 to 11.51177, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 219/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 17.6411 - mean_absolute_error: 2.8539 - acc: 0.1313 - val_loss: 11.5040 - val_mean_absolute_error: 2.5822 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00219: val_loss improved from 11.51177 to 11.50398, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 220/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 17.6304 - mean_absolute_error: 2.8534 - acc: 0.1318 - val_loss: 11.4918 - val_mean_absolute_error: 2.5808 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00220: val_loss improved from 11.50398 to 11.49177, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 221/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 17.6209 - mean_absolute_error: 2.8530 - acc: 0.1313 - val_loss: 11.4802 - val_mean_absolute_error: 2.5796 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00221: val_loss improved from 11.49177 to 11.48025, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 222/500\n",
      "2072/2072 [==============================] - 0s 64us/step - loss: 17.6112 - mean_absolute_error: 2.8525 - acc: 0.1313 - val_loss: 11.4695 - val_mean_absolute_error: 2.5784 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00222: val_loss improved from 11.48025 to 11.46950, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 223/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 17.6010 - mean_absolute_error: 2.8520 - acc: 0.1308 - val_loss: 11.4579 - val_mean_absolute_error: 2.5771 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00223: val_loss improved from 11.46950 to 11.45790, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 224/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 17.5874 - mean_absolute_error: 2.8509 - acc: 0.1293 - val_loss: 11.4239 - val_mean_absolute_error: 2.5730 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00224: val_loss improved from 11.45790 to 11.42394, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 225/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 17.5838 - mean_absolute_error: 2.8515 - acc: 0.1298 - val_loss: 11.4345 - val_mean_absolute_error: 2.5745 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 11.42394\n",
      "Epoch 226/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 17.5701 - mean_absolute_error: 2.8505 - acc: 0.1284 - val_loss: 11.4233 - val_mean_absolute_error: 2.5732 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00226: val_loss improved from 11.42394 to 11.42335, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 227/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 17.5593 - mean_absolute_error: 2.8499 - acc: 0.1284 - val_loss: 11.4121 - val_mean_absolute_error: 2.5719 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00227: val_loss improved from 11.42335 to 11.41206, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 228/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 17.5511 - mean_absolute_error: 2.8497 - acc: 0.1279 - val_loss: 11.4002 - val_mean_absolute_error: 2.5706 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00228: val_loss improved from 11.41206 to 11.40022, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 229/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 17.5400 - mean_absolute_error: 2.8490 - acc: 0.1293 - val_loss: 11.3881 - val_mean_absolute_error: 2.5693 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00229: val_loss improved from 11.40022 to 11.38807, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 230/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 17.5302 - mean_absolute_error: 2.8486 - acc: 0.1289 - val_loss: 11.3768 - val_mean_absolute_error: 2.5680 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00230: val_loss improved from 11.38807 to 11.37679, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 231/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 17.5222 - mean_absolute_error: 2.8484 - acc: 0.1274 - val_loss: 11.3638 - val_mean_absolute_error: 2.5666 - val_acc: 0.1467\n",
      "\n",
      "Epoch 00231: val_loss improved from 11.37679 to 11.36381, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 232/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 17.5119 - mean_absolute_error: 2.8479 - acc: 0.1269 - val_loss: 11.3549 - val_mean_absolute_error: 2.5656 - val_acc: 0.1467\n",
      "\n",
      "Epoch 00232: val_loss improved from 11.36381 to 11.35485, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 233/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 17.5018 - mean_absolute_error: 2.8474 - acc: 0.1269 - val_loss: 11.3437 - val_mean_absolute_error: 2.5644 - val_acc: 0.1467\n",
      "\n",
      "Epoch 00233: val_loss improved from 11.35485 to 11.34367, saving model to ANN_Interval_best_cRNFL.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 17.4919 - mean_absolute_error: 2.8470 - acc: 0.1260 - val_loss: 11.3324 - val_mean_absolute_error: 2.5631 - val_acc: 0.1467\n",
      "\n",
      "Epoch 00234: val_loss improved from 11.34367 to 11.33243, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 235/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 17.4812 - mean_absolute_error: 2.8463 - acc: 0.1269 - val_loss: 11.3227 - val_mean_absolute_error: 2.5621 - val_acc: 0.1467\n",
      "\n",
      "Epoch 00235: val_loss improved from 11.33243 to 11.32271, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 236/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 17.4705 - mean_absolute_error: 2.8457 - acc: 0.1264 - val_loss: 11.3114 - val_mean_absolute_error: 2.5608 - val_acc: 0.1467\n",
      "\n",
      "Epoch 00236: val_loss improved from 11.32271 to 11.31138, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 237/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 17.4604 - mean_absolute_error: 2.8452 - acc: 0.1274 - val_loss: 11.3000 - val_mean_absolute_error: 2.5595 - val_acc: 0.1486\n",
      "\n",
      "Epoch 00237: val_loss improved from 11.31138 to 11.30003, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 238/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 17.4547 - mean_absolute_error: 2.8449 - acc: 0.1289 - val_loss: 11.2906 - val_mean_absolute_error: 2.5580 - val_acc: 0.1486\n",
      "\n",
      "Epoch 00238: val_loss improved from 11.30003 to 11.29064, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 239/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 17.4454 - mean_absolute_error: 2.8445 - acc: 0.1284 - val_loss: 11.2798 - val_mean_absolute_error: 2.5567 - val_acc: 0.1486\n",
      "\n",
      "Epoch 00239: val_loss improved from 11.29064 to 11.27982, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 240/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 17.4344 - mean_absolute_error: 2.8439 - acc: 0.1279 - val_loss: 11.2679 - val_mean_absolute_error: 2.5553 - val_acc: 0.1467\n",
      "\n",
      "Epoch 00240: val_loss improved from 11.27982 to 11.26792, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 241/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 17.4244 - mean_absolute_error: 2.8434 - acc: 0.1284 - val_loss: 11.2561 - val_mean_absolute_error: 2.5539 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00241: val_loss improved from 11.26792 to 11.25608, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 242/500\n",
      "2072/2072 [==============================] - 0s 87us/step - loss: 17.4142 - mean_absolute_error: 2.8429 - acc: 0.1269 - val_loss: 11.2440 - val_mean_absolute_error: 2.5525 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00242: val_loss improved from 11.25608 to 11.24395, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 243/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 17.4041 - mean_absolute_error: 2.8424 - acc: 0.1264 - val_loss: 11.2337 - val_mean_absolute_error: 2.5514 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00243: val_loss improved from 11.24395 to 11.23371, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 244/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 17.3932 - mean_absolute_error: 2.8419 - acc: 0.1264 - val_loss: 11.2205 - val_mean_absolute_error: 2.5498 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00244: val_loss improved from 11.23371 to 11.22051, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 245/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 17.3824 - mean_absolute_error: 2.8413 - acc: 0.1260 - val_loss: 11.2091 - val_mean_absolute_error: 2.5485 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00245: val_loss improved from 11.22051 to 11.20908, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 246/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 17.3667 - mean_absolute_error: 2.8394 - acc: 0.1260 - val_loss: 11.1959 - val_mean_absolute_error: 2.5472 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00246: val_loss improved from 11.20908 to 11.19589, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 247/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 17.3565 - mean_absolute_error: 2.8391 - acc: 0.1269 - val_loss: 11.1872 - val_mean_absolute_error: 2.5461 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00247: val_loss improved from 11.19589 to 11.18722, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 248/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 17.3471 - mean_absolute_error: 2.8387 - acc: 0.1274 - val_loss: 11.1743 - val_mean_absolute_error: 2.5445 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00248: val_loss improved from 11.18722 to 11.17432, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 249/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 17.3361 - mean_absolute_error: 2.8381 - acc: 0.1274 - val_loss: 11.1609 - val_mean_absolute_error: 2.5429 - val_acc: 0.1467\n",
      "\n",
      "Epoch 00249: val_loss improved from 11.17432 to 11.16092, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 250/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 17.3274 - mean_absolute_error: 2.8379 - acc: 0.1274 - val_loss: 11.1435 - val_mean_absolute_error: 2.5408 - val_acc: 0.1467\n",
      "\n",
      "Epoch 00250: val_loss improved from 11.16092 to 11.14354, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 251/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 17.3175 - mean_absolute_error: 2.8373 - acc: 0.1274 - val_loss: 11.1360 - val_mean_absolute_error: 2.5399 - val_acc: 0.1467\n",
      "\n",
      "Epoch 00251: val_loss improved from 11.14354 to 11.13600, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 252/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 17.3073 - mean_absolute_error: 2.8368 - acc: 0.1269 - val_loss: 11.1232 - val_mean_absolute_error: 2.5384 - val_acc: 0.1467\n",
      "\n",
      "Epoch 00252: val_loss improved from 11.13600 to 11.12322, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 253/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 17.2992 - mean_absolute_error: 2.8366 - acc: 0.1260 - val_loss: 11.1075 - val_mean_absolute_error: 2.5364 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00253: val_loss improved from 11.12322 to 11.10746, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 254/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 17.2877 - mean_absolute_error: 2.8359 - acc: 0.1264 - val_loss: 11.0941 - val_mean_absolute_error: 2.5348 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00254: val_loss improved from 11.10746 to 11.09405, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 255/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 17.2784 - mean_absolute_error: 2.8355 - acc: 0.1264 - val_loss: 11.0820 - val_mean_absolute_error: 2.5334 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00255: val_loss improved from 11.09405 to 11.08195, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 256/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 17.2598 - mean_absolute_error: 2.8338 - acc: 0.1269 - val_loss: 11.0611 - val_mean_absolute_error: 2.5310 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00256: val_loss improved from 11.08195 to 11.06111, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 257/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 17.2611 - mean_absolute_error: 2.8350 - acc: 0.1255 - val_loss: 11.0551 - val_mean_absolute_error: 2.5302 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00257: val_loss improved from 11.06111 to 11.05513, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 258/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 17.2424 - mean_absolute_error: 2.8334 - acc: 0.1260 - val_loss: 11.0459 - val_mean_absolute_error: 2.5293 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00258: val_loss improved from 11.05513 to 11.04589, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 259/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 17.2404 - mean_absolute_error: 2.8338 - acc: 0.1240 - val_loss: 11.0188 - val_mean_absolute_error: 2.5256 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00259: val_loss improved from 11.04589 to 11.01878, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 260/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 17.2213 - mean_absolute_error: 2.8323 - acc: 0.1255 - val_loss: 11.0186 - val_mean_absolute_error: 2.5261 - val_acc: 0.1429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00260: val_loss improved from 11.01878 to 11.01863, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 261/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 17.2206 - mean_absolute_error: 2.8329 - acc: 0.1245 - val_loss: 10.9917 - val_mean_absolute_error: 2.5224 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00261: val_loss improved from 11.01863 to 10.99172, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 262/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 17.2012 - mean_absolute_error: 2.8314 - acc: 0.1260 - val_loss: 10.9920 - val_mean_absolute_error: 2.5228 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 10.99172\n",
      "Epoch 263/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 17.2074 - mean_absolute_error: 2.8335 - acc: 0.1216 - val_loss: 10.9122 - val_mean_absolute_error: 2.5124 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00263: val_loss improved from 10.99172 to 10.91221, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 264/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 17.1856 - mean_absolute_error: 2.8307 - acc: 0.1240 - val_loss: 10.9535 - val_mean_absolute_error: 2.5178 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 10.91221\n",
      "Epoch 265/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 17.1702 - mean_absolute_error: 2.8297 - acc: 0.1250 - val_loss: 10.9449 - val_mean_absolute_error: 2.5173 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 10.91221\n",
      "Epoch 266/500\n",
      "2072/2072 [==============================] - 0s 64us/step - loss: 17.1655 - mean_absolute_error: 2.8299 - acc: 0.1245 - val_loss: 10.9261 - val_mean_absolute_error: 2.5145 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 10.91221\n",
      "Epoch 267/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 17.1500 - mean_absolute_error: 2.8287 - acc: 0.1240 - val_loss: 10.9173 - val_mean_absolute_error: 2.5140 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 10.91221\n",
      "Epoch 268/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 17.1405 - mean_absolute_error: 2.8284 - acc: 0.1240 - val_loss: 10.9024 - val_mean_absolute_error: 2.5121 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00268: val_loss improved from 10.91221 to 10.90235, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 269/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 17.1295 - mean_absolute_error: 2.8277 - acc: 0.1240 - val_loss: 10.8891 - val_mean_absolute_error: 2.5105 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00269: val_loss improved from 10.90235 to 10.88909, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 270/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 17.1193 - mean_absolute_error: 2.8272 - acc: 0.1250 - val_loss: 10.8757 - val_mean_absolute_error: 2.5090 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00270: val_loss improved from 10.88909 to 10.87568, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 271/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 17.1094 - mean_absolute_error: 2.8268 - acc: 0.1250 - val_loss: 10.8615 - val_mean_absolute_error: 2.5073 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00271: val_loss improved from 10.87568 to 10.86155, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 272/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 17.0990 - mean_absolute_error: 2.8263 - acc: 0.1255 - val_loss: 10.8476 - val_mean_absolute_error: 2.5057 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00272: val_loss improved from 10.86155 to 10.84761, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 273/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 17.0889 - mean_absolute_error: 2.8258 - acc: 0.1260 - val_loss: 10.8337 - val_mean_absolute_error: 2.5041 - val_acc: 0.1332\n",
      "\n",
      "Epoch 00273: val_loss improved from 10.84761 to 10.83368, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 274/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 17.0788 - mean_absolute_error: 2.8253 - acc: 0.1260 - val_loss: 10.8196 - val_mean_absolute_error: 2.5025 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00274: val_loss improved from 10.83368 to 10.81965, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 275/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 17.0686 - mean_absolute_error: 2.8248 - acc: 0.1260 - val_loss: 10.8057 - val_mean_absolute_error: 2.5009 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00275: val_loss improved from 10.81965 to 10.80568, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 276/500\n",
      "2072/2072 [==============================] - 0s 53us/step - loss: 17.0583 - mean_absolute_error: 2.8243 - acc: 0.1260 - val_loss: 10.7916 - val_mean_absolute_error: 2.4993 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00276: val_loss improved from 10.80568 to 10.79159, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 277/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 17.0462 - mean_absolute_error: 2.8234 - acc: 0.1284 - val_loss: 10.7757 - val_mean_absolute_error: 2.4974 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00277: val_loss improved from 10.79159 to 10.77568, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 278/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 17.0355 - mean_absolute_error: 2.8230 - acc: 0.1279 - val_loss: 10.7631 - val_mean_absolute_error: 2.4963 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00278: val_loss improved from 10.77568 to 10.76309, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 279/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 17.0255 - mean_absolute_error: 2.8225 - acc: 0.1289 - val_loss: 10.7491 - val_mean_absolute_error: 2.4948 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00279: val_loss improved from 10.76309 to 10.74907, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 280/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 17.0154 - mean_absolute_error: 2.8220 - acc: 0.1289 - val_loss: 10.7362 - val_mean_absolute_error: 2.4934 - val_acc: 0.1332\n",
      "\n",
      "Epoch 00280: val_loss improved from 10.74907 to 10.73620, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 281/500\n",
      "2072/2072 [==============================] - 0s 46us/step - loss: 17.0053 - mean_absolute_error: 2.8215 - acc: 0.1303 - val_loss: 10.7217 - val_mean_absolute_error: 2.4918 - val_acc: 0.1351\n",
      "\n",
      "Epoch 00281: val_loss improved from 10.73620 to 10.72171, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 282/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 16.9956 - mean_absolute_error: 2.8211 - acc: 0.1289 - val_loss: 10.7263 - val_mean_absolute_error: 2.4934 - val_acc: 0.1332\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 10.72171\n",
      "Epoch 283/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 16.9838 - mean_absolute_error: 2.8206 - acc: 0.1293 - val_loss: 10.7107 - val_mean_absolute_error: 2.4917 - val_acc: 0.1332\n",
      "\n",
      "Epoch 00283: val_loss improved from 10.72171 to 10.71072, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 284/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 16.9745 - mean_absolute_error: 2.8202 - acc: 0.1293 - val_loss: 10.6970 - val_mean_absolute_error: 2.4902 - val_acc: 0.1351\n",
      "\n",
      "Epoch 00284: val_loss improved from 10.71072 to 10.69697, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 285/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 16.9644 - mean_absolute_error: 2.8197 - acc: 0.1293 - val_loss: 10.6830 - val_mean_absolute_error: 2.4887 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00285: val_loss improved from 10.69697 to 10.68301, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 286/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 16.9547 - mean_absolute_error: 2.8192 - acc: 0.1289 - val_loss: 10.6672 - val_mean_absolute_error: 2.4868 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00286: val_loss improved from 10.68301 to 10.66723, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 287/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 16.9521 - mean_absolute_error: 2.8193 - acc: 0.1303 - val_loss: 10.6584 - val_mean_absolute_error: 2.4861 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00287: val_loss improved from 10.66723 to 10.65845, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 288/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 16.9387 - mean_absolute_error: 2.8182 - acc: 0.1298 - val_loss: 10.6492 - val_mean_absolute_error: 2.4852 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00288: val_loss improved from 10.65845 to 10.64923, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 289/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 16.9271 - mean_absolute_error: 2.8176 - acc: 0.1308 - val_loss: 10.6392 - val_mean_absolute_error: 2.4842 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00289: val_loss improved from 10.64923 to 10.63924, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 290/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 16.9166 - mean_absolute_error: 2.8171 - acc: 0.1308 - val_loss: 10.6290 - val_mean_absolute_error: 2.4831 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00290: val_loss improved from 10.63924 to 10.62905, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 291/500\n",
      "2072/2072 [==============================] - 0s 92us/step - loss: 16.9051 - mean_absolute_error: 2.8164 - acc: 0.1308 - val_loss: 10.6347 - val_mean_absolute_error: 2.4847 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 10.62905\n",
      "Epoch 292/500\n",
      "2072/2072 [==============================] - 0s 103us/step - loss: 16.8891 - mean_absolute_error: 2.8151 - acc: 0.1289 - val_loss: 10.6243 - val_mean_absolute_error: 2.4837 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00292: val_loss improved from 10.62905 to 10.62426, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 293/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 16.8799 - mean_absolute_error: 2.8147 - acc: 0.1289 - val_loss: 10.6096 - val_mean_absolute_error: 2.4820 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00293: val_loss improved from 10.62426 to 10.60962, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 294/500\n",
      "2072/2072 [==============================] - 0s 66us/step - loss: 16.8681 - mean_absolute_error: 2.8141 - acc: 0.1293 - val_loss: 10.5995 - val_mean_absolute_error: 2.4800 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00294: val_loss improved from 10.60962 to 10.59951, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 295/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 16.8649 - mean_absolute_error: 2.8143 - acc: 0.1298 - val_loss: 10.5953 - val_mean_absolute_error: 2.4798 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00295: val_loss improved from 10.59951 to 10.59530, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 296/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 16.8541 - mean_absolute_error: 2.8138 - acc: 0.1293 - val_loss: 10.5825 - val_mean_absolute_error: 2.4784 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00296: val_loss improved from 10.59530 to 10.58252, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 297/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 16.8442 - mean_absolute_error: 2.8134 - acc: 0.1284 - val_loss: 10.5633 - val_mean_absolute_error: 2.4770 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00297: val_loss improved from 10.58252 to 10.56329, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 298/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 16.8279 - mean_absolute_error: 2.8121 - acc: 0.1274 - val_loss: 10.5652 - val_mean_absolute_error: 2.4773 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 10.56329\n",
      "Epoch 299/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 16.8226 - mean_absolute_error: 2.8122 - acc: 0.1284 - val_loss: 10.5417 - val_mean_absolute_error: 2.4739 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00299: val_loss improved from 10.56329 to 10.54174, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 300/500\n",
      "2072/2072 [==============================] - 0s 85us/step - loss: 16.8137 - mean_absolute_error: 2.8119 - acc: 0.1274 - val_loss: 10.5219 - val_mean_absolute_error: 2.4723 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00300: val_loss improved from 10.54174 to 10.52185, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 301/500\n",
      "2072/2072 [==============================] - 0s 113us/step - loss: 16.7972 - mean_absolute_error: 2.8106 - acc: 0.1264 - val_loss: 10.5266 - val_mean_absolute_error: 2.4731 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 10.52185\n",
      "Epoch 302/500\n",
      "2072/2072 [==============================] - 0s 114us/step - loss: 16.7708 - mean_absolute_error: 2.8094 - acc: 0.1269 - val_loss: 10.4114 - val_mean_absolute_error: 2.4597 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00302: val_loss improved from 10.52185 to 10.41145, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 303/500\n",
      "2072/2072 [==============================] - 0s 101us/step - loss: 16.7902 - mean_absolute_error: 2.8113 - acc: 0.1264 - val_loss: 10.5013 - val_mean_absolute_error: 2.4704 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 10.41145\n",
      "Epoch 304/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 16.7645 - mean_absolute_error: 2.8085 - acc: 0.1260 - val_loss: 10.4818 - val_mean_absolute_error: 2.4681 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 10.41145\n",
      "Epoch 305/500\n",
      "2072/2072 [==============================] - 0s 64us/step - loss: 16.7550 - mean_absolute_error: 2.8081 - acc: 0.1260 - val_loss: 10.4673 - val_mean_absolute_error: 2.4663 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 10.41145\n",
      "Epoch 306/500\n",
      "2072/2072 [==============================] - 0s 64us/step - loss: 16.7515 - mean_absolute_error: 2.8088 - acc: 0.1269 - val_loss: 10.4534 - val_mean_absolute_error: 2.4647 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 10.41145\n",
      "Epoch 307/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 16.7408 - mean_absolute_error: 2.8082 - acc: 0.1264 - val_loss: 10.4403 - val_mean_absolute_error: 2.4633 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 10.41145\n",
      "Epoch 308/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 16.7312 - mean_absolute_error: 2.8078 - acc: 0.1269 - val_loss: 10.4276 - val_mean_absolute_error: 2.4619 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 10.41145\n",
      "Epoch 309/500\n",
      "2072/2072 [==============================] - 0s 66us/step - loss: 16.7153 - mean_absolute_error: 2.8062 - acc: 0.1250 - val_loss: 10.4091 - val_mean_absolute_error: 2.4598 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00309: val_loss improved from 10.41145 to 10.40909, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 310/500\n",
      "2072/2072 [==============================] - 0s 55us/step - loss: 16.7044 - mean_absolute_error: 2.8056 - acc: 0.1255 - val_loss: 10.3955 - val_mean_absolute_error: 2.4582 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00310: val_loss improved from 10.40909 to 10.39551, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 311/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 16.7008 - mean_absolute_error: 2.8063 - acc: 0.1274 - val_loss: 10.3829 - val_mean_absolute_error: 2.4565 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00311: val_loss improved from 10.39551 to 10.38289, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 312/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 16.6909 - mean_absolute_error: 2.8058 - acc: 0.1264 - val_loss: 10.3701 - val_mean_absolute_error: 2.4553 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00312: val_loss improved from 10.38289 to 10.37010, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 313/500\n",
      "2072/2072 [==============================] - 0s 59us/step - loss: 16.6748 - mean_absolute_error: 2.8042 - acc: 0.1250 - val_loss: 10.3556 - val_mean_absolute_error: 2.4536 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00313: val_loss improved from 10.37010 to 10.35561, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 314/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 16.6663 - mean_absolute_error: 2.8042 - acc: 0.1260 - val_loss: 10.3421 - val_mean_absolute_error: 2.4519 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00314: val_loss improved from 10.35561 to 10.34215, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 315/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 16.6571 - mean_absolute_error: 2.8038 - acc: 0.1260 - val_loss: 10.3286 - val_mean_absolute_error: 2.4504 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00315: val_loss improved from 10.34215 to 10.32863, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 316/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2072/2072 [==============================] - 0s 66us/step - loss: 16.6472 - mean_absolute_error: 2.8033 - acc: 0.1260 - val_loss: 10.3156 - val_mean_absolute_error: 2.4488 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00316: val_loss improved from 10.32863 to 10.31557, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 317/500\n",
      "2072/2072 [==============================] - 0s 53us/step - loss: 16.6360 - mean_absolute_error: 2.8026 - acc: 0.1255 - val_loss: 10.3007 - val_mean_absolute_error: 2.4468 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00317: val_loss improved from 10.31557 to 10.30074, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 318/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 16.6278 - mean_absolute_error: 2.8027 - acc: 0.1269 - val_loss: 10.2892 - val_mean_absolute_error: 2.4456 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00318: val_loss improved from 10.30074 to 10.28917, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 319/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 16.6198 - mean_absolute_error: 2.8018 - acc: 0.1240 - val_loss: 10.2573 - val_mean_absolute_error: 2.4413 - val_acc: 0.1351\n",
      "\n",
      "Epoch 00319: val_loss improved from 10.28917 to 10.25725, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 320/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 16.6099 - mean_absolute_error: 2.8021 - acc: 0.1264 - val_loss: 10.2583 - val_mean_absolute_error: 2.4419 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 10.25725\n",
      "Epoch 321/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 16.5913 - mean_absolute_error: 2.8010 - acc: 0.1250 - val_loss: 10.2445 - val_mean_absolute_error: 2.4404 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00321: val_loss improved from 10.25725 to 10.24451, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 322/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 16.5874 - mean_absolute_error: 2.8015 - acc: 0.1240 - val_loss: 10.2244 - val_mean_absolute_error: 2.4380 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00322: val_loss improved from 10.24451 to 10.22437, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 323/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 16.5775 - mean_absolute_error: 2.8011 - acc: 0.1245 - val_loss: 10.2073 - val_mean_absolute_error: 2.4358 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00323: val_loss improved from 10.22437 to 10.20729, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 324/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 16.5566 - mean_absolute_error: 2.7996 - acc: 0.1250 - val_loss: 10.1911 - val_mean_absolute_error: 2.4336 - val_acc: 0.1351\n",
      "\n",
      "Epoch 00324: val_loss improved from 10.20729 to 10.19110, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 325/500\n",
      "2072/2072 [==============================] - 0s 66us/step - loss: 16.5598 - mean_absolute_error: 2.7999 - acc: 0.1245 - val_loss: 10.1749 - val_mean_absolute_error: 2.4319 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00325: val_loss improved from 10.19110 to 10.17492, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 326/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 16.5480 - mean_absolute_error: 2.7988 - acc: 0.1260 - val_loss: 10.1457 - val_mean_absolute_error: 2.4278 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00326: val_loss improved from 10.17492 to 10.14570, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 327/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 16.5350 - mean_absolute_error: 2.7994 - acc: 0.1255 - val_loss: 10.1458 - val_mean_absolute_error: 2.4282 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 10.14570\n",
      "Epoch 328/500\n",
      "2072/2072 [==============================] - 0s 52us/step - loss: 16.5265 - mean_absolute_error: 2.7982 - acc: 0.1250 - val_loss: 10.1128 - val_mean_absolute_error: 2.4236 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00328: val_loss improved from 10.14570 to 10.11282, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 329/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 16.5186 - mean_absolute_error: 2.7989 - acc: 0.1264 - val_loss: 10.1155 - val_mean_absolute_error: 2.4245 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 10.11282\n",
      "Epoch 330/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 16.5082 - mean_absolute_error: 2.7981 - acc: 0.1260 - val_loss: 10.1028 - val_mean_absolute_error: 2.4231 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00330: val_loss improved from 10.11282 to 10.10277, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 331/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 16.4974 - mean_absolute_error: 2.7975 - acc: 0.1255 - val_loss: 10.0889 - val_mean_absolute_error: 2.4215 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00331: val_loss improved from 10.10277 to 10.08888, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 332/500\n",
      "2072/2072 [==============================] - 0s 94us/step - loss: 16.4876 - mean_absolute_error: 2.7970 - acc: 0.1264 - val_loss: 10.0757 - val_mean_absolute_error: 2.4200 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00332: val_loss improved from 10.08888 to 10.07565, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 333/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 16.4781 - mean_absolute_error: 2.7966 - acc: 0.1264 - val_loss: 10.0479 - val_mean_absolute_error: 2.4168 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00333: val_loss improved from 10.07565 to 10.04792, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 334/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 16.4688 - mean_absolute_error: 2.7964 - acc: 0.1260 - val_loss: 10.0350 - val_mean_absolute_error: 2.4151 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00334: val_loss improved from 10.04792 to 10.03502, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 335/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 16.4595 - mean_absolute_error: 2.7958 - acc: 0.1250 - val_loss: 10.0173 - val_mean_absolute_error: 2.4128 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00335: val_loss improved from 10.03502 to 10.01733, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 336/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 16.4486 - mean_absolute_error: 2.7954 - acc: 0.1255 - val_loss: 10.0107 - val_mean_absolute_error: 2.4119 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00336: val_loss improved from 10.01733 to 10.01070, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 337/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 16.4408 - mean_absolute_error: 2.7951 - acc: 0.1250 - val_loss: 9.9989 - val_mean_absolute_error: 2.4105 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00337: val_loss improved from 10.01070 to 9.99891, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 338/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 16.4295 - mean_absolute_error: 2.7945 - acc: 0.1250 - val_loss: 9.9819 - val_mean_absolute_error: 2.4088 - val_acc: 0.1332\n",
      "\n",
      "Epoch 00338: val_loss improved from 9.99891 to 9.98186, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 339/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 16.4167 - mean_absolute_error: 2.7937 - acc: 0.1250 - val_loss: 9.9708 - val_mean_absolute_error: 2.4072 - val_acc: 0.1332\n",
      "\n",
      "Epoch 00339: val_loss improved from 9.98186 to 9.97081, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 340/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 16.4102 - mean_absolute_error: 2.7938 - acc: 0.1260 - val_loss: 9.9531 - val_mean_absolute_error: 2.4050 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00340: val_loss improved from 9.97081 to 9.95311, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 341/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 16.3975 - mean_absolute_error: 2.7937 - acc: 0.1279 - val_loss: 9.9442 - val_mean_absolute_error: 2.4041 - val_acc: 0.1332\n",
      "\n",
      "Epoch 00341: val_loss improved from 9.95311 to 9.94422, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 342/500\n",
      "2072/2072 [==============================] - 0s 59us/step - loss: 16.3911 - mean_absolute_error: 2.7930 - acc: 0.1260 - val_loss: 9.9289 - val_mean_absolute_error: 2.4024 - val_acc: 0.1332\n",
      "\n",
      "Epoch 00342: val_loss improved from 9.94422 to 9.92890, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 343/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 16.3775 - mean_absolute_error: 2.7927 - acc: 0.1269 - val_loss: 9.9143 - val_mean_absolute_error: 2.4007 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00343: val_loss improved from 9.92890 to 9.91430, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 344/500\n",
      "2072/2072 [==============================] - 0s 53us/step - loss: 16.3737 - mean_absolute_error: 2.7927 - acc: 0.1269 - val_loss: 9.8971 - val_mean_absolute_error: 2.3982 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00344: val_loss improved from 9.91430 to 9.89707, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 345/500\n",
      "2072/2072 [==============================] - 0s 53us/step - loss: 16.3621 - mean_absolute_error: 2.7919 - acc: 0.1260 - val_loss: 9.8935 - val_mean_absolute_error: 2.3992 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00345: val_loss improved from 9.89707 to 9.89345, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 346/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 16.3468 - mean_absolute_error: 2.7910 - acc: 0.1279 - val_loss: 9.8772 - val_mean_absolute_error: 2.3968 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00346: val_loss improved from 9.89345 to 9.87721, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 347/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 16.3331 - mean_absolute_error: 2.7913 - acc: 0.1274 - val_loss: 9.8816 - val_mean_absolute_error: 2.3981 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 9.87721\n",
      "Epoch 348/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 16.3219 - mean_absolute_error: 2.7901 - acc: 0.1255 - val_loss: 9.8684 - val_mean_absolute_error: 2.3970 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00348: val_loss improved from 9.87721 to 9.86845, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 349/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 16.3135 - mean_absolute_error: 2.7895 - acc: 0.1264 - val_loss: 9.8465 - val_mean_absolute_error: 2.3939 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00349: val_loss improved from 9.86845 to 9.84654, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 350/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 16.3044 - mean_absolute_error: 2.7894 - acc: 0.1255 - val_loss: 9.8342 - val_mean_absolute_error: 2.3922 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00350: val_loss improved from 9.84654 to 9.83423, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 351/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 16.2908 - mean_absolute_error: 2.7886 - acc: 0.1255 - val_loss: 9.8246 - val_mean_absolute_error: 2.3906 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00351: val_loss improved from 9.83423 to 9.82456, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 352/500\n",
      "2072/2072 [==============================] - 0s 53us/step - loss: 16.2792 - mean_absolute_error: 2.7881 - acc: 0.1250 - val_loss: 9.8179 - val_mean_absolute_error: 2.3889 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00352: val_loss improved from 9.82456 to 9.81786, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 353/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 16.2672 - mean_absolute_error: 2.7878 - acc: 0.1240 - val_loss: 9.7825 - val_mean_absolute_error: 2.3873 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00353: val_loss improved from 9.81786 to 9.78253, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 354/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 16.2606 - mean_absolute_error: 2.7873 - acc: 0.1255 - val_loss: 9.7926 - val_mean_absolute_error: 2.3858 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 9.78253\n",
      "Epoch 355/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 16.2459 - mean_absolute_error: 2.7869 - acc: 0.1245 - val_loss: 9.7592 - val_mean_absolute_error: 2.3844 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00355: val_loss improved from 9.78253 to 9.75922, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 356/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 16.2387 - mean_absolute_error: 2.7863 - acc: 0.1240 - val_loss: 9.7668 - val_mean_absolute_error: 2.3824 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 9.75922\n",
      "Epoch 357/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 16.2245 - mean_absolute_error: 2.7859 - acc: 0.1236 - val_loss: 9.7375 - val_mean_absolute_error: 2.3815 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00357: val_loss improved from 9.75922 to 9.73754, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 358/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 16.2246 - mean_absolute_error: 2.7860 - acc: 0.1231 - val_loss: 9.7424 - val_mean_absolute_error: 2.3795 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 9.73754\n",
      "Epoch 359/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 16.2056 - mean_absolute_error: 2.7852 - acc: 0.1236 - val_loss: 9.7110 - val_mean_absolute_error: 2.3785 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00359: val_loss improved from 9.73754 to 9.71101, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 360/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 16.1974 - mean_absolute_error: 2.7848 - acc: 0.1236 - val_loss: 9.7035 - val_mean_absolute_error: 2.3769 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00360: val_loss improved from 9.71101 to 9.70345, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 361/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 16.1913 - mean_absolute_error: 2.7842 - acc: 0.1236 - val_loss: 9.7061 - val_mean_absolute_error: 2.3747 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 9.70345\n",
      "Epoch 362/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 16.1740 - mean_absolute_error: 2.7836 - acc: 0.1236 - val_loss: 9.6806 - val_mean_absolute_error: 2.3741 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00362: val_loss improved from 9.70345 to 9.68059, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 363/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 16.1725 - mean_absolute_error: 2.7834 - acc: 0.1236 - val_loss: 9.6814 - val_mean_absolute_error: 2.3715 - val_acc: 0.1216\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 9.68059\n",
      "Epoch 364/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 16.1571 - mean_absolute_error: 2.7831 - acc: 0.1231 - val_loss: 9.6493 - val_mean_absolute_error: 2.3713 - val_acc: 0.1216\n",
      "\n",
      "Epoch 00364: val_loss improved from 9.68059 to 9.64934, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 365/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 16.1525 - mean_absolute_error: 2.7828 - acc: 0.1231 - val_loss: 9.6363 - val_mean_absolute_error: 2.3694 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00365: val_loss improved from 9.64934 to 9.63628, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 366/500\n",
      "2072/2072 [==============================] - 0s 55us/step - loss: 16.1431 - mean_absolute_error: 2.7825 - acc: 0.1226 - val_loss: 9.6278 - val_mean_absolute_error: 2.3683 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00366: val_loss improved from 9.63628 to 9.62777, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 367/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 16.1329 - mean_absolute_error: 2.7819 - acc: 0.1231 - val_loss: 9.6183 - val_mean_absolute_error: 2.3670 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00367: val_loss improved from 9.62777 to 9.61829, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 368/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 16.1313 - mean_absolute_error: 2.7817 - acc: 0.1221 - val_loss: 9.6263 - val_mean_absolute_error: 2.3643 - val_acc: 0.1216\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 9.61829\n",
      "Epoch 369/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 16.1059 - mean_absolute_error: 2.7803 - acc: 0.1221 - val_loss: 9.5952 - val_mean_absolute_error: 2.3643 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00369: val_loss improved from 9.61829 to 9.59516, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 370/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 16.1173 - mean_absolute_error: 2.7814 - acc: 0.1226 - val_loss: 9.6029 - val_mean_absolute_error: 2.3613 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 9.59516\n",
      "Epoch 371/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2072/2072 [==============================] - 0s 51us/step - loss: 16.0864 - mean_absolute_error: 2.7792 - acc: 0.1236 - val_loss: 9.5767 - val_mean_absolute_error: 2.3614 - val_acc: 0.1158\n",
      "\n",
      "Epoch 00371: val_loss improved from 9.59516 to 9.57671, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 372/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 16.0957 - mean_absolute_error: 2.7801 - acc: 0.1240 - val_loss: 9.5789 - val_mean_absolute_error: 2.3582 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 9.57671\n",
      "Epoch 373/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 16.0670 - mean_absolute_error: 2.7783 - acc: 0.1245 - val_loss: 9.5702 - val_mean_absolute_error: 2.3594 - val_acc: 0.1197\n",
      "\n",
      "Epoch 00373: val_loss improved from 9.57671 to 9.57019, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 374/500\n",
      "2072/2072 [==============================] - 0s 50us/step - loss: 16.0754 - mean_absolute_error: 2.7795 - acc: 0.1240 - val_loss: 9.5496 - val_mean_absolute_error: 2.3579 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00374: val_loss improved from 9.57019 to 9.54963, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 375/500\n",
      "2072/2072 [==============================] - 0s 59us/step - loss: 16.0720 - mean_absolute_error: 2.7802 - acc: 0.1255 - val_loss: 9.3253 - val_mean_absolute_error: 2.3254 - val_acc: 0.1332\n",
      "\n",
      "Epoch 00375: val_loss improved from 9.54963 to 9.32534, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 376/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 16.1590 - mean_absolute_error: 2.7939 - acc: 0.1202 - val_loss: 9.4790 - val_mean_absolute_error: 2.3421 - val_acc: 0.1158\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 9.32534\n",
      "Epoch 377/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 16.0337 - mean_absolute_error: 2.7758 - acc: 0.1231 - val_loss: 9.4419 - val_mean_absolute_error: 2.3392 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 9.32534\n",
      "Epoch 378/500\n",
      "2072/2072 [==============================] - 0s 66us/step - loss: 16.0360 - mean_absolute_error: 2.7763 - acc: 0.1231 - val_loss: 9.4474 - val_mean_absolute_error: 2.3361 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 9.32534\n",
      "Epoch 379/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 16.0056 - mean_absolute_error: 2.7742 - acc: 0.1226 - val_loss: 9.4456 - val_mean_absolute_error: 2.3377 - val_acc: 0.1158\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 9.32534\n",
      "Epoch 380/500\n",
      "2072/2072 [==============================] - 0s 52us/step - loss: 16.0187 - mean_absolute_error: 2.7762 - acc: 0.1226 - val_loss: 9.4232 - val_mean_absolute_error: 2.3356 - val_acc: 0.1178\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 9.32534\n",
      "Epoch 381/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 16.0084 - mean_absolute_error: 2.7755 - acc: 0.1216 - val_loss: 9.4043 - val_mean_absolute_error: 2.3343 - val_acc: 0.1158\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 9.32534\n",
      "Epoch 382/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 16.0008 - mean_absolute_error: 2.7751 - acc: 0.1221 - val_loss: 9.3666 - val_mean_absolute_error: 2.3232 - val_acc: 0.1216\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 9.32534\n",
      "Epoch 383/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 15.9635 - mean_absolute_error: 2.7708 - acc: 0.1216 - val_loss: 9.3764 - val_mean_absolute_error: 2.3265 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 9.32534\n",
      "Epoch 384/500\n",
      "2072/2072 [==============================] - 0s 53us/step - loss: 15.9743 - mean_absolute_error: 2.7730 - acc: 0.1221 - val_loss: 9.3578 - val_mean_absolute_error: 2.3248 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 9.32534\n",
      "Epoch 385/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 15.9638 - mean_absolute_error: 2.7731 - acc: 0.1207 - val_loss: 9.3240 - val_mean_absolute_error: 2.3206 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00385: val_loss improved from 9.32534 to 9.32397, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 386/500\n",
      "2072/2072 [==============================] - 0s 59us/step - loss: 15.9559 - mean_absolute_error: 2.7720 - acc: 0.1216 - val_loss: 9.3364 - val_mean_absolute_error: 2.3193 - val_acc: 0.1216\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 9.32397\n",
      "Epoch 387/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 15.9160 - mean_absolute_error: 2.7678 - acc: 0.1226 - val_loss: 9.3336 - val_mean_absolute_error: 2.3204 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 9.32397\n",
      "Epoch 388/500\n",
      "2072/2072 [==============================] - 0s 52us/step - loss: 15.9304 - mean_absolute_error: 2.7704 - acc: 0.1236 - val_loss: 9.3266 - val_mean_absolute_error: 2.3204 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 9.32397\n",
      "Epoch 389/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 15.9246 - mean_absolute_error: 2.7703 - acc: 0.1236 - val_loss: 9.3175 - val_mean_absolute_error: 2.3192 - val_acc: 0.1216\n",
      "\n",
      "Epoch 00389: val_loss improved from 9.32397 to 9.31748, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 390/500\n",
      "2072/2072 [==============================] - 0s 55us/step - loss: 15.9116 - mean_absolute_error: 2.7694 - acc: 0.1240 - val_loss: 9.3085 - val_mean_absolute_error: 2.3182 - val_acc: 0.1216\n",
      "\n",
      "Epoch 00390: val_loss improved from 9.31748 to 9.30849, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 391/500\n",
      "2072/2072 [==============================] - 0s 48us/step - loss: 15.8984 - mean_absolute_error: 2.7681 - acc: 0.1236 - val_loss: 9.2967 - val_mean_absolute_error: 2.3163 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00391: val_loss improved from 9.30849 to 9.29674, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 392/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 15.8924 - mean_absolute_error: 2.7685 - acc: 0.1240 - val_loss: 9.2926 - val_mean_absolute_error: 2.3165 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00392: val_loss improved from 9.29674 to 9.29259, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 393/500\n",
      "2072/2072 [==============================] - 0s 47us/step - loss: 15.8808 - mean_absolute_error: 2.7678 - acc: 0.1245 - val_loss: 9.2844 - val_mean_absolute_error: 2.3156 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00393: val_loss improved from 9.29259 to 9.28438, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 394/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 15.8714 - mean_absolute_error: 2.7674 - acc: 0.1245 - val_loss: 9.2758 - val_mean_absolute_error: 2.3145 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00394: val_loss improved from 9.28438 to 9.27585, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 395/500\n",
      "2072/2072 [==============================] - 0s 66us/step - loss: 15.8649 - mean_absolute_error: 2.7673 - acc: 0.1240 - val_loss: 9.2595 - val_mean_absolute_error: 2.3121 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00395: val_loss improved from 9.27585 to 9.25954, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 396/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 15.8559 - mean_absolute_error: 2.7668 - acc: 0.1245 - val_loss: 9.2507 - val_mean_absolute_error: 2.3110 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00396: val_loss improved from 9.25954 to 9.25066, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 397/500\n",
      "2072/2072 [==============================] - 0s 64us/step - loss: 15.8506 - mean_absolute_error: 2.7671 - acc: 0.1245 - val_loss: 9.2394 - val_mean_absolute_error: 2.3092 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00397: val_loss improved from 9.25066 to 9.23937, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 398/500\n",
      "2072/2072 [==============================] - 0s 53us/step - loss: 15.8366 - mean_absolute_error: 2.7657 - acc: 0.1245 - val_loss: 9.2340 - val_mean_absolute_error: 2.3089 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00398: val_loss improved from 9.23937 to 9.23398, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 399/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 15.8279 - mean_absolute_error: 2.7654 - acc: 0.1231 - val_loss: 9.2252 - val_mean_absolute_error: 2.3077 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00399: val_loss improved from 9.23398 to 9.22515, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 400/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2072/2072 [==============================] - 0s 56us/step - loss: 15.8210 - mean_absolute_error: 2.7653 - acc: 0.1245 - val_loss: 9.2159 - val_mean_absolute_error: 2.3066 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00400: val_loss improved from 9.22515 to 9.21587, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 401/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 15.8120 - mean_absolute_error: 2.7648 - acc: 0.1245 - val_loss: 9.2082 - val_mean_absolute_error: 2.3057 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00401: val_loss improved from 9.21587 to 9.20825, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 402/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 15.8015 - mean_absolute_error: 2.7642 - acc: 0.1250 - val_loss: 9.2031 - val_mean_absolute_error: 2.3052 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00402: val_loss improved from 9.20825 to 9.20311, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 403/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 15.7926 - mean_absolute_error: 2.7638 - acc: 0.1260 - val_loss: 9.1942 - val_mean_absolute_error: 2.3041 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00403: val_loss improved from 9.20311 to 9.19422, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 404/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 15.8542 - mean_absolute_error: 2.7722 - acc: 0.1260 - val_loss: 9.1744 - val_mean_absolute_error: 2.3016 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00404: val_loss improved from 9.19422 to 9.17440, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 405/500\n",
      "2072/2072 [==============================] - 0s 58us/step - loss: 15.7791 - mean_absolute_error: 2.7633 - acc: 0.1245 - val_loss: 9.1814 - val_mean_absolute_error: 2.3023 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 9.17440\n",
      "Epoch 406/500\n",
      "2072/2072 [==============================] - 0s 59us/step - loss: 15.7616 - mean_absolute_error: 2.7617 - acc: 0.1255 - val_loss: 9.1769 - val_mean_absolute_error: 2.3020 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 9.17440\n",
      "Epoch 407/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 15.7541 - mean_absolute_error: 2.7614 - acc: 0.1250 - val_loss: 9.1687 - val_mean_absolute_error: 2.3010 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00407: val_loss improved from 9.17440 to 9.16868, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 408/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 15.7466 - mean_absolute_error: 2.7611 - acc: 0.1269 - val_loss: 9.1605 - val_mean_absolute_error: 2.2999 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00408: val_loss improved from 9.16868 to 9.16051, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 409/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 15.7493 - mean_absolute_error: 2.7619 - acc: 0.1274 - val_loss: 9.0773 - val_mean_absolute_error: 2.2843 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00409: val_loss improved from 9.16051 to 9.07729, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 410/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 15.7640 - mean_absolute_error: 2.7630 - acc: 0.1264 - val_loss: 9.1514 - val_mean_absolute_error: 2.2997 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 9.07729\n",
      "Epoch 411/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 15.7175 - mean_absolute_error: 2.7590 - acc: 0.1250 - val_loss: 9.1440 - val_mean_absolute_error: 2.2984 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 9.07729\n",
      "Epoch 412/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 15.7076 - mean_absolute_error: 2.7584 - acc: 0.1250 - val_loss: 9.1350 - val_mean_absolute_error: 2.2969 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 9.07729\n",
      "Epoch 413/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 15.6975 - mean_absolute_error: 2.7577 - acc: 0.1264 - val_loss: 9.1276 - val_mean_absolute_error: 2.2958 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 9.07729\n",
      "Epoch 414/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 15.6895 - mean_absolute_error: 2.7575 - acc: 0.1269 - val_loss: 9.1112 - val_mean_absolute_error: 2.2932 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 9.07729\n",
      "Epoch 415/500\n",
      "2072/2072 [==============================] - 0s 90us/step - loss: 15.6852 - mean_absolute_error: 2.7576 - acc: 0.1260 - val_loss: 9.1027 - val_mean_absolute_error: 2.2921 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 9.07729\n",
      "Epoch 416/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 15.6817 - mean_absolute_error: 2.7581 - acc: 0.1264 - val_loss: 9.0846 - val_mean_absolute_error: 2.2889 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 9.07729\n",
      "Epoch 417/500\n",
      "2072/2072 [==============================] - 0s 93us/step - loss: 15.6672 - mean_absolute_error: 2.7567 - acc: 0.1250 - val_loss: 9.0929 - val_mean_absolute_error: 2.2913 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 9.07729\n",
      "Epoch 418/500\n",
      "2072/2072 [==============================] - 0s 103us/step - loss: 15.6540 - mean_absolute_error: 2.7557 - acc: 0.1245 - val_loss: 9.0840 - val_mean_absolute_error: 2.2897 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 9.07729\n",
      "Epoch 419/500\n",
      "2072/2072 [==============================] - 0s 95us/step - loss: 15.6673 - mean_absolute_error: 2.7579 - acc: 0.1240 - val_loss: 8.9789 - val_mean_absolute_error: 2.2700 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00419: val_loss improved from 9.07729 to 8.97891, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 420/500\n",
      "2072/2072 [==============================] - 0s 109us/step - loss: 15.6887 - mean_absolute_error: 2.7582 - acc: 0.1255 - val_loss: 9.0735 - val_mean_absolute_error: 2.2893 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 8.97891\n",
      "Epoch 421/500\n",
      "2072/2072 [==============================] - 0s 102us/step - loss: 15.6319 - mean_absolute_error: 2.7542 - acc: 0.1255 - val_loss: 9.0602 - val_mean_absolute_error: 2.2866 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 8.97891\n",
      "Epoch 422/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 15.6227 - mean_absolute_error: 2.7533 - acc: 0.1269 - val_loss: 9.0642 - val_mean_absolute_error: 2.2879 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 8.97891\n",
      "Epoch 423/500\n",
      "2072/2072 [==============================] - 0s 105us/step - loss: 15.6183 - mean_absolute_error: 2.7534 - acc: 0.1264 - val_loss: 9.0577 - val_mean_absolute_error: 2.2867 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 8.97891\n",
      "Epoch 424/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 15.6072 - mean_absolute_error: 2.7531 - acc: 0.1250 - val_loss: 9.0415 - val_mean_absolute_error: 2.2836 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 8.97891\n",
      "Epoch 425/500\n",
      "2072/2072 [==============================] - 0s 64us/step - loss: 15.5878 - mean_absolute_error: 2.7503 - acc: 0.1240 - val_loss: 9.0501 - val_mean_absolute_error: 2.2851 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 8.97891\n",
      "Epoch 426/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 15.6178 - mean_absolute_error: 2.7550 - acc: 0.1255 - val_loss: 8.9411 - val_mean_absolute_error: 2.2639 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00426: val_loss improved from 8.97891 to 8.94111, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 427/500\n",
      "2072/2072 [==============================] - 0s 96us/step - loss: 15.6205 - mean_absolute_error: 2.7532 - acc: 0.1240 - val_loss: 9.0109 - val_mean_absolute_error: 2.2783 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 8.94111\n",
      "Epoch 428/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 15.5946 - mean_absolute_error: 2.7523 - acc: 0.1274 - val_loss: 9.0224 - val_mean_absolute_error: 2.2807 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 8.94111\n",
      "Epoch 429/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 15.5534 - mean_absolute_error: 2.7477 - acc: 0.1264 - val_loss: 9.0305 - val_mean_absolute_error: 2.2822 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 8.94111\n",
      "Epoch 430/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 15.5775 - mean_absolute_error: 2.7513 - acc: 0.1274 - val_loss: 9.0078 - val_mean_absolute_error: 2.2782 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 8.94111\n",
      "Epoch 431/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 15.5363 - mean_absolute_error: 2.7467 - acc: 0.1240 - val_loss: 9.0111 - val_mean_absolute_error: 2.2793 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 8.94111\n",
      "Epoch 432/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 15.5511 - mean_absolute_error: 2.7491 - acc: 0.1250 - val_loss: 8.9175 - val_mean_absolute_error: 2.2614 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00432: val_loss improved from 8.94111 to 8.91747, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 433/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 15.6041 - mean_absolute_error: 2.7548 - acc: 0.1293 - val_loss: 8.9777 - val_mean_absolute_error: 2.2737 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 8.91747\n",
      "Epoch 434/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 15.5120 - mean_absolute_error: 2.7444 - acc: 0.1255 - val_loss: 8.9943 - val_mean_absolute_error: 2.2771 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 8.91747\n",
      "Epoch 435/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 15.5196 - mean_absolute_error: 2.7463 - acc: 0.1264 - val_loss: 8.9937 - val_mean_absolute_error: 2.2766 - val_acc: 0.1255\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 8.91747\n",
      "Epoch 436/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 15.5332 - mean_absolute_error: 2.7485 - acc: 0.1289 - val_loss: 8.9747 - val_mean_absolute_error: 2.2733 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 8.91747\n",
      "Epoch 437/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 15.4914 - mean_absolute_error: 2.7438 - acc: 0.1250 - val_loss: 8.9482 - val_mean_absolute_error: 2.2689 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 8.91747\n",
      "Epoch 438/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 15.5019 - mean_absolute_error: 2.7457 - acc: 0.1245 - val_loss: 8.8792 - val_mean_absolute_error: 2.2557 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00438: val_loss improved from 8.91747 to 8.87919, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 439/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 15.5673 - mean_absolute_error: 2.7519 - acc: 0.1236 - val_loss: 8.9578 - val_mean_absolute_error: 2.2711 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 8.87919\n",
      "Epoch 440/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 15.4689 - mean_absolute_error: 2.7421 - acc: 0.1269 - val_loss: 8.9317 - val_mean_absolute_error: 2.2663 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 8.87919\n",
      "Epoch 441/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 15.4722 - mean_absolute_error: 2.7430 - acc: 0.1260 - val_loss: 8.9335 - val_mean_absolute_error: 2.2664 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 8.87919\n",
      "Epoch 442/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 15.5001 - mean_absolute_error: 2.7473 - acc: 0.1255 - val_loss: 8.8383 - val_mean_absolute_error: 2.2495 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00442: val_loss improved from 8.87919 to 8.83832, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 443/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 15.5018 - mean_absolute_error: 2.7449 - acc: 0.1236 - val_loss: 8.9170 - val_mean_absolute_error: 2.2645 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 8.83832\n",
      "Epoch 444/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 15.4567 - mean_absolute_error: 2.7423 - acc: 0.1236 - val_loss: 8.9195 - val_mean_absolute_error: 2.2644 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 8.83832\n",
      "Epoch 445/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 15.4599 - mean_absolute_error: 2.7429 - acc: 0.1240 - val_loss: 8.9274 - val_mean_absolute_error: 2.2662 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 8.83832\n",
      "Epoch 446/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 15.4254 - mean_absolute_error: 2.7391 - acc: 0.1245 - val_loss: 8.9009 - val_mean_absolute_error: 2.2615 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 8.83832\n",
      "Epoch 447/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 15.4275 - mean_absolute_error: 2.7400 - acc: 0.1240 - val_loss: 8.9025 - val_mean_absolute_error: 2.2613 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 8.83832\n",
      "Epoch 448/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 15.4546 - mean_absolute_error: 2.7442 - acc: 0.1216 - val_loss: 8.7933 - val_mean_absolute_error: 2.2426 - val_acc: 0.1351\n",
      "\n",
      "Epoch 00448: val_loss improved from 8.83832 to 8.79329, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 449/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 15.4707 - mean_absolute_error: 2.7432 - acc: 0.1240 - val_loss: 8.8861 - val_mean_absolute_error: 2.2589 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 8.79329\n",
      "Epoch 450/500\n",
      "2072/2072 [==============================] - 0s 90us/step - loss: 15.4466 - mean_absolute_error: 2.7434 - acc: 0.1255 - val_loss: 8.8429 - val_mean_absolute_error: 2.2508 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 8.79329\n",
      "Epoch 451/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 15.3978 - mean_absolute_error: 2.7371 - acc: 0.1245 - val_loss: 8.8780 - val_mean_absolute_error: 2.2581 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 8.79329\n",
      "Epoch 452/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 15.3984 - mean_absolute_error: 2.7378 - acc: 0.1240 - val_loss: 8.8818 - val_mean_absolute_error: 2.2581 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 8.79329\n",
      "Epoch 453/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 15.4221 - mean_absolute_error: 2.7418 - acc: 0.1240 - val_loss: 8.8626 - val_mean_absolute_error: 2.2547 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 8.79329\n",
      "Epoch 454/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 15.3761 - mean_absolute_error: 2.7364 - acc: 0.1236 - val_loss: 8.8640 - val_mean_absolute_error: 2.2551 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 8.79329\n",
      "Epoch 455/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 15.3872 - mean_absolute_error: 2.7383 - acc: 0.1221 - val_loss: 8.7753 - val_mean_absolute_error: 2.2400 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00455: val_loss improved from 8.79329 to 8.77530, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 456/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 15.4494 - mean_absolute_error: 2.7432 - acc: 0.1240 - val_loss: 8.8291 - val_mean_absolute_error: 2.2487 - val_acc: 0.1293\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 8.77530\n",
      "Epoch 457/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 15.3610 - mean_absolute_error: 2.7349 - acc: 0.1255 - val_loss: 8.8382 - val_mean_absolute_error: 2.2503 - val_acc: 0.1332\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 8.77530\n",
      "Epoch 458/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 15.3819 - mean_absolute_error: 2.7382 - acc: 0.1264 - val_loss: 8.8412 - val_mean_absolute_error: 2.2512 - val_acc: 0.1313\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 8.77530\n",
      "Epoch 459/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 15.3366 - mean_absolute_error: 2.7329 - acc: 0.1250 - val_loss: 8.8424 - val_mean_absolute_error: 2.2514 - val_acc: 0.1351\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 8.77530\n",
      "Epoch 460/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 15.3532 - mean_absolute_error: 2.7359 - acc: 0.1264 - val_loss: 8.8431 - val_mean_absolute_error: 2.2511 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 8.77530\n",
      "Epoch 461/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2072/2072 [==============================] - 0s 76us/step - loss: 15.3700 - mean_absolute_error: 2.7386 - acc: 0.1226 - val_loss: 8.7324 - val_mean_absolute_error: 2.2331 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00461: val_loss improved from 8.77530 to 8.73245, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 462/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 15.3751 - mean_absolute_error: 2.7361 - acc: 0.1260 - val_loss: 8.8164 - val_mean_absolute_error: 2.2466 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 8.73245\n",
      "Epoch 463/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 15.3552 - mean_absolute_error: 2.7368 - acc: 0.1269 - val_loss: 8.7989 - val_mean_absolute_error: 2.2433 - val_acc: 0.1351\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 8.73245\n",
      "Epoch 464/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 15.3109 - mean_absolute_error: 2.7313 - acc: 0.1264 - val_loss: 8.8072 - val_mean_absolute_error: 2.2450 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 8.73245\n",
      "Epoch 465/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 15.3313 - mean_absolute_error: 2.7345 - acc: 0.1279 - val_loss: 8.7887 - val_mean_absolute_error: 2.2415 - val_acc: 0.1351\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 8.73245\n",
      "Epoch 466/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 15.2826 - mean_absolute_error: 2.7284 - acc: 0.1226 - val_loss: 8.8026 - val_mean_absolute_error: 2.2442 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 8.73245\n",
      "Epoch 467/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 15.3288 - mean_absolute_error: 2.7352 - acc: 0.1264 - val_loss: 8.7811 - val_mean_absolute_error: 2.2403 - val_acc: 0.1351\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 8.73245\n",
      "Epoch 468/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 15.2930 - mean_absolute_error: 2.7307 - acc: 0.1264 - val_loss: 8.7834 - val_mean_absolute_error: 2.2411 - val_acc: 0.1332\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 8.73245\n",
      "Epoch 469/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 15.2902 - mean_absolute_error: 2.7308 - acc: 0.1236 - val_loss: 8.7845 - val_mean_absolute_error: 2.2408 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 8.73245\n",
      "Epoch 470/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 15.3169 - mean_absolute_error: 2.7347 - acc: 0.1240 - val_loss: 8.7673 - val_mean_absolute_error: 2.2379 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 8.73245\n",
      "Epoch 471/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 15.2771 - mean_absolute_error: 2.7299 - acc: 0.1240 - val_loss: 8.7795 - val_mean_absolute_error: 2.2402 - val_acc: 0.1351\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 8.73245\n",
      "Epoch 472/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 15.2940 - mean_absolute_error: 2.7327 - acc: 0.1250 - val_loss: 8.7615 - val_mean_absolute_error: 2.2367 - val_acc: 0.1351\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 8.73245\n",
      "Epoch 473/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 15.2603 - mean_absolute_error: 2.7287 - acc: 0.1236 - val_loss: 8.7724 - val_mean_absolute_error: 2.2388 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 8.73245\n",
      "Epoch 474/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 15.2835 - mean_absolute_error: 2.7322 - acc: 0.1245 - val_loss: 8.7530 - val_mean_absolute_error: 2.2352 - val_acc: 0.1351\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 8.73245\n",
      "Epoch 475/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 15.2532 - mean_absolute_error: 2.7285 - acc: 0.1221 - val_loss: 8.7604 - val_mean_absolute_error: 2.2368 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 8.73245\n",
      "Epoch 476/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 15.2823 - mean_absolute_error: 2.7335 - acc: 0.1221 - val_loss: 8.6615 - val_mean_absolute_error: 2.2216 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00476: val_loss improved from 8.73245 to 8.66153, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 477/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 15.2998 - mean_absolute_error: 2.7323 - acc: 0.1250 - val_loss: 8.7502 - val_mean_absolute_error: 2.2352 - val_acc: 0.1371\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 8.66153\n",
      "Epoch 478/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 15.2766 - mean_absolute_error: 2.7327 - acc: 0.1236 - val_loss: 8.7454 - val_mean_absolute_error: 2.2339 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 8.66153\n",
      "Epoch 479/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 15.2447 - mean_absolute_error: 2.7289 - acc: 0.1240 - val_loss: 8.7525 - val_mean_absolute_error: 2.2352 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 8.66153\n",
      "Epoch 480/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 15.2489 - mean_absolute_error: 2.7302 - acc: 0.1221 - val_loss: 8.7384 - val_mean_absolute_error: 2.2323 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 8.66153\n",
      "Epoch 481/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 15.2149 - mean_absolute_error: 2.7259 - acc: 0.1202 - val_loss: 8.7414 - val_mean_absolute_error: 2.2331 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 8.66153\n",
      "Epoch 482/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 15.2400 - mean_absolute_error: 2.7298 - acc: 0.1216 - val_loss: 8.7260 - val_mean_absolute_error: 2.2301 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 8.66153\n",
      "Epoch 483/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 15.2030 - mean_absolute_error: 2.7250 - acc: 0.1211 - val_loss: 8.7341 - val_mean_absolute_error: 2.2316 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 8.66153\n",
      "Epoch 484/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 15.2315 - mean_absolute_error: 2.7292 - acc: 0.1221 - val_loss: 8.7198 - val_mean_absolute_error: 2.2289 - val_acc: 0.1390\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 8.66153\n",
      "Epoch 485/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 15.1940 - mean_absolute_error: 2.7246 - acc: 0.1226 - val_loss: 8.7271 - val_mean_absolute_error: 2.2304 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 8.66153\n",
      "Epoch 486/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 15.2207 - mean_absolute_error: 2.7286 - acc: 0.1221 - val_loss: 8.7130 - val_mean_absolute_error: 2.2277 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 8.66153\n",
      "Epoch 487/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 15.1897 - mean_absolute_error: 2.7247 - acc: 0.1226 - val_loss: 8.7191 - val_mean_absolute_error: 2.2291 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 8.66153\n",
      "Epoch 488/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 15.2083 - mean_absolute_error: 2.7282 - acc: 0.1226 - val_loss: 8.6224 - val_mean_absolute_error: 2.2146 - val_acc: 0.1486\n",
      "\n",
      "Epoch 00488: val_loss improved from 8.66153 to 8.62243, saving model to ANN_Interval_best_cRNFL.hdf5\n",
      "Epoch 489/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 15.2312 - mean_absolute_error: 2.7287 - acc: 0.1236 - val_loss: 8.7021 - val_mean_absolute_error: 2.2267 - val_acc: 0.1467\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 8.62243\n",
      "Epoch 490/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 15.2180 - mean_absolute_error: 2.7292 - acc: 0.1221 - val_loss: 8.6914 - val_mean_absolute_error: 2.2245 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 8.62243\n",
      "Epoch 491/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 15.1749 - mean_absolute_error: 2.7237 - acc: 0.1240 - val_loss: 8.7025 - val_mean_absolute_error: 2.2265 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 8.62243\n",
      "Epoch 492/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 15.1916 - mean_absolute_error: 2.7264 - acc: 0.1226 - val_loss: 8.6854 - val_mean_absolute_error: 2.2232 - val_acc: 0.1429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00492: val_loss did not improve from 8.62243\n",
      "Epoch 493/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 15.1650 - mean_absolute_error: 2.7233 - acc: 0.1240 - val_loss: 8.6919 - val_mean_absolute_error: 2.2245 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 8.62243\n",
      "Epoch 494/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 15.1912 - mean_absolute_error: 2.7271 - acc: 0.1231 - val_loss: 8.6799 - val_mean_absolute_error: 2.2221 - val_acc: 0.1467\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 8.62243\n",
      "Epoch 495/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 15.1592 - mean_absolute_error: 2.7232 - acc: 0.1216 - val_loss: 8.6864 - val_mean_absolute_error: 2.2235 - val_acc: 0.1506\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 8.62243\n",
      "Epoch 496/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 15.1779 - mean_absolute_error: 2.7260 - acc: 0.1226 - val_loss: 8.6751 - val_mean_absolute_error: 2.2212 - val_acc: 0.1486\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 8.62243\n",
      "Epoch 497/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 15.1446 - mean_absolute_error: 2.7220 - acc: 0.1216 - val_loss: 8.6863 - val_mean_absolute_error: 2.2232 - val_acc: 0.1506\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 8.62243\n",
      "Epoch 498/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 15.1635 - mean_absolute_error: 2.7248 - acc: 0.1216 - val_loss: 8.6698 - val_mean_absolute_error: 2.2201 - val_acc: 0.1486\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 8.62243\n",
      "Epoch 499/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 15.1355 - mean_absolute_error: 2.7213 - acc: 0.1207 - val_loss: 8.6808 - val_mean_absolute_error: 2.2222 - val_acc: 0.1525\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 8.62243\n",
      "Epoch 500/500\n",
      "2072/2072 [==============================] - 0s 85us/step - loss: 15.1490 - mean_absolute_error: 2.7243 - acc: 0.1216 - val_loss: 8.5805 - val_mean_absolute_error: 2.2077 - val_acc: 0.1544\n",
      "\n",
      "Epoch 00500: val_loss improved from 8.62243 to 8.58046, saving model to ANN_Interval_best_cRNFL.hdf5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1a1ecb59b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN_baseline(X, y_RNFL, 'cRNFL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2072 samples, validate on 518 samples\n",
      "Epoch 1/500\n",
      "2072/2072 [==============================] - 1s 659us/step - loss: 3241.9067 - mean_absolute_error: 50.8588 - acc: 0.0029 - val_loss: 188.9456 - val_mean_absolute_error: 13.1880 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 188.94557, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 2/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 36.7634 - mean_absolute_error: 4.4397 - acc: 0.0936 - val_loss: 13.9833 - val_mean_absolute_error: 2.6533 - val_acc: 0.1351\n",
      "\n",
      "Epoch 00002: val_loss improved from 188.94557 to 13.98330, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 3/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 14.4259 - mean_absolute_error: 2.7364 - acc: 0.1385 - val_loss: 14.0699 - val_mean_absolute_error: 2.6696 - val_acc: 0.1429\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 13.98330\n",
      "Epoch 4/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 13.9131 - mean_absolute_error: 2.6688 - acc: 0.1366 - val_loss: 13.6310 - val_mean_absolute_error: 2.6144 - val_acc: 0.1544\n",
      "\n",
      "Epoch 00004: val_loss improved from 13.98330 to 13.63096, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 5/500\n",
      "2072/2072 [==============================] - 0s 88us/step - loss: 13.3919 - mean_absolute_error: 2.5997 - acc: 0.1404 - val_loss: 13.0814 - val_mean_absolute_error: 2.5422 - val_acc: 0.1583\n",
      "\n",
      "Epoch 00005: val_loss improved from 13.63096 to 13.08135, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 6/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 12.8519 - mean_absolute_error: 2.5276 - acc: 0.1438 - val_loss: 12.4029 - val_mean_absolute_error: 2.4481 - val_acc: 0.1602\n",
      "\n",
      "Epoch 00006: val_loss improved from 13.08135 to 12.40289, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 7/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 12.2917 - mean_absolute_error: 2.4519 - acc: 0.1506 - val_loss: 11.6362 - val_mean_absolute_error: 2.3366 - val_acc: 0.1718\n",
      "\n",
      "Epoch 00007: val_loss improved from 12.40289 to 11.63621, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 8/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 11.7181 - mean_absolute_error: 2.3720 - acc: 0.1544 - val_loss: 10.9490 - val_mean_absolute_error: 2.2371 - val_acc: 0.1583\n",
      "\n",
      "Epoch 00008: val_loss improved from 11.63621 to 10.94899, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 9/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 11.1589 - mean_absolute_error: 2.2905 - acc: 0.1607 - val_loss: 10.3994 - val_mean_absolute_error: 2.1518 - val_acc: 0.1699\n",
      "\n",
      "Epoch 00009: val_loss improved from 10.94899 to 10.39937, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 10/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 10.6375 - mean_absolute_error: 2.2105 - acc: 0.1670 - val_loss: 9.9423 - val_mean_absolute_error: 2.0780 - val_acc: 0.1815\n",
      "\n",
      "Epoch 00010: val_loss improved from 10.39937 to 9.94233, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 11/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 10.1580 - mean_absolute_error: 2.1320 - acc: 0.1713 - val_loss: 9.5532 - val_mean_absolute_error: 2.0119 - val_acc: 0.1834\n",
      "\n",
      "Epoch 00011: val_loss improved from 9.94233 to 9.55317, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 12/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 9.7199 - mean_absolute_error: 2.0557 - acc: 0.1795 - val_loss: 9.2214 - val_mean_absolute_error: 1.9528 - val_acc: 0.1911\n",
      "\n",
      "Epoch 00012: val_loss improved from 9.55317 to 9.22142, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 13/500\n",
      "2072/2072 [==============================] - 0s 89us/step - loss: 9.3225 - mean_absolute_error: 1.9829 - acc: 0.1887 - val_loss: 8.9257 - val_mean_absolute_error: 1.8978 - val_acc: 0.1969\n",
      "\n",
      "Epoch 00013: val_loss improved from 9.22142 to 8.92573, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 14/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 8.9648 - mean_absolute_error: 1.9144 - acc: 0.1950 - val_loss: 8.6428 - val_mean_absolute_error: 1.8434 - val_acc: 0.1988\n",
      "\n",
      "Epoch 00014: val_loss improved from 8.92573 to 8.64281, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 15/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 8.6477 - mean_absolute_error: 1.8515 - acc: 0.2085 - val_loss: 8.3725 - val_mean_absolute_error: 1.7886 - val_acc: 0.2162\n",
      "\n",
      "Epoch 00015: val_loss improved from 8.64281 to 8.37249, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 16/500\n",
      "2072/2072 [==============================] - 0s 85us/step - loss: 8.3720 - mean_absolute_error: 1.7938 - acc: 0.2201 - val_loss: 8.1310 - val_mean_absolute_error: 1.7373 - val_acc: 0.2181\n",
      "\n",
      "Epoch 00016: val_loss improved from 8.37249 to 8.13099, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 17/500\n",
      "2072/2072 [==============================] - 0s 88us/step - loss: 8.1366 - mean_absolute_error: 1.7417 - acc: 0.2273 - val_loss: 7.9268 - val_mean_absolute_error: 1.6920 - val_acc: 0.2297\n",
      "\n",
      "Epoch 00017: val_loss improved from 8.13099 to 7.92682, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 18/500\n",
      "2072/2072 [==============================] - 0s 87us/step - loss: 7.9382 - mean_absolute_error: 1.6948 - acc: 0.2403 - val_loss: 7.7611 - val_mean_absolute_error: 1.6516 - val_acc: 0.2278\n",
      "\n",
      "Epoch 00018: val_loss improved from 7.92682 to 7.76113, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 19/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 7.7726 - mean_absolute_error: 1.6539 - acc: 0.2548 - val_loss: 7.6318 - val_mean_absolute_error: 1.6190 - val_acc: 0.2297\n",
      "\n",
      "Epoch 00019: val_loss improved from 7.76113 to 7.63182, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 20/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 7.6352 - mean_absolute_error: 1.6189 - acc: 0.2577 - val_loss: 7.5335 - val_mean_absolute_error: 1.5929 - val_acc: 0.2413\n",
      "\n",
      "Epoch 00020: val_loss improved from 7.63182 to 7.53354, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 21/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 7.5215 - mean_absolute_error: 1.5896 - acc: 0.2654 - val_loss: 7.4573 - val_mean_absolute_error: 1.5705 - val_acc: 0.2413\n",
      "\n",
      "Epoch 00021: val_loss improved from 7.53354 to 7.45727, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 22/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 7.4275 - mean_absolute_error: 1.5650 - acc: 0.2717 - val_loss: 7.3933 - val_mean_absolute_error: 1.5513 - val_acc: 0.2568\n",
      "\n",
      "Epoch 00022: val_loss improved from 7.45727 to 7.39334, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 23/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 7.3498 - mean_absolute_error: 1.5441 - acc: 0.2790 - val_loss: 7.3367 - val_mean_absolute_error: 1.5341 - val_acc: 0.2625\n",
      "\n",
      "Epoch 00023: val_loss improved from 7.39334 to 7.33673, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 24/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 7.2854 - mean_absolute_error: 1.5264 - acc: 0.2823 - val_loss: 7.2867 - val_mean_absolute_error: 1.5181 - val_acc: 0.2664\n",
      "\n",
      "Epoch 00024: val_loss improved from 7.33673 to 7.28673, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 25/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 7.2316 - mean_absolute_error: 1.5108 - acc: 0.2838 - val_loss: 7.2446 - val_mean_absolute_error: 1.5048 - val_acc: 0.2703\n",
      "\n",
      "Epoch 00025: val_loss improved from 7.28673 to 7.24461, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 26/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 7.1859 - mean_absolute_error: 1.4972 - acc: 0.2828 - val_loss: 7.2120 - val_mean_absolute_error: 1.4932 - val_acc: 0.2645\n",
      "\n",
      "Epoch 00026: val_loss improved from 7.24461 to 7.21195, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 27/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 7.1464 - mean_absolute_error: 1.4856 - acc: 0.2847 - val_loss: 7.1891 - val_mean_absolute_error: 1.4832 - val_acc: 0.2625\n",
      "\n",
      "Epoch 00027: val_loss improved from 7.21195 to 7.18914, saving model to ANN_Interval_best_GCIPL.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 7.1115 - mean_absolute_error: 1.4756 - acc: 0.2867 - val_loss: 7.1744 - val_mean_absolute_error: 1.4748 - val_acc: 0.2568\n",
      "\n",
      "Epoch 00028: val_loss improved from 7.18914 to 7.17443, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 29/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 7.0809 - mean_absolute_error: 1.4672 - acc: 0.2901 - val_loss: 7.1647 - val_mean_absolute_error: 1.4671 - val_acc: 0.2664\n",
      "\n",
      "Epoch 00029: val_loss improved from 7.17443 to 7.16470, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 30/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 7.0545 - mean_absolute_error: 1.4599 - acc: 0.2920 - val_loss: 7.1571 - val_mean_absolute_error: 1.4602 - val_acc: 0.2780\n",
      "\n",
      "Epoch 00030: val_loss improved from 7.16470 to 7.15710, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 31/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 7.0325 - mean_absolute_error: 1.4539 - acc: 0.2997 - val_loss: 7.1506 - val_mean_absolute_error: 1.4537 - val_acc: 0.2761\n",
      "\n",
      "Epoch 00031: val_loss improved from 7.15710 to 7.15064, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 32/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 7.0147 - mean_absolute_error: 1.4494 - acc: 0.3007 - val_loss: 7.1455 - val_mean_absolute_error: 1.4481 - val_acc: 0.2780\n",
      "\n",
      "Epoch 00032: val_loss improved from 7.15064 to 7.14552, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 33/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 7.0009 - mean_absolute_error: 1.4462 - acc: 0.3002 - val_loss: 7.1421 - val_mean_absolute_error: 1.4431 - val_acc: 0.2741\n",
      "\n",
      "Epoch 00033: val_loss improved from 7.14552 to 7.14212, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 34/500\n",
      "2072/2072 [==============================] - 0s 91us/step - loss: 6.9910 - mean_absolute_error: 1.4440 - acc: 0.3026 - val_loss: 7.1404 - val_mean_absolute_error: 1.4384 - val_acc: 0.2761\n",
      "\n",
      "Epoch 00034: val_loss improved from 7.14212 to 7.14035, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 35/500\n",
      "2072/2072 [==============================] - 0s 101us/step - loss: 6.9851 - mean_absolute_error: 1.4434 - acc: 0.2992 - val_loss: 7.1394 - val_mean_absolute_error: 1.4341 - val_acc: 0.2876\n",
      "\n",
      "Epoch 00035: val_loss improved from 7.14035 to 7.13944, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 36/500\n",
      "2072/2072 [==============================] - 0s 92us/step - loss: 6.9834 - mean_absolute_error: 1.4444 - acc: 0.2949 - val_loss: 7.1386 - val_mean_absolute_error: 1.4300 - val_acc: 0.2857\n",
      "\n",
      "Epoch 00036: val_loss improved from 7.13944 to 7.13858, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 37/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 6.9862 - mean_absolute_error: 1.4472 - acc: 0.2905 - val_loss: 7.1380 - val_mean_absolute_error: 1.4262 - val_acc: 0.2934\n",
      "\n",
      "Epoch 00037: val_loss improved from 7.13858 to 7.13797, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 38/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.9939 - mean_absolute_error: 1.4515 - acc: 0.2828 - val_loss: 7.1386 - val_mean_absolute_error: 1.4228 - val_acc: 0.2934\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 7.13797\n",
      "Epoch 39/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 7.0064 - mean_absolute_error: 1.4567 - acc: 0.2852 - val_loss: 7.1412 - val_mean_absolute_error: 1.4196 - val_acc: 0.2934\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 7.13797\n",
      "Epoch 40/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 7.0231 - mean_absolute_error: 1.4628 - acc: 0.2847 - val_loss: 7.1466 - val_mean_absolute_error: 1.4167 - val_acc: 0.2973\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 7.13797\n",
      "Epoch 41/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 7.0426 - mean_absolute_error: 1.4696 - acc: 0.2785 - val_loss: 7.1552 - val_mean_absolute_error: 1.4141 - val_acc: 0.2973\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 7.13797\n",
      "Epoch 42/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 7.0634 - mean_absolute_error: 1.4768 - acc: 0.2741 - val_loss: 7.1672 - val_mean_absolute_error: 1.4119 - val_acc: 0.2934\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 7.13797\n",
      "Epoch 43/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 7.0835 - mean_absolute_error: 1.4841 - acc: 0.2732 - val_loss: 7.1815 - val_mean_absolute_error: 1.4103 - val_acc: 0.3069\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 7.13797\n",
      "Epoch 44/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 7.1016 - mean_absolute_error: 1.4908 - acc: 0.2765 - val_loss: 7.1960 - val_mean_absolute_error: 1.4089 - val_acc: 0.3069\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 7.13797\n",
      "Epoch 45/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 7.1171 - mean_absolute_error: 1.4966 - acc: 0.2741 - val_loss: 7.2079 - val_mean_absolute_error: 1.4077 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 7.13797\n",
      "Epoch 46/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 7.1303 - mean_absolute_error: 1.5019 - acc: 0.2746 - val_loss: 7.2157 - val_mean_absolute_error: 1.4065 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 7.13797\n",
      "Epoch 47/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 7.1417 - mean_absolute_error: 1.5064 - acc: 0.2727 - val_loss: 7.2193 - val_mean_absolute_error: 1.4049 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 7.13797\n",
      "Epoch 48/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 7.1516 - mean_absolute_error: 1.5106 - acc: 0.2693 - val_loss: 7.2194 - val_mean_absolute_error: 1.4032 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 7.13797\n",
      "Epoch 49/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 7.1602 - mean_absolute_error: 1.5146 - acc: 0.2669 - val_loss: 7.2174 - val_mean_absolute_error: 1.4015 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 7.13797\n",
      "Epoch 50/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 7.1672 - mean_absolute_error: 1.5184 - acc: 0.2635 - val_loss: 7.2142 - val_mean_absolute_error: 1.3999 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 7.13797\n",
      "Epoch 51/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 7.1730 - mean_absolute_error: 1.5220 - acc: 0.2621 - val_loss: 7.2107 - val_mean_absolute_error: 1.3984 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 7.13797\n",
      "Epoch 52/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 7.1772 - mean_absolute_error: 1.5251 - acc: 0.2640 - val_loss: 7.2072 - val_mean_absolute_error: 1.3970 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 7.13797\n",
      "Epoch 53/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 7.1799 - mean_absolute_error: 1.5278 - acc: 0.2625 - val_loss: 7.2040 - val_mean_absolute_error: 1.3958 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 7.13797\n",
      "Epoch 54/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 7.1810 - mean_absolute_error: 1.5300 - acc: 0.2611 - val_loss: 7.2010 - val_mean_absolute_error: 1.3948 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 7.13797\n",
      "Epoch 55/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 7.1807 - mean_absolute_error: 1.5318 - acc: 0.2597 - val_loss: 7.1983 - val_mean_absolute_error: 1.3939 - val_acc: 0.3108\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 7.13797\n",
      "Epoch 56/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 7.1790 - mean_absolute_error: 1.5333 - acc: 0.2597 - val_loss: 7.1958 - val_mean_absolute_error: 1.3931 - val_acc: 0.3108\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 7.13797\n",
      "Epoch 57/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 7.1763 - mean_absolute_error: 1.5344 - acc: 0.2606 - val_loss: 7.1934 - val_mean_absolute_error: 1.3924 - val_acc: 0.3069\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 7.13797\n",
      "Epoch 58/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 7.1723 - mean_absolute_error: 1.5352 - acc: 0.2587 - val_loss: 7.1911 - val_mean_absolute_error: 1.3918 - val_acc: 0.3108\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 7.13797\n",
      "Epoch 59/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 7.1677 - mean_absolute_error: 1.5358 - acc: 0.2577 - val_loss: 7.1889 - val_mean_absolute_error: 1.3912 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 7.13797\n",
      "Epoch 60/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 7.1621 - mean_absolute_error: 1.5362 - acc: 0.2577 - val_loss: 7.1865 - val_mean_absolute_error: 1.3906 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 7.13797\n",
      "Epoch 61/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 7.1567 - mean_absolute_error: 1.5365 - acc: 0.2563 - val_loss: 7.1841 - val_mean_absolute_error: 1.3901 - val_acc: 0.3108\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 7.13797\n",
      "Epoch 62/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 7.1502 - mean_absolute_error: 1.5366 - acc: 0.2563 - val_loss: 7.1817 - val_mean_absolute_error: 1.3896 - val_acc: 0.3089\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 7.13797\n",
      "Epoch 63/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 7.1436 - mean_absolute_error: 1.5367 - acc: 0.2553 - val_loss: 7.1791 - val_mean_absolute_error: 1.3891 - val_acc: 0.3089\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 7.13797\n",
      "Epoch 64/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 7.1367 - mean_absolute_error: 1.5366 - acc: 0.2558 - val_loss: 7.1764 - val_mean_absolute_error: 1.3887 - val_acc: 0.3108\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 7.13797\n",
      "Epoch 65/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 7.1295 - mean_absolute_error: 1.5365 - acc: 0.2543 - val_loss: 7.1736 - val_mean_absolute_error: 1.3882 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 7.13797\n",
      "Epoch 66/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 7.1223 - mean_absolute_error: 1.5364 - acc: 0.2548 - val_loss: 7.1707 - val_mean_absolute_error: 1.3877 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 7.13797\n",
      "Epoch 67/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 7.1148 - mean_absolute_error: 1.5361 - acc: 0.2534 - val_loss: 7.1676 - val_mean_absolute_error: 1.3872 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 7.13797\n",
      "Epoch 68/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 7.1074 - mean_absolute_error: 1.5358 - acc: 0.2543 - val_loss: 7.1643 - val_mean_absolute_error: 1.3867 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 7.13797\n",
      "Epoch 69/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 7.0999 - mean_absolute_error: 1.5355 - acc: 0.2548 - val_loss: 7.1609 - val_mean_absolute_error: 1.3863 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 7.13797\n",
      "Epoch 70/500\n",
      "2072/2072 [==============================] - 0s 85us/step - loss: 7.0925 - mean_absolute_error: 1.5352 - acc: 0.2543 - val_loss: 7.1572 - val_mean_absolute_error: 1.3858 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 7.13797\n",
      "Epoch 71/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 7.0848 - mean_absolute_error: 1.5348 - acc: 0.2553 - val_loss: 7.1536 - val_mean_absolute_error: 1.3854 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 7.13797\n",
      "Epoch 72/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 7.0774 - mean_absolute_error: 1.5345 - acc: 0.2558 - val_loss: 7.1497 - val_mean_absolute_error: 1.3850 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 7.13797\n",
      "Epoch 73/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 7.0699 - mean_absolute_error: 1.5341 - acc: 0.2563 - val_loss: 7.1457 - val_mean_absolute_error: 1.3846 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 7.13797\n",
      "Epoch 74/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 7.0625 - mean_absolute_error: 1.5336 - acc: 0.2563 - val_loss: 7.1415 - val_mean_absolute_error: 1.3842 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 7.13797\n",
      "Epoch 75/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 7.0551 - mean_absolute_error: 1.5332 - acc: 0.2553 - val_loss: 7.1372 - val_mean_absolute_error: 1.3838 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00075: val_loss improved from 7.13797 to 7.13724, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 76/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 7.0478 - mean_absolute_error: 1.5328 - acc: 0.2558 - val_loss: 7.1328 - val_mean_absolute_error: 1.3834 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00076: val_loss improved from 7.13724 to 7.13280, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 77/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 7.0405 - mean_absolute_error: 1.5324 - acc: 0.2563 - val_loss: 7.1282 - val_mean_absolute_error: 1.3829 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00077: val_loss improved from 7.13280 to 7.12824, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 78/500\n",
      "2072/2072 [==============================] - 0s 88us/step - loss: 7.0336 - mean_absolute_error: 1.5321 - acc: 0.2572 - val_loss: 7.1236 - val_mean_absolute_error: 1.3825 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00078: val_loss improved from 7.12824 to 7.12355, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 79/500\n",
      "2072/2072 [==============================] - 0s 87us/step - loss: 7.0258 - mean_absolute_error: 1.5315 - acc: 0.2568 - val_loss: 7.1187 - val_mean_absolute_error: 1.3821 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00079: val_loss improved from 7.12355 to 7.11866, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 80/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 7.0190 - mean_absolute_error: 1.5312 - acc: 0.2582 - val_loss: 7.1138 - val_mean_absolute_error: 1.3817 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00080: val_loss improved from 7.11866 to 7.11376, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 81/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 7.0120 - mean_absolute_error: 1.5307 - acc: 0.2587 - val_loss: 7.1087 - val_mean_absolute_error: 1.3813 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00081: val_loss improved from 7.11376 to 7.10872, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 82/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 7.0051 - mean_absolute_error: 1.5303 - acc: 0.2582 - val_loss: 7.1035 - val_mean_absolute_error: 1.3809 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00082: val_loss improved from 7.10872 to 7.10351, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 83/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.9977 - mean_absolute_error: 1.5297 - acc: 0.2587 - val_loss: 7.0982 - val_mean_absolute_error: 1.3805 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00083: val_loss improved from 7.10351 to 7.09822, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 84/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 6.9914 - mean_absolute_error: 1.5294 - acc: 0.2592 - val_loss: 7.0928 - val_mean_absolute_error: 1.3802 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00084: val_loss improved from 7.09822 to 7.09284, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 85/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 6.9845 - mean_absolute_error: 1.5289 - acc: 0.2601 - val_loss: 7.0873 - val_mean_absolute_error: 1.3798 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00085: val_loss improved from 7.09284 to 7.08730, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 86/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.9779 - mean_absolute_error: 1.5285 - acc: 0.2611 - val_loss: 7.0818 - val_mean_absolute_error: 1.3795 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00086: val_loss improved from 7.08730 to 7.08177, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 87/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.9713 - mean_absolute_error: 1.5280 - acc: 0.2616 - val_loss: 7.0760 - val_mean_absolute_error: 1.3791 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00087: val_loss improved from 7.08177 to 7.07601, saving model to ANN_Interval_best_GCIPL.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 6.9648 - mean_absolute_error: 1.5275 - acc: 0.2616 - val_loss: 7.0703 - val_mean_absolute_error: 1.3788 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00088: val_loss improved from 7.07601 to 7.07035, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 89/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 6.9584 - mean_absolute_error: 1.5270 - acc: 0.2616 - val_loss: 7.0645 - val_mean_absolute_error: 1.3784 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00089: val_loss improved from 7.07035 to 7.06447, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 90/500\n",
      "2072/2072 [==============================] - 0s 88us/step - loss: 6.9523 - mean_absolute_error: 1.5267 - acc: 0.2606 - val_loss: 7.0583 - val_mean_absolute_error: 1.3780 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00090: val_loss improved from 7.06447 to 7.05827, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 91/500\n",
      "2072/2072 [==============================] - 0s 90us/step - loss: 6.9456 - mean_absolute_error: 1.5260 - acc: 0.2616 - val_loss: 7.0526 - val_mean_absolute_error: 1.3777 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00091: val_loss improved from 7.05827 to 7.05255, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 92/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 6.9393 - mean_absolute_error: 1.5255 - acc: 0.2621 - val_loss: 7.0465 - val_mean_absolute_error: 1.3773 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00092: val_loss improved from 7.05255 to 7.04646, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 93/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.9332 - mean_absolute_error: 1.5250 - acc: 0.2621 - val_loss: 7.0402 - val_mean_absolute_error: 1.3769 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00093: val_loss improved from 7.04646 to 7.04023, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 94/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.9271 - mean_absolute_error: 1.5245 - acc: 0.2621 - val_loss: 7.0340 - val_mean_absolute_error: 1.3766 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00094: val_loss improved from 7.04023 to 7.03399, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 95/500\n",
      "2072/2072 [==============================] - 0s 106us/step - loss: 6.9212 - mean_absolute_error: 1.5240 - acc: 0.2611 - val_loss: 7.0277 - val_mean_absolute_error: 1.3762 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00095: val_loss improved from 7.03399 to 7.02768, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 96/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 6.9152 - mean_absolute_error: 1.5234 - acc: 0.2597 - val_loss: 7.0213 - val_mean_absolute_error: 1.3758 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00096: val_loss improved from 7.02768 to 7.02131, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 97/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.9084 - mean_absolute_error: 1.5226 - acc: 0.2611 - val_loss: 7.0149 - val_mean_absolute_error: 1.3755 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00097: val_loss improved from 7.02131 to 7.01491, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 98/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.9039 - mean_absolute_error: 1.5224 - acc: 0.2611 - val_loss: 7.0084 - val_mean_absolute_error: 1.3751 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00098: val_loss improved from 7.01491 to 7.00836, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 99/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.8984 - mean_absolute_error: 1.5219 - acc: 0.2597 - val_loss: 7.0018 - val_mean_absolute_error: 1.3747 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00099: val_loss improved from 7.00836 to 7.00179, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 100/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 6.8926 - mean_absolute_error: 1.5213 - acc: 0.2592 - val_loss: 6.9953 - val_mean_absolute_error: 1.3743 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00100: val_loss improved from 7.00179 to 6.99534, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 101/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 6.8872 - mean_absolute_error: 1.5207 - acc: 0.2592 - val_loss: 6.9887 - val_mean_absolute_error: 1.3739 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00101: val_loss improved from 6.99534 to 6.98871, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 102/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.8819 - mean_absolute_error: 1.5202 - acc: 0.2597 - val_loss: 6.9821 - val_mean_absolute_error: 1.3735 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00102: val_loss improved from 6.98871 to 6.98213, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 103/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 6.8765 - mean_absolute_error: 1.5198 - acc: 0.2597 - val_loss: 6.9754 - val_mean_absolute_error: 1.3731 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00103: val_loss improved from 6.98213 to 6.97543, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 104/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.8713 - mean_absolute_error: 1.5195 - acc: 0.2597 - val_loss: 6.9687 - val_mean_absolute_error: 1.3727 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00104: val_loss improved from 6.97543 to 6.96875, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 105/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.8663 - mean_absolute_error: 1.5191 - acc: 0.2601 - val_loss: 6.9620 - val_mean_absolute_error: 1.3723 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00105: val_loss improved from 6.96875 to 6.96199, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 106/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.8614 - mean_absolute_error: 1.5188 - acc: 0.2597 - val_loss: 6.9553 - val_mean_absolute_error: 1.3719 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00106: val_loss improved from 6.96199 to 6.95532, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 107/500\n",
      "2072/2072 [==============================] - 0s 89us/step - loss: 6.8564 - mean_absolute_error: 1.5185 - acc: 0.2601 - val_loss: 6.9486 - val_mean_absolute_error: 1.3715 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00107: val_loss improved from 6.95532 to 6.94865, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 108/500\n",
      "2072/2072 [==============================] - 0s 96us/step - loss: 6.8516 - mean_absolute_error: 1.5182 - acc: 0.2606 - val_loss: 6.9419 - val_mean_absolute_error: 1.3711 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00108: val_loss improved from 6.94865 to 6.94194, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 109/500\n",
      "2072/2072 [==============================] - 0s 89us/step - loss: 6.8469 - mean_absolute_error: 1.5178 - acc: 0.2601 - val_loss: 6.9353 - val_mean_absolute_error: 1.3707 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00109: val_loss improved from 6.94194 to 6.93530, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 110/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.8423 - mean_absolute_error: 1.5175 - acc: 0.2601 - val_loss: 6.9285 - val_mean_absolute_error: 1.3704 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00110: val_loss improved from 6.93530 to 6.92845, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 111/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 6.8383 - mean_absolute_error: 1.5172 - acc: 0.2606 - val_loss: 6.9219 - val_mean_absolute_error: 1.3700 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00111: val_loss improved from 6.92845 to 6.92192, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 112/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.8394 - mean_absolute_error: 1.5174 - acc: 0.2630 - val_loss: 6.9111 - val_mean_absolute_error: 1.3691 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00112: val_loss improved from 6.92192 to 6.91113, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 113/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.8170 - mean_absolute_error: 1.5130 - acc: 0.2630 - val_loss: 6.9090 - val_mean_absolute_error: 1.3693 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00113: val_loss improved from 6.91113 to 6.90904, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 114/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.8256 - mean_absolute_error: 1.5162 - acc: 0.2606 - val_loss: 6.9019 - val_mean_absolute_error: 1.3689 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00114: val_loss improved from 6.90904 to 6.90191, saving model to ANN_Interval_best_GCIPL.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.8215 - mean_absolute_error: 1.5159 - acc: 0.2606 - val_loss: 6.8956 - val_mean_absolute_error: 1.3685 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00115: val_loss improved from 6.90191 to 6.89558, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 116/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.8170 - mean_absolute_error: 1.5153 - acc: 0.2592 - val_loss: 6.8892 - val_mean_absolute_error: 1.3682 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00116: val_loss improved from 6.89558 to 6.88917, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 117/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 6.8136 - mean_absolute_error: 1.5151 - acc: 0.2592 - val_loss: 6.8828 - val_mean_absolute_error: 1.3678 - val_acc: 0.3108\n",
      "\n",
      "Epoch 00117: val_loss improved from 6.88917 to 6.88284, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 118/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 6.8098 - mean_absolute_error: 1.5147 - acc: 0.2592 - val_loss: 6.8766 - val_mean_absolute_error: 1.3674 - val_acc: 0.3108\n",
      "\n",
      "Epoch 00118: val_loss improved from 6.88284 to 6.87657, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 119/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.8061 - mean_absolute_error: 1.5143 - acc: 0.2601 - val_loss: 6.8703 - val_mean_absolute_error: 1.3670 - val_acc: 0.3108\n",
      "\n",
      "Epoch 00119: val_loss improved from 6.87657 to 6.87028, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 120/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.8025 - mean_absolute_error: 1.5140 - acc: 0.2611 - val_loss: 6.8642 - val_mean_absolute_error: 1.3667 - val_acc: 0.3108\n",
      "\n",
      "Epoch 00120: val_loss improved from 6.87028 to 6.86422, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 121/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 6.7989 - mean_absolute_error: 1.5136 - acc: 0.2611 - val_loss: 6.8582 - val_mean_absolute_error: 1.3663 - val_acc: 0.3108\n",
      "\n",
      "Epoch 00121: val_loss improved from 6.86422 to 6.85815, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 122/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.7956 - mean_absolute_error: 1.5132 - acc: 0.2611 - val_loss: 6.8521 - val_mean_absolute_error: 1.3660 - val_acc: 0.3108\n",
      "\n",
      "Epoch 00122: val_loss improved from 6.85815 to 6.85210, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 123/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.7922 - mean_absolute_error: 1.5129 - acc: 0.2606 - val_loss: 6.8463 - val_mean_absolute_error: 1.3657 - val_acc: 0.3089\n",
      "\n",
      "Epoch 00123: val_loss improved from 6.85210 to 6.84626, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 124/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.7891 - mean_absolute_error: 1.5125 - acc: 0.2616 - val_loss: 6.8403 - val_mean_absolute_error: 1.3653 - val_acc: 0.3089\n",
      "\n",
      "Epoch 00124: val_loss improved from 6.84626 to 6.84034, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 125/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.7858 - mean_absolute_error: 1.5121 - acc: 0.2621 - val_loss: 6.8347 - val_mean_absolute_error: 1.3650 - val_acc: 0.3089\n",
      "\n",
      "Epoch 00125: val_loss improved from 6.84034 to 6.83468, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 126/500\n",
      "2072/2072 [==============================] - 0s 99us/step - loss: 6.7827 - mean_absolute_error: 1.5118 - acc: 0.2625 - val_loss: 6.8290 - val_mean_absolute_error: 1.3647 - val_acc: 0.3108\n",
      "\n",
      "Epoch 00126: val_loss improved from 6.83468 to 6.82905, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 127/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 6.7796 - mean_absolute_error: 1.5114 - acc: 0.2616 - val_loss: 6.8235 - val_mean_absolute_error: 1.3644 - val_acc: 0.3108\n",
      "\n",
      "Epoch 00127: val_loss improved from 6.82905 to 6.82350, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 128/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 6.7766 - mean_absolute_error: 1.5110 - acc: 0.2616 - val_loss: 6.8179 - val_mean_absolute_error: 1.3641 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00128: val_loss improved from 6.82350 to 6.81794, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 129/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 6.7739 - mean_absolute_error: 1.5107 - acc: 0.2616 - val_loss: 6.8125 - val_mean_absolute_error: 1.3638 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00129: val_loss improved from 6.81794 to 6.81245, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 130/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 6.7712 - mean_absolute_error: 1.5104 - acc: 0.2621 - val_loss: 6.8072 - val_mean_absolute_error: 1.3635 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00130: val_loss improved from 6.81245 to 6.80716, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 131/500\n",
      "2072/2072 [==============================] - 0s 106us/step - loss: 6.7684 - mean_absolute_error: 1.5101 - acc: 0.2625 - val_loss: 6.8019 - val_mean_absolute_error: 1.3632 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00131: val_loss improved from 6.80716 to 6.80194, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 132/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 6.7657 - mean_absolute_error: 1.5097 - acc: 0.2625 - val_loss: 6.7967 - val_mean_absolute_error: 1.3629 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00132: val_loss improved from 6.80194 to 6.79669, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 133/500\n",
      "2072/2072 [==============================] - 0s 87us/step - loss: 6.7632 - mean_absolute_error: 1.5094 - acc: 0.2635 - val_loss: 6.7917 - val_mean_absolute_error: 1.3627 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00133: val_loss improved from 6.79669 to 6.79175, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 134/500\n",
      "2072/2072 [==============================] - 0s 88us/step - loss: 6.7607 - mean_absolute_error: 1.5091 - acc: 0.2635 - val_loss: 6.7867 - val_mean_absolute_error: 1.3624 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00134: val_loss improved from 6.79175 to 6.78670, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 135/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 6.7582 - mean_absolute_error: 1.5088 - acc: 0.2635 - val_loss: 6.7818 - val_mean_absolute_error: 1.3621 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00135: val_loss improved from 6.78670 to 6.78178, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 136/500\n",
      "2072/2072 [==============================] - 0s 97us/step - loss: 6.7560 - mean_absolute_error: 1.5085 - acc: 0.2645 - val_loss: 6.7769 - val_mean_absolute_error: 1.3618 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00136: val_loss improved from 6.78178 to 6.77685, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 137/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 6.7534 - mean_absolute_error: 1.5082 - acc: 0.2645 - val_loss: 6.7722 - val_mean_absolute_error: 1.3616 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00137: val_loss improved from 6.77685 to 6.77216, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 138/500\n",
      "2072/2072 [==============================] - 0s 96us/step - loss: 6.7511 - mean_absolute_error: 1.5079 - acc: 0.2645 - val_loss: 6.7674 - val_mean_absolute_error: 1.3613 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00138: val_loss improved from 6.77216 to 6.76742, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 139/500\n",
      "2072/2072 [==============================] - 0s 89us/step - loss: 6.7489 - mean_absolute_error: 1.5076 - acc: 0.2650 - val_loss: 6.7628 - val_mean_absolute_error: 1.3611 - val_acc: 0.3108\n",
      "\n",
      "Epoch 00139: val_loss improved from 6.76742 to 6.76277, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 140/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 6.7467 - mean_absolute_error: 1.5074 - acc: 0.2650 - val_loss: 6.7582 - val_mean_absolute_error: 1.3609 - val_acc: 0.3108\n",
      "\n",
      "Epoch 00140: val_loss improved from 6.76277 to 6.75823, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 141/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 6.7445 - mean_absolute_error: 1.5071 - acc: 0.2654 - val_loss: 6.7537 - val_mean_absolute_error: 1.3606 - val_acc: 0.3108\n",
      "\n",
      "Epoch 00141: val_loss improved from 6.75823 to 6.75370, saving model to ANN_Interval_best_GCIPL.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 6.7423 - mean_absolute_error: 1.5068 - acc: 0.2654 - val_loss: 6.7492 - val_mean_absolute_error: 1.3604 - val_acc: 0.3089\n",
      "\n",
      "Epoch 00142: val_loss improved from 6.75370 to 6.74924, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 143/500\n",
      "2072/2072 [==============================] - 0s 85us/step - loss: 6.7403 - mean_absolute_error: 1.5066 - acc: 0.2650 - val_loss: 6.7448 - val_mean_absolute_error: 1.3602 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00143: val_loss improved from 6.74924 to 6.74485, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 144/500\n",
      "2072/2072 [==============================] - 0s 85us/step - loss: 6.7384 - mean_absolute_error: 1.5064 - acc: 0.2659 - val_loss: 6.7405 - val_mean_absolute_error: 1.3600 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00144: val_loss improved from 6.74485 to 6.74051, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 145/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 6.7706 - mean_absolute_error: 1.5150 - acc: 0.2606 - val_loss: 6.7400 - val_mean_absolute_error: 1.3603 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00145: val_loss improved from 6.74051 to 6.73997, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 146/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 6.7294 - mean_absolute_error: 1.5046 - acc: 0.2664 - val_loss: 6.7338 - val_mean_absolute_error: 1.3598 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00146: val_loss improved from 6.73997 to 6.73383, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 147/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 6.7292 - mean_absolute_error: 1.5048 - acc: 0.2659 - val_loss: 6.7293 - val_mean_absolute_error: 1.3595 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00147: val_loss improved from 6.73383 to 6.72928, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 148/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 6.7278 - mean_absolute_error: 1.5047 - acc: 0.2669 - val_loss: 6.7249 - val_mean_absolute_error: 1.3593 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00148: val_loss improved from 6.72928 to 6.72494, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 149/500\n",
      "2072/2072 [==============================] - 0s 85us/step - loss: 6.7264 - mean_absolute_error: 1.5045 - acc: 0.2669 - val_loss: 6.7207 - val_mean_absolute_error: 1.3591 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00149: val_loss improved from 6.72494 to 6.72067, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 150/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 6.7250 - mean_absolute_error: 1.5044 - acc: 0.2659 - val_loss: 6.7165 - val_mean_absolute_error: 1.3588 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00150: val_loss improved from 6.72067 to 6.71648, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 151/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 6.7234 - mean_absolute_error: 1.5043 - acc: 0.2664 - val_loss: 6.7124 - val_mean_absolute_error: 1.3586 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00151: val_loss improved from 6.71648 to 6.71240, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 152/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 6.7219 - mean_absolute_error: 1.5041 - acc: 0.2669 - val_loss: 6.7084 - val_mean_absolute_error: 1.3584 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00152: val_loss improved from 6.71240 to 6.70836, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 153/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 6.7204 - mean_absolute_error: 1.5039 - acc: 0.2669 - val_loss: 6.7044 - val_mean_absolute_error: 1.3582 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00153: val_loss improved from 6.70836 to 6.70441, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 154/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 6.7188 - mean_absolute_error: 1.5038 - acc: 0.2664 - val_loss: 6.7005 - val_mean_absolute_error: 1.3580 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00154: val_loss improved from 6.70441 to 6.70053, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 155/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 6.7173 - mean_absolute_error: 1.5036 - acc: 0.2645 - val_loss: 6.6967 - val_mean_absolute_error: 1.3578 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00155: val_loss improved from 6.70053 to 6.69670, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 156/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.7157 - mean_absolute_error: 1.5034 - acc: 0.2654 - val_loss: 6.6929 - val_mean_absolute_error: 1.3576 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00156: val_loss improved from 6.69670 to 6.69292, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 157/500\n",
      "2072/2072 [==============================] - 0s 90us/step - loss: 6.7215 - mean_absolute_error: 1.5041 - acc: 0.2698 - val_loss: 6.6890 - val_mean_absolute_error: 1.3574 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00157: val_loss improved from 6.69292 to 6.68902, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 158/500\n",
      "2072/2072 [==============================] - 0s 89us/step - loss: 6.6944 - mean_absolute_error: 1.4977 - acc: 0.2669 - val_loss: 6.6858 - val_mean_absolute_error: 1.3572 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00158: val_loss improved from 6.68902 to 6.68578, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 159/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 6.7125 - mean_absolute_error: 1.5033 - acc: 0.2640 - val_loss: 6.6815 - val_mean_absolute_error: 1.3570 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00159: val_loss improved from 6.68578 to 6.68146, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 160/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 6.7090 - mean_absolute_error: 1.5026 - acc: 0.2650 - val_loss: 6.6779 - val_mean_absolute_error: 1.3568 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00160: val_loss improved from 6.68146 to 6.67789, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 161/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.7088 - mean_absolute_error: 1.5027 - acc: 0.2650 - val_loss: 6.6745 - val_mean_absolute_error: 1.3567 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00161: val_loss improved from 6.67789 to 6.67450, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 162/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.7066 - mean_absolute_error: 1.5024 - acc: 0.2645 - val_loss: 6.6710 - val_mean_absolute_error: 1.3566 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00162: val_loss improved from 6.67450 to 6.67104, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 163/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.7051 - mean_absolute_error: 1.5022 - acc: 0.2645 - val_loss: 6.6677 - val_mean_absolute_error: 1.3565 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00163: val_loss improved from 6.67104 to 6.66768, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 164/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 6.7042 - mean_absolute_error: 1.5022 - acc: 0.2640 - val_loss: 6.6644 - val_mean_absolute_error: 1.3563 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00164: val_loss improved from 6.66768 to 6.66440, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 165/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 6.7025 - mean_absolute_error: 1.5019 - acc: 0.2645 - val_loss: 6.6609 - val_mean_absolute_error: 1.3562 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00165: val_loss improved from 6.66440 to 6.66089, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 166/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.7009 - mean_absolute_error: 1.5017 - acc: 0.2640 - val_loss: 6.6577 - val_mean_absolute_error: 1.3561 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00166: val_loss improved from 6.66089 to 6.65772, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 167/500\n",
      "2072/2072 [==============================] - 0s 85us/step - loss: 6.6994 - mean_absolute_error: 1.5015 - acc: 0.2640 - val_loss: 6.6544 - val_mean_absolute_error: 1.3559 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00167: val_loss improved from 6.65772 to 6.65444, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 168/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 6.6980 - mean_absolute_error: 1.5013 - acc: 0.2640 - val_loss: 6.6512 - val_mean_absolute_error: 1.3558 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00168: val_loss improved from 6.65444 to 6.65119, saving model to ANN_Interval_best_GCIPL.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/500\n",
      "2072/2072 [==============================] - 0s 90us/step - loss: 6.6965 - mean_absolute_error: 1.5011 - acc: 0.2650 - val_loss: 6.6480 - val_mean_absolute_error: 1.3557 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00169: val_loss improved from 6.65119 to 6.64798, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 170/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 6.6952 - mean_absolute_error: 1.5010 - acc: 0.2659 - val_loss: 6.6448 - val_mean_absolute_error: 1.3556 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00170: val_loss improved from 6.64798 to 6.64479, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 171/500\n",
      "2072/2072 [==============================] - 0s 89us/step - loss: 6.6936 - mean_absolute_error: 1.5008 - acc: 0.2669 - val_loss: 6.6416 - val_mean_absolute_error: 1.3554 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00171: val_loss improved from 6.64479 to 6.64165, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 172/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 6.6923 - mean_absolute_error: 1.5006 - acc: 0.2674 - val_loss: 6.6385 - val_mean_absolute_error: 1.3553 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00172: val_loss improved from 6.64165 to 6.63850, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 173/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 6.6909 - mean_absolute_error: 1.5004 - acc: 0.2674 - val_loss: 6.6354 - val_mean_absolute_error: 1.3552 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00173: val_loss improved from 6.63850 to 6.63543, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 174/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.6895 - mean_absolute_error: 1.5003 - acc: 0.2669 - val_loss: 6.6323 - val_mean_absolute_error: 1.3551 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00174: val_loss improved from 6.63543 to 6.63234, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 175/500\n",
      "2072/2072 [==============================] - 0s 90us/step - loss: 6.6883 - mean_absolute_error: 1.5001 - acc: 0.2669 - val_loss: 6.6293 - val_mean_absolute_error: 1.3549 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00175: val_loss improved from 6.63234 to 6.62931, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 176/500\n",
      "2072/2072 [==============================] - 0s 87us/step - loss: 6.6869 - mean_absolute_error: 1.5000 - acc: 0.2669 - val_loss: 6.6263 - val_mean_absolute_error: 1.3548 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00176: val_loss improved from 6.62931 to 6.62631, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 177/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.6856 - mean_absolute_error: 1.4998 - acc: 0.2674 - val_loss: 6.6233 - val_mean_absolute_error: 1.3547 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00177: val_loss improved from 6.62631 to 6.62331, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 178/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.6843 - mean_absolute_error: 1.4997 - acc: 0.2674 - val_loss: 6.6204 - val_mean_absolute_error: 1.3546 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00178: val_loss improved from 6.62331 to 6.62036, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 179/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 6.6830 - mean_absolute_error: 1.4995 - acc: 0.2674 - val_loss: 6.6174 - val_mean_absolute_error: 1.3545 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00179: val_loss improved from 6.62036 to 6.61742, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 180/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 6.6817 - mean_absolute_error: 1.4994 - acc: 0.2669 - val_loss: 6.6145 - val_mean_absolute_error: 1.3543 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00180: val_loss improved from 6.61742 to 6.61449, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 181/500\n",
      "2072/2072 [==============================] - 0s 93us/step - loss: 6.6808 - mean_absolute_error: 1.4993 - acc: 0.2669 - val_loss: 6.6117 - val_mean_absolute_error: 1.3542 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00181: val_loss improved from 6.61449 to 6.61167, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 182/500\n",
      "2072/2072 [==============================] - 0s 90us/step - loss: 6.6792 - mean_absolute_error: 1.4990 - acc: 0.2674 - val_loss: 6.6088 - val_mean_absolute_error: 1.3541 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00182: val_loss improved from 6.61167 to 6.60881, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 183/500\n",
      "2072/2072 [==============================] - 0s 104us/step - loss: 6.6781 - mean_absolute_error: 1.4989 - acc: 0.2683 - val_loss: 6.6059 - val_mean_absolute_error: 1.3540 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00183: val_loss improved from 6.60881 to 6.60593, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 184/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 6.6763 - mean_absolute_error: 1.4987 - acc: 0.2698 - val_loss: 6.6031 - val_mean_absolute_error: 1.3539 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00184: val_loss improved from 6.60593 to 6.60312, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 185/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.6756 - mean_absolute_error: 1.4986 - acc: 0.2698 - val_loss: 6.6004 - val_mean_absolute_error: 1.3538 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00185: val_loss improved from 6.60312 to 6.60040, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 186/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.6744 - mean_absolute_error: 1.4985 - acc: 0.2698 - val_loss: 6.5976 - val_mean_absolute_error: 1.3537 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00186: val_loss improved from 6.60040 to 6.59756, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 187/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 6.6733 - mean_absolute_error: 1.4984 - acc: 0.2703 - val_loss: 6.5949 - val_mean_absolute_error: 1.3536 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00187: val_loss improved from 6.59756 to 6.59487, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 188/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.6721 - mean_absolute_error: 1.4982 - acc: 0.2708 - val_loss: 6.5922 - val_mean_absolute_error: 1.3535 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00188: val_loss improved from 6.59487 to 6.59219, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 189/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.6710 - mean_absolute_error: 1.4981 - acc: 0.2708 - val_loss: 6.5894 - val_mean_absolute_error: 1.3533 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00189: val_loss improved from 6.59219 to 6.58943, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 190/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.6699 - mean_absolute_error: 1.4980 - acc: 0.2717 - val_loss: 6.5868 - val_mean_absolute_error: 1.3532 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00190: val_loss improved from 6.58943 to 6.58676, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 191/500\n",
      "2072/2072 [==============================] - 0s 85us/step - loss: 6.6688 - mean_absolute_error: 1.4979 - acc: 0.2722 - val_loss: 6.5840 - val_mean_absolute_error: 1.3531 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00191: val_loss improved from 6.58676 to 6.58400, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 192/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.6677 - mean_absolute_error: 1.4977 - acc: 0.2722 - val_loss: 6.5815 - val_mean_absolute_error: 1.3530 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00192: val_loss improved from 6.58400 to 6.58148, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 193/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.6666 - mean_absolute_error: 1.4976 - acc: 0.2722 - val_loss: 6.5789 - val_mean_absolute_error: 1.3529 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00193: val_loss improved from 6.58148 to 6.57886, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 194/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.6649 - mean_absolute_error: 1.4973 - acc: 0.2727 - val_loss: 6.5763 - val_mean_absolute_error: 1.3528 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00194: val_loss improved from 6.57886 to 6.57629, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 195/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.6645 - mean_absolute_error: 1.4974 - acc: 0.2722 - val_loss: 6.5737 - val_mean_absolute_error: 1.3527 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00195: val_loss improved from 6.57629 to 6.57373, saving model to ANN_Interval_best_GCIPL.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 6.6634 - mean_absolute_error: 1.4973 - acc: 0.2722 - val_loss: 6.5712 - val_mean_absolute_error: 1.3526 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00196: val_loss improved from 6.57373 to 6.57117, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 197/500\n",
      "2072/2072 [==============================] - 0s 93us/step - loss: 6.6624 - mean_absolute_error: 1.4972 - acc: 0.2717 - val_loss: 6.5686 - val_mean_absolute_error: 1.3525 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00197: val_loss improved from 6.57117 to 6.56861, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 198/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.6614 - mean_absolute_error: 1.4970 - acc: 0.2712 - val_loss: 6.5661 - val_mean_absolute_error: 1.3524 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00198: val_loss improved from 6.56861 to 6.56609, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 199/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 6.6603 - mean_absolute_error: 1.4969 - acc: 0.2717 - val_loss: 6.5636 - val_mean_absolute_error: 1.3523 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00199: val_loss improved from 6.56609 to 6.56355, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 200/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.6594 - mean_absolute_error: 1.4968 - acc: 0.2712 - val_loss: 6.5611 - val_mean_absolute_error: 1.3522 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00200: val_loss improved from 6.56355 to 6.56109, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 201/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.6585 - mean_absolute_error: 1.4968 - acc: 0.2712 - val_loss: 6.5586 - val_mean_absolute_error: 1.3521 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00201: val_loss improved from 6.56109 to 6.55862, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 202/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.6575 - mean_absolute_error: 1.4967 - acc: 0.2708 - val_loss: 6.5562 - val_mean_absolute_error: 1.3520 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00202: val_loss improved from 6.55862 to 6.55615, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 203/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 6.6566 - mean_absolute_error: 1.4966 - acc: 0.2703 - val_loss: 6.5538 - val_mean_absolute_error: 1.3519 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00203: val_loss improved from 6.55615 to 6.55377, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 204/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.6555 - mean_absolute_error: 1.4965 - acc: 0.2703 - val_loss: 6.5513 - val_mean_absolute_error: 1.3518 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00204: val_loss improved from 6.55377 to 6.55131, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 205/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 6.6538 - mean_absolute_error: 1.4962 - acc: 0.2703 - val_loss: 6.5489 - val_mean_absolute_error: 1.3518 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00205: val_loss improved from 6.55131 to 6.54894, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 206/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 6.6534 - mean_absolute_error: 1.4963 - acc: 0.2703 - val_loss: 6.5466 - val_mean_absolute_error: 1.3517 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00206: val_loss improved from 6.54894 to 6.54659, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 207/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.6524 - mean_absolute_error: 1.4961 - acc: 0.2708 - val_loss: 6.5443 - val_mean_absolute_error: 1.3516 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00207: val_loss improved from 6.54659 to 6.54428, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 208/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 6.6515 - mean_absolute_error: 1.4960 - acc: 0.2708 - val_loss: 6.5420 - val_mean_absolute_error: 1.3515 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00208: val_loss improved from 6.54428 to 6.54203, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 209/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 6.6505 - mean_absolute_error: 1.4959 - acc: 0.2708 - val_loss: 6.5397 - val_mean_absolute_error: 1.3514 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00209: val_loss improved from 6.54203 to 6.53971, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 210/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 6.6496 - mean_absolute_error: 1.4958 - acc: 0.2708 - val_loss: 6.5375 - val_mean_absolute_error: 1.3513 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00210: val_loss improved from 6.53971 to 6.53749, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 211/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.6486 - mean_absolute_error: 1.4957 - acc: 0.2708 - val_loss: 6.5351 - val_mean_absolute_error: 1.3512 - val_acc: 0.3127\n",
      "\n",
      "Epoch 00211: val_loss improved from 6.53749 to 6.53511, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 212/500\n",
      "2072/2072 [==============================] - 0s 88us/step - loss: 6.6475 - mean_absolute_error: 1.4956 - acc: 0.2708 - val_loss: 6.5329 - val_mean_absolute_error: 1.3511 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00212: val_loss improved from 6.53511 to 6.53289, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 213/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 6.6468 - mean_absolute_error: 1.4956 - acc: 0.2708 - val_loss: 6.5306 - val_mean_absolute_error: 1.3510 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00213: val_loss improved from 6.53289 to 6.53064, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 214/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.6459 - mean_absolute_error: 1.4955 - acc: 0.2708 - val_loss: 6.5284 - val_mean_absolute_error: 1.3509 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00214: val_loss improved from 6.53064 to 6.52839, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 215/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 6.6450 - mean_absolute_error: 1.4954 - acc: 0.2708 - val_loss: 6.5262 - val_mean_absolute_error: 1.3509 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00215: val_loss improved from 6.52839 to 6.52616, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 216/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 6.6441 - mean_absolute_error: 1.4953 - acc: 0.2708 - val_loss: 6.5239 - val_mean_absolute_error: 1.3508 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00216: val_loss improved from 6.52616 to 6.52394, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 217/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 6.6432 - mean_absolute_error: 1.4952 - acc: 0.2712 - val_loss: 6.5217 - val_mean_absolute_error: 1.3507 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00217: val_loss improved from 6.52394 to 6.52174, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 218/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.6426 - mean_absolute_error: 1.4952 - acc: 0.2717 - val_loss: 6.5196 - val_mean_absolute_error: 1.3506 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00218: val_loss improved from 6.52174 to 6.51958, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 219/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 6.6415 - mean_absolute_error: 1.4951 - acc: 0.2717 - val_loss: 6.5175 - val_mean_absolute_error: 1.3506 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00219: val_loss improved from 6.51958 to 6.51751, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 220/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 6.6404 - mean_absolute_error: 1.4949 - acc: 0.2712 - val_loss: 6.5154 - val_mean_absolute_error: 1.3505 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00220: val_loss improved from 6.51751 to 6.51536, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 221/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 6.6396 - mean_absolute_error: 1.4948 - acc: 0.2712 - val_loss: 6.5132 - val_mean_absolute_error: 1.3504 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00221: val_loss improved from 6.51536 to 6.51320, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 222/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.6388 - mean_absolute_error: 1.4948 - acc: 0.2712 - val_loss: 6.5110 - val_mean_absolute_error: 1.3504 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00222: val_loss improved from 6.51320 to 6.51104, saving model to ANN_Interval_best_GCIPL.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/500\n",
      "2072/2072 [==============================] - 0s 85us/step - loss: 6.6378 - mean_absolute_error: 1.4947 - acc: 0.2712 - val_loss: 6.5090 - val_mean_absolute_error: 1.3503 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00223: val_loss improved from 6.51104 to 6.50903, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 224/500\n",
      "2072/2072 [==============================] - 0s 85us/step - loss: 6.6369 - mean_absolute_error: 1.4946 - acc: 0.2712 - val_loss: 6.5069 - val_mean_absolute_error: 1.3502 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00224: val_loss improved from 6.50903 to 6.50694, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 225/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 6.6361 - mean_absolute_error: 1.4945 - acc: 0.2712 - val_loss: 6.5049 - val_mean_absolute_error: 1.3502 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00225: val_loss improved from 6.50694 to 6.50487, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 226/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 6.6352 - mean_absolute_error: 1.4944 - acc: 0.2712 - val_loss: 6.5028 - val_mean_absolute_error: 1.3501 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00226: val_loss improved from 6.50487 to 6.50281, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 227/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.6343 - mean_absolute_error: 1.4943 - acc: 0.2712 - val_loss: 6.5008 - val_mean_absolute_error: 1.3500 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00227: val_loss improved from 6.50281 to 6.50076, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 228/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 6.6335 - mean_absolute_error: 1.4943 - acc: 0.2712 - val_loss: 6.4987 - val_mean_absolute_error: 1.3500 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00228: val_loss improved from 6.50076 to 6.49872, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 229/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.6326 - mean_absolute_error: 1.4942 - acc: 0.2712 - val_loss: 6.4967 - val_mean_absolute_error: 1.3499 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00229: val_loss improved from 6.49872 to 6.49670, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 230/500\n",
      "2072/2072 [==============================] - 0s 87us/step - loss: 6.6318 - mean_absolute_error: 1.4941 - acc: 0.2712 - val_loss: 6.4946 - val_mean_absolute_error: 1.3498 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00230: val_loss improved from 6.49670 to 6.49461, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 231/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.6310 - mean_absolute_error: 1.4940 - acc: 0.2717 - val_loss: 6.4927 - val_mean_absolute_error: 1.3498 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00231: val_loss improved from 6.49461 to 6.49268, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 232/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 6.6301 - mean_absolute_error: 1.4939 - acc: 0.2712 - val_loss: 6.4907 - val_mean_absolute_error: 1.3497 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00232: val_loss improved from 6.49268 to 6.49071, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 233/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 6.6293 - mean_absolute_error: 1.4939 - acc: 0.2712 - val_loss: 6.4887 - val_mean_absolute_error: 1.3497 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00233: val_loss improved from 6.49071 to 6.48874, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 234/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 6.6285 - mean_absolute_error: 1.4938 - acc: 0.2712 - val_loss: 6.4868 - val_mean_absolute_error: 1.3496 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00234: val_loss improved from 6.48874 to 6.48678, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 235/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 6.6276 - mean_absolute_error: 1.4937 - acc: 0.2712 - val_loss: 6.4848 - val_mean_absolute_error: 1.3495 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00235: val_loss improved from 6.48678 to 6.48483, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 236/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.6269 - mean_absolute_error: 1.4937 - acc: 0.2712 - val_loss: 6.4829 - val_mean_absolute_error: 1.3495 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00236: val_loss improved from 6.48483 to 6.48292, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 237/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.6260 - mean_absolute_error: 1.4936 - acc: 0.2712 - val_loss: 6.4810 - val_mean_absolute_error: 1.3494 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00237: val_loss improved from 6.48292 to 6.48101, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 238/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 6.6251 - mean_absolute_error: 1.4935 - acc: 0.2703 - val_loss: 6.4791 - val_mean_absolute_error: 1.3494 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00238: val_loss improved from 6.48101 to 6.47912, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 239/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 6.6239 - mean_absolute_error: 1.4933 - acc: 0.2708 - val_loss: 6.4773 - val_mean_absolute_error: 1.3493 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00239: val_loss improved from 6.47912 to 6.47732, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 240/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.6235 - mean_absolute_error: 1.4934 - acc: 0.2708 - val_loss: 6.4754 - val_mean_absolute_error: 1.3493 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00240: val_loss improved from 6.47732 to 6.47539, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 241/500\n",
      "2072/2072 [==============================] - 0s 91us/step - loss: 6.6227 - mean_absolute_error: 1.4933 - acc: 0.2703 - val_loss: 6.4735 - val_mean_absolute_error: 1.3492 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00241: val_loss improved from 6.47539 to 6.47353, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 242/500\n",
      "2072/2072 [==============================] - 0s 94us/step - loss: 6.6223 - mean_absolute_error: 1.4933 - acc: 0.2703 - val_loss: 6.4717 - val_mean_absolute_error: 1.3492 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00242: val_loss improved from 6.47353 to 6.47171, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 243/500\n",
      "2072/2072 [==============================] - 0s 92us/step - loss: 6.6213 - mean_absolute_error: 1.4931 - acc: 0.2698 - val_loss: 6.4699 - val_mean_absolute_error: 1.3491 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00243: val_loss improved from 6.47171 to 6.46988, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 244/500\n",
      "2072/2072 [==============================] - 0s 87us/step - loss: 6.6203 - mean_absolute_error: 1.4930 - acc: 0.2708 - val_loss: 6.4681 - val_mean_absolute_error: 1.3490 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00244: val_loss improved from 6.46988 to 6.46806, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 245/500\n",
      "2072/2072 [==============================] - 0s 85us/step - loss: 6.6195 - mean_absolute_error: 1.4930 - acc: 0.2712 - val_loss: 6.4662 - val_mean_absolute_error: 1.3490 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00245: val_loss improved from 6.46806 to 6.46617, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 246/500\n",
      "2072/2072 [==============================] - 0s 85us/step - loss: 6.6187 - mean_absolute_error: 1.4929 - acc: 0.2712 - val_loss: 6.4644 - val_mean_absolute_error: 1.3489 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00246: val_loss improved from 6.46617 to 6.46436, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 247/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 6.6182 - mean_absolute_error: 1.4929 - acc: 0.2708 - val_loss: 6.4626 - val_mean_absolute_error: 1.3489 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00247: val_loss improved from 6.46436 to 6.46259, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 248/500\n",
      "2072/2072 [==============================] - 0s 88us/step - loss: 6.6173 - mean_absolute_error: 1.4928 - acc: 0.2712 - val_loss: 6.4608 - val_mean_absolute_error: 1.3488 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00248: val_loss improved from 6.46259 to 6.46078, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 249/500\n",
      "2072/2072 [==============================] - 0s 93us/step - loss: 6.6163 - mean_absolute_error: 1.4927 - acc: 0.2708 - val_loss: 6.4590 - val_mean_absolute_error: 1.3487 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00249: val_loss improved from 6.46078 to 6.45901, saving model to ANN_Interval_best_GCIPL.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/500\n",
      "2072/2072 [==============================] - 0s 89us/step - loss: 6.6156 - mean_absolute_error: 1.4926 - acc: 0.2717 - val_loss: 6.4572 - val_mean_absolute_error: 1.3487 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00250: val_loss improved from 6.45901 to 6.45722, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 251/500\n",
      "2072/2072 [==============================] - 0s 88us/step - loss: 6.6151 - mean_absolute_error: 1.4926 - acc: 0.2717 - val_loss: 6.4555 - val_mean_absolute_error: 1.3486 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00251: val_loss improved from 6.45722 to 6.45554, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 252/500\n",
      "2072/2072 [==============================] - 0s 88us/step - loss: 6.6140 - mean_absolute_error: 1.4925 - acc: 0.2717 - val_loss: 6.4537 - val_mean_absolute_error: 1.3486 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00252: val_loss improved from 6.45554 to 6.45371, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 253/500\n",
      "2072/2072 [==============================] - 0s 89us/step - loss: 6.6133 - mean_absolute_error: 1.4924 - acc: 0.2727 - val_loss: 6.4520 - val_mean_absolute_error: 1.3485 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00253: val_loss improved from 6.45371 to 6.45199, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 254/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.6126 - mean_absolute_error: 1.4924 - acc: 0.2727 - val_loss: 6.4503 - val_mean_absolute_error: 1.3485 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00254: val_loss improved from 6.45199 to 6.45025, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 255/500\n",
      "2072/2072 [==============================] - 0s 90us/step - loss: 6.6120 - mean_absolute_error: 1.4924 - acc: 0.2722 - val_loss: 6.4485 - val_mean_absolute_error: 1.3484 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00255: val_loss improved from 6.45025 to 6.44851, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 256/500\n",
      "2072/2072 [==============================] - 0s 87us/step - loss: 6.6110 - mean_absolute_error: 1.4923 - acc: 0.2722 - val_loss: 6.4468 - val_mean_absolute_error: 1.3484 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00256: val_loss improved from 6.44851 to 6.44684, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 257/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 6.6103 - mean_absolute_error: 1.4922 - acc: 0.2722 - val_loss: 6.4451 - val_mean_absolute_error: 1.3483 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00257: val_loss improved from 6.44684 to 6.44514, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 258/500\n",
      "2072/2072 [==============================] - 0s 87us/step - loss: 6.6095 - mean_absolute_error: 1.4921 - acc: 0.2722 - val_loss: 6.4434 - val_mean_absolute_error: 1.3483 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00258: val_loss improved from 6.44514 to 6.44342, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 259/500\n",
      "2072/2072 [==============================] - 0s 91us/step - loss: 6.6088 - mean_absolute_error: 1.4921 - acc: 0.2722 - val_loss: 6.4418 - val_mean_absolute_error: 1.3482 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00259: val_loss improved from 6.44342 to 6.44176, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 260/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.6081 - mean_absolute_error: 1.4920 - acc: 0.2722 - val_loss: 6.4401 - val_mean_absolute_error: 1.3482 - val_acc: 0.3166\n",
      "\n",
      "Epoch 00260: val_loss improved from 6.44176 to 6.44012, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 261/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.6073 - mean_absolute_error: 1.4919 - acc: 0.2712 - val_loss: 6.4384 - val_mean_absolute_error: 1.3481 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00261: val_loss improved from 6.44012 to 6.43842, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 262/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.6071 - mean_absolute_error: 1.4920 - acc: 0.2708 - val_loss: 6.4368 - val_mean_absolute_error: 1.3481 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00262: val_loss improved from 6.43842 to 6.43679, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 263/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.6053 - mean_absolute_error: 1.4917 - acc: 0.2708 - val_loss: 6.4353 - val_mean_absolute_error: 1.3481 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00263: val_loss improved from 6.43679 to 6.43527, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 264/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 6.6051 - mean_absolute_error: 1.4918 - acc: 0.2708 - val_loss: 6.4336 - val_mean_absolute_error: 1.3480 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00264: val_loss improved from 6.43527 to 6.43361, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 265/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.6044 - mean_absolute_error: 1.4917 - acc: 0.2703 - val_loss: 6.4320 - val_mean_absolute_error: 1.3479 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00265: val_loss improved from 6.43361 to 6.43199, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 266/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 6.6037 - mean_absolute_error: 1.4917 - acc: 0.2708 - val_loss: 6.4304 - val_mean_absolute_error: 1.3479 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00266: val_loss improved from 6.43199 to 6.43036, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 267/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.6031 - mean_absolute_error: 1.4916 - acc: 0.2708 - val_loss: 6.4287 - val_mean_absolute_error: 1.3478 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00267: val_loss improved from 6.43036 to 6.42868, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 268/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.6022 - mean_absolute_error: 1.4915 - acc: 0.2708 - val_loss: 6.4271 - val_mean_absolute_error: 1.3478 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00268: val_loss improved from 6.42868 to 6.42711, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 269/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 6.6015 - mean_absolute_error: 1.4915 - acc: 0.2708 - val_loss: 6.4256 - val_mean_absolute_error: 1.3478 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00269: val_loss improved from 6.42711 to 6.42560, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 270/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.6008 - mean_absolute_error: 1.4914 - acc: 0.2708 - val_loss: 6.4240 - val_mean_absolute_error: 1.3477 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00270: val_loss improved from 6.42560 to 6.42401, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 271/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.6004 - mean_absolute_error: 1.4914 - acc: 0.2708 - val_loss: 6.4225 - val_mean_absolute_error: 1.3477 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00271: val_loss improved from 6.42401 to 6.42251, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 272/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.5993 - mean_absolute_error: 1.4913 - acc: 0.2708 - val_loss: 6.4209 - val_mean_absolute_error: 1.3477 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00272: val_loss improved from 6.42251 to 6.42094, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 273/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 6.5987 - mean_absolute_error: 1.4912 - acc: 0.2708 - val_loss: 6.4193 - val_mean_absolute_error: 1.3476 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00273: val_loss improved from 6.42094 to 6.41931, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 274/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 6.5981 - mean_absolute_error: 1.4912 - acc: 0.2708 - val_loss: 6.4178 - val_mean_absolute_error: 1.3476 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00274: val_loss improved from 6.41931 to 6.41781, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 275/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 6.5973 - mean_absolute_error: 1.4911 - acc: 0.2708 - val_loss: 6.4163 - val_mean_absolute_error: 1.3476 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00275: val_loss improved from 6.41781 to 6.41629, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 276/500\n",
      "2072/2072 [==============================] - 0s 85us/step - loss: 6.5963 - mean_absolute_error: 1.4910 - acc: 0.2708 - val_loss: 6.4149 - val_mean_absolute_error: 1.3476 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00276: val_loss improved from 6.41629 to 6.41485, saving model to ANN_Interval_best_GCIPL.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/500\n",
      "2072/2072 [==============================] - 0s 165us/step - loss: 6.5949 - mean_absolute_error: 1.4908 - acc: 0.2708 - val_loss: 6.4131 - val_mean_absolute_error: 1.3475 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00277: val_loss improved from 6.41485 to 6.41313, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 278/500\n",
      "2072/2072 [==============================] - 0s 140us/step - loss: 6.5953 - mean_absolute_error: 1.4910 - acc: 0.2708 - val_loss: 6.4118 - val_mean_absolute_error: 1.3475 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00278: val_loss improved from 6.41313 to 6.41175, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 279/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 6.5946 - mean_absolute_error: 1.4910 - acc: 0.2708 - val_loss: 6.4103 - val_mean_absolute_error: 1.3474 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00279: val_loss improved from 6.41175 to 6.41027, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 280/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.5940 - mean_absolute_error: 1.4909 - acc: 0.2708 - val_loss: 6.4088 - val_mean_absolute_error: 1.3474 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00280: val_loss improved from 6.41027 to 6.40878, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 281/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 6.5933 - mean_absolute_error: 1.4909 - acc: 0.2708 - val_loss: 6.4073 - val_mean_absolute_error: 1.3474 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00281: val_loss improved from 6.40878 to 6.40732, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 282/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 6.5925 - mean_absolute_error: 1.4908 - acc: 0.2708 - val_loss: 6.4058 - val_mean_absolute_error: 1.3473 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00282: val_loss improved from 6.40732 to 6.40584, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 283/500\n",
      "2072/2072 [==============================] - 0s 89us/step - loss: 6.5919 - mean_absolute_error: 1.4908 - acc: 0.2708 - val_loss: 6.4044 - val_mean_absolute_error: 1.3473 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00283: val_loss improved from 6.40584 to 6.40444, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 284/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 6.5912 - mean_absolute_error: 1.4907 - acc: 0.2708 - val_loss: 6.4028 - val_mean_absolute_error: 1.3472 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00284: val_loss improved from 6.40444 to 6.40279, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 285/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 6.5906 - mean_absolute_error: 1.4907 - acc: 0.2708 - val_loss: 6.4015 - val_mean_absolute_error: 1.3472 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00285: val_loss improved from 6.40279 to 6.40148, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 286/500\n",
      "2072/2072 [==============================] - 0s 100us/step - loss: 6.5900 - mean_absolute_error: 1.4906 - acc: 0.2708 - val_loss: 6.4000 - val_mean_absolute_error: 1.3472 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00286: val_loss improved from 6.40148 to 6.40000, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 287/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 6.5893 - mean_absolute_error: 1.4906 - acc: 0.2712 - val_loss: 6.3987 - val_mean_absolute_error: 1.3472 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00287: val_loss improved from 6.40000 to 6.39866, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 288/500\n",
      "2072/2072 [==============================] - 0s 109us/step - loss: 6.5885 - mean_absolute_error: 1.4905 - acc: 0.2712 - val_loss: 6.3972 - val_mean_absolute_error: 1.3472 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00288: val_loss improved from 6.39866 to 6.39721, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 289/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 6.5878 - mean_absolute_error: 1.4904 - acc: 0.2717 - val_loss: 6.3958 - val_mean_absolute_error: 1.3471 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00289: val_loss improved from 6.39721 to 6.39580, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 290/500\n",
      "2072/2072 [==============================] - 0s 85us/step - loss: 6.5867 - mean_absolute_error: 1.4903 - acc: 0.2722 - val_loss: 6.3943 - val_mean_absolute_error: 1.3471 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00290: val_loss improved from 6.39580 to 6.39433, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 291/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 6.5865 - mean_absolute_error: 1.4904 - acc: 0.2717 - val_loss: 6.3930 - val_mean_absolute_error: 1.3471 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00291: val_loss improved from 6.39433 to 6.39300, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 292/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 6.5859 - mean_absolute_error: 1.4903 - acc: 0.2722 - val_loss: 6.3915 - val_mean_absolute_error: 1.3470 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00292: val_loss improved from 6.39300 to 6.39153, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 293/500\n",
      "2072/2072 [==============================] - 0s 66us/step - loss: 6.5852 - mean_absolute_error: 1.4903 - acc: 0.2717 - val_loss: 6.3902 - val_mean_absolute_error: 1.3470 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00293: val_loss improved from 6.39153 to 6.39025, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 294/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 6.5846 - mean_absolute_error: 1.4902 - acc: 0.2717 - val_loss: 6.3889 - val_mean_absolute_error: 1.3470 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00294: val_loss improved from 6.39025 to 6.38889, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 295/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 6.5839 - mean_absolute_error: 1.4902 - acc: 0.2722 - val_loss: 6.3875 - val_mean_absolute_error: 1.3469 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00295: val_loss improved from 6.38889 to 6.38752, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 296/500\n",
      "2072/2072 [==============================] - 0s 116us/step - loss: 6.5836 - mean_absolute_error: 1.4902 - acc: 0.2717 - val_loss: 6.3861 - val_mean_absolute_error: 1.3469 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00296: val_loss improved from 6.38752 to 6.38606, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 297/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 6.5823 - mean_absolute_error: 1.4900 - acc: 0.2722 - val_loss: 6.3847 - val_mean_absolute_error: 1.3469 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00297: val_loss improved from 6.38606 to 6.38472, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 298/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 6.5818 - mean_absolute_error: 1.4900 - acc: 0.2722 - val_loss: 6.3836 - val_mean_absolute_error: 1.3469 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00298: val_loss improved from 6.38472 to 6.38360, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 299/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.5808 - mean_absolute_error: 1.4899 - acc: 0.2727 - val_loss: 6.3823 - val_mean_absolute_error: 1.3470 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00299: val_loss improved from 6.38360 to 6.38228, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 300/500\n",
      "2072/2072 [==============================] - 0s 87us/step - loss: 6.5805 - mean_absolute_error: 1.4899 - acc: 0.2722 - val_loss: 6.3811 - val_mean_absolute_error: 1.3469 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00300: val_loss improved from 6.38228 to 6.38108, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 301/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 6.5796 - mean_absolute_error: 1.4898 - acc: 0.2712 - val_loss: 6.3798 - val_mean_absolute_error: 1.3469 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00301: val_loss improved from 6.38108 to 6.37979, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 302/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 6.5799 - mean_absolute_error: 1.4899 - acc: 0.2712 - val_loss: 6.3577 - val_mean_absolute_error: 1.3433 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00302: val_loss improved from 6.37979 to 6.35770, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 303/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 6.5864 - mean_absolute_error: 1.4919 - acc: 0.2722 - val_loss: 6.3783 - val_mean_absolute_error: 1.3470 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 6.35770\n",
      "Epoch 304/500\n",
      "2072/2072 [==============================] - 0s 59us/step - loss: 6.5768 - mean_absolute_error: 1.4894 - acc: 0.2717 - val_loss: 6.3763 - val_mean_absolute_error: 1.3468 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 6.35770\n",
      "Epoch 305/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 6.5767 - mean_absolute_error: 1.4895 - acc: 0.2712 - val_loss: 6.3749 - val_mean_absolute_error: 1.3468 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 6.35770\n",
      "Epoch 306/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.5762 - mean_absolute_error: 1.4895 - acc: 0.2712 - val_loss: 6.3735 - val_mean_absolute_error: 1.3467 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 6.35770\n",
      "Epoch 307/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 6.5757 - mean_absolute_error: 1.4895 - acc: 0.2708 - val_loss: 6.3721 - val_mean_absolute_error: 1.3467 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 6.35770\n",
      "Epoch 308/500\n",
      "2072/2072 [==============================] - 0s 51us/step - loss: 6.5748 - mean_absolute_error: 1.4894 - acc: 0.2708 - val_loss: 6.3708 - val_mean_absolute_error: 1.3466 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 6.35770\n",
      "Epoch 309/500\n",
      "2072/2072 [==============================] - 0s 56us/step - loss: 6.5749 - mean_absolute_error: 1.4895 - acc: 0.2708 - val_loss: 6.3696 - val_mean_absolute_error: 1.3466 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 6.35770\n",
      "Epoch 310/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 6.5741 - mean_absolute_error: 1.4894 - acc: 0.2712 - val_loss: 6.3683 - val_mean_absolute_error: 1.3466 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 6.35770\n",
      "Epoch 311/500\n",
      "2072/2072 [==============================] - 0s 54us/step - loss: 6.5731 - mean_absolute_error: 1.4893 - acc: 0.2712 - val_loss: 6.3670 - val_mean_absolute_error: 1.3466 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 6.35770\n",
      "Epoch 312/500\n",
      "2072/2072 [==============================] - 0s 55us/step - loss: 6.5730 - mean_absolute_error: 1.4894 - acc: 0.2717 - val_loss: 6.3658 - val_mean_absolute_error: 1.3466 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 6.35770\n",
      "Epoch 313/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 6.5720 - mean_absolute_error: 1.4893 - acc: 0.2722 - val_loss: 6.3646 - val_mean_absolute_error: 1.3466 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 6.35770\n",
      "Epoch 314/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 6.5718 - mean_absolute_error: 1.4893 - acc: 0.2717 - val_loss: 6.3633 - val_mean_absolute_error: 1.3465 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 6.35770\n",
      "Epoch 315/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 6.6054 - mean_absolute_error: 1.4983 - acc: 0.2703 - val_loss: 6.3659 - val_mean_absolute_error: 1.3471 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 6.35770\n",
      "Epoch 316/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 6.5662 - mean_absolute_error: 1.4881 - acc: 0.2722 - val_loss: 6.3628 - val_mean_absolute_error: 1.3468 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 6.35770\n",
      "Epoch 317/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 6.5669 - mean_absolute_error: 1.4884 - acc: 0.2722 - val_loss: 6.3612 - val_mean_absolute_error: 1.3467 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 6.35770\n",
      "Epoch 318/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 6.5668 - mean_absolute_error: 1.4885 - acc: 0.2717 - val_loss: 6.3596 - val_mean_absolute_error: 1.3466 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 6.35770\n",
      "Epoch 319/500\n",
      "2072/2072 [==============================] - 0s 61us/step - loss: 6.5667 - mean_absolute_error: 1.4886 - acc: 0.2717 - val_loss: 6.3582 - val_mean_absolute_error: 1.3465 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 6.35770\n",
      "Epoch 320/500\n",
      "2072/2072 [==============================] - 0s 62us/step - loss: 6.5666 - mean_absolute_error: 1.4887 - acc: 0.2717 - val_loss: 6.3568 - val_mean_absolute_error: 1.3465 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00320: val_loss improved from 6.35770 to 6.35677, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 321/500\n",
      "2072/2072 [==============================] - 0s 59us/step - loss: 6.5664 - mean_absolute_error: 1.4887 - acc: 0.2717 - val_loss: 6.3554 - val_mean_absolute_error: 1.3464 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00321: val_loss improved from 6.35677 to 6.35544, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 322/500\n",
      "2072/2072 [==============================] - 0s 49us/step - loss: 6.5653 - mean_absolute_error: 1.4886 - acc: 0.2722 - val_loss: 6.3541 - val_mean_absolute_error: 1.3464 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00322: val_loss improved from 6.35544 to 6.35410, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 323/500\n",
      "2072/2072 [==============================] - 0s 53us/step - loss: 6.5655 - mean_absolute_error: 1.4887 - acc: 0.2722 - val_loss: 6.3529 - val_mean_absolute_error: 1.3464 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00323: val_loss improved from 6.35410 to 6.35290, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 324/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 6.5651 - mean_absolute_error: 1.4888 - acc: 0.2722 - val_loss: 6.3516 - val_mean_absolute_error: 1.3463 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00324: val_loss improved from 6.35290 to 6.35156, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 325/500\n",
      "2072/2072 [==============================] - 0s 54us/step - loss: 6.5646 - mean_absolute_error: 1.4887 - acc: 0.2727 - val_loss: 6.3503 - val_mean_absolute_error: 1.3463 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00325: val_loss improved from 6.35156 to 6.35030, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 326/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 6.5642 - mean_absolute_error: 1.4887 - acc: 0.2732 - val_loss: 6.3491 - val_mean_absolute_error: 1.3462 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00326: val_loss improved from 6.35030 to 6.34906, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 327/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 6.5639 - mean_absolute_error: 1.4889 - acc: 0.2708 - val_loss: 6.3451 - val_mean_absolute_error: 1.3457 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00327: val_loss improved from 6.34906 to 6.34506, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 328/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 6.5657 - mean_absolute_error: 1.4894 - acc: 0.2727 - val_loss: 6.3465 - val_mean_absolute_error: 1.3462 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 6.34506\n",
      "Epoch 329/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 6.5626 - mean_absolute_error: 1.4887 - acc: 0.2727 - val_loss: 6.3454 - val_mean_absolute_error: 1.3462 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 6.34506\n",
      "Epoch 330/500\n",
      "2072/2072 [==============================] - 0s 57us/step - loss: 6.5619 - mean_absolute_error: 1.4886 - acc: 0.2727 - val_loss: 6.3442 - val_mean_absolute_error: 1.3461 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00330: val_loss improved from 6.34506 to 6.34423, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 331/500\n",
      "2072/2072 [==============================] - 0s 66us/step - loss: 6.5614 - mean_absolute_error: 1.4886 - acc: 0.2722 - val_loss: 6.3431 - val_mean_absolute_error: 1.3461 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00331: val_loss improved from 6.34423 to 6.34306, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 332/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 6.5609 - mean_absolute_error: 1.4886 - acc: 0.2722 - val_loss: 6.3419 - val_mean_absolute_error: 1.3461 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00332: val_loss improved from 6.34306 to 6.34190, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 333/500\n",
      "2072/2072 [==============================] - 0s 60us/step - loss: 6.5591 - mean_absolute_error: 1.4882 - acc: 0.2717 - val_loss: 6.3406 - val_mean_absolute_error: 1.3461 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00333: val_loss improved from 6.34190 to 6.34064, saving model to ANN_Interval_best_GCIPL.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.5600 - mean_absolute_error: 1.4886 - acc: 0.2727 - val_loss: 6.3396 - val_mean_absolute_error: 1.3460 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00334: val_loss improved from 6.34064 to 6.33957, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 335/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 6.5593 - mean_absolute_error: 1.4885 - acc: 0.2732 - val_loss: 6.3384 - val_mean_absolute_error: 1.3460 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00335: val_loss improved from 6.33957 to 6.33845, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 336/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 6.5588 - mean_absolute_error: 1.4885 - acc: 0.2732 - val_loss: 6.3373 - val_mean_absolute_error: 1.3460 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00336: val_loss improved from 6.33845 to 6.33733, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 337/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 6.5582 - mean_absolute_error: 1.4884 - acc: 0.2732 - val_loss: 6.3362 - val_mean_absolute_error: 1.3460 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00337: val_loss improved from 6.33733 to 6.33620, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 338/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 6.5576 - mean_absolute_error: 1.4884 - acc: 0.2736 - val_loss: 6.3351 - val_mean_absolute_error: 1.3460 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00338: val_loss improved from 6.33620 to 6.33510, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 339/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 6.5570 - mean_absolute_error: 1.4883 - acc: 0.2736 - val_loss: 6.3340 - val_mean_absolute_error: 1.3459 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00339: val_loss improved from 6.33510 to 6.33398, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 340/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 6.5565 - mean_absolute_error: 1.4883 - acc: 0.2741 - val_loss: 6.3329 - val_mean_absolute_error: 1.3459 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00340: val_loss improved from 6.33398 to 6.33288, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 341/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 6.5559 - mean_absolute_error: 1.4883 - acc: 0.2741 - val_loss: 6.3318 - val_mean_absolute_error: 1.3459 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00341: val_loss improved from 6.33288 to 6.33179, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 342/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 6.5553 - mean_absolute_error: 1.4882 - acc: 0.2741 - val_loss: 6.3307 - val_mean_absolute_error: 1.3459 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00342: val_loss improved from 6.33179 to 6.33069, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 343/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 6.5547 - mean_absolute_error: 1.4882 - acc: 0.2741 - val_loss: 6.3296 - val_mean_absolute_error: 1.3459 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00343: val_loss improved from 6.33069 to 6.32961, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 344/500\n",
      "2072/2072 [==============================] - 0s 99us/step - loss: 6.5542 - mean_absolute_error: 1.4881 - acc: 0.2746 - val_loss: 6.3285 - val_mean_absolute_error: 1.3459 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00344: val_loss improved from 6.32961 to 6.32853, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 345/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 6.5536 - mean_absolute_error: 1.4881 - acc: 0.2746 - val_loss: 6.3274 - val_mean_absolute_error: 1.3458 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00345: val_loss improved from 6.32853 to 6.32745, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 346/500\n",
      "2072/2072 [==============================] - 0s 64us/step - loss: 6.5530 - mean_absolute_error: 1.4880 - acc: 0.2746 - val_loss: 6.3264 - val_mean_absolute_error: 1.3458 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00346: val_loss improved from 6.32745 to 6.32638, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 347/500\n",
      "2072/2072 [==============================] - 0s 89us/step - loss: 6.5522 - mean_absolute_error: 1.4879 - acc: 0.2741 - val_loss: 6.3253 - val_mean_absolute_error: 1.3458 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00347: val_loss improved from 6.32638 to 6.32528, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 348/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 6.5513 - mean_absolute_error: 1.4878 - acc: 0.2741 - val_loss: 6.3242 - val_mean_absolute_error: 1.3458 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00348: val_loss improved from 6.32528 to 6.32422, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 349/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 6.5514 - mean_absolute_error: 1.4879 - acc: 0.2746 - val_loss: 6.3232 - val_mean_absolute_error: 1.3458 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00349: val_loss improved from 6.32422 to 6.32319, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 350/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 6.5508 - mean_absolute_error: 1.4879 - acc: 0.2741 - val_loss: 6.3222 - val_mean_absolute_error: 1.3458 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00350: val_loss improved from 6.32319 to 6.32217, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 351/500\n",
      "2072/2072 [==============================] - 0s 64us/step - loss: 6.5747 - mean_absolute_error: 1.4932 - acc: 0.2717 - val_loss: 6.2331 - val_mean_absolute_error: 1.3520 - val_acc: 0.3050\n",
      "\n",
      "Epoch 00351: val_loss improved from 6.32217 to 6.23312, saving model to ANN_Interval_best_GCIPL.hdf5\n",
      "Epoch 352/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 6.6643 - mean_absolute_error: 1.5164 - acc: 0.2654 - val_loss: 6.3347 - val_mean_absolute_error: 1.3485 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 6.23312\n",
      "Epoch 353/500\n",
      "2072/2072 [==============================] - 0s 94us/step - loss: 6.5318 - mean_absolute_error: 1.4834 - acc: 0.2727 - val_loss: 6.3211 - val_mean_absolute_error: 1.3461 - val_acc: 0.3301\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 6.23312\n",
      "Epoch 354/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 6.5370 - mean_absolute_error: 1.4847 - acc: 0.2741 - val_loss: 6.3174 - val_mean_absolute_error: 1.3456 - val_acc: 0.3301\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 6.23312\n",
      "Epoch 355/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 6.5383 - mean_absolute_error: 1.4854 - acc: 0.2712 - val_loss: 6.3259 - val_mean_absolute_error: 1.3475 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 6.23312\n",
      "Epoch 356/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 6.5368 - mean_absolute_error: 1.4852 - acc: 0.2722 - val_loss: 6.3228 - val_mean_absolute_error: 1.3470 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 6.23312\n",
      "Epoch 357/500\n",
      "2072/2072 [==============================] - 0s 103us/step - loss: 6.5382 - mean_absolute_error: 1.4856 - acc: 0.2732 - val_loss: 6.3207 - val_mean_absolute_error: 1.3467 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 6.23312\n",
      "Epoch 358/500\n",
      "2072/2072 [==============================] - 0s 95us/step - loss: 6.5392 - mean_absolute_error: 1.4858 - acc: 0.2727 - val_loss: 6.3186 - val_mean_absolute_error: 1.3465 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 6.23312\n",
      "Epoch 359/500\n",
      "2072/2072 [==============================] - 0s 66us/step - loss: 6.5397 - mean_absolute_error: 1.4860 - acc: 0.2732 - val_loss: 6.3161 - val_mean_absolute_error: 1.3462 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 6.23312\n",
      "Epoch 360/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 6.5403 - mean_absolute_error: 1.4863 - acc: 0.2736 - val_loss: 6.3154 - val_mean_absolute_error: 1.3463 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 6.23312\n",
      "Epoch 361/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 6.5403 - mean_absolute_error: 1.4864 - acc: 0.2736 - val_loss: 6.3131 - val_mean_absolute_error: 1.3460 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 6.23312\n",
      "Epoch 362/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.5406 - mean_absolute_error: 1.4865 - acc: 0.2741 - val_loss: 6.3114 - val_mean_absolute_error: 1.3458 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 6.23312\n",
      "Epoch 363/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 6.5406 - mean_absolute_error: 1.4867 - acc: 0.2741 - val_loss: 6.3106 - val_mean_absolute_error: 1.3459 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 6.23312\n",
      "Epoch 364/500\n",
      "2072/2072 [==============================] - 0s 88us/step - loss: 6.5402 - mean_absolute_error: 1.4867 - acc: 0.2741 - val_loss: 6.3072 - val_mean_absolute_error: 1.3454 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 6.23312\n",
      "Epoch 365/500\n",
      "2072/2072 [==============================] - 0s 98us/step - loss: 6.5427 - mean_absolute_error: 1.4866 - acc: 0.2756 - val_loss: 6.2880 - val_mean_absolute_error: 1.3419 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 6.23312\n",
      "Epoch 366/500\n",
      "2072/2072 [==============================] - 0s 87us/step - loss: 6.5510 - mean_absolute_error: 1.4892 - acc: 0.2741 - val_loss: 6.3103 - val_mean_absolute_error: 1.3466 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 6.23312\n",
      "Epoch 367/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 6.5377 - mean_absolute_error: 1.4866 - acc: 0.2741 - val_loss: 6.3072 - val_mean_absolute_error: 1.3461 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 6.23312\n",
      "Epoch 368/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 6.5381 - mean_absolute_error: 1.4865 - acc: 0.2751 - val_loss: 6.2985 - val_mean_absolute_error: 1.3443 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 6.23312\n",
      "Epoch 369/500\n",
      "2072/2072 [==============================] - 0s 85us/step - loss: 6.5420 - mean_absolute_error: 1.4875 - acc: 0.2761 - val_loss: 6.2979 - val_mean_absolute_error: 1.3444 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 6.23312\n",
      "Epoch 370/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.5407 - mean_absolute_error: 1.4873 - acc: 0.2751 - val_loss: 6.2992 - val_mean_absolute_error: 1.3451 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 6.23312\n",
      "Epoch 371/500\n",
      "2072/2072 [==============================] - 0s 90us/step - loss: 6.5362 - mean_absolute_error: 1.4861 - acc: 0.2761 - val_loss: 6.2895 - val_mean_absolute_error: 1.3433 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 6.23312\n",
      "Epoch 372/500\n",
      "2072/2072 [==============================] - 0s 65us/step - loss: 6.5393 - mean_absolute_error: 1.4874 - acc: 0.2736 - val_loss: 6.2939 - val_mean_absolute_error: 1.3442 - val_acc: 0.3301\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 6.23312\n",
      "Epoch 373/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 6.5380 - mean_absolute_error: 1.4874 - acc: 0.2746 - val_loss: 6.2925 - val_mean_absolute_error: 1.3442 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 6.23312\n",
      "Epoch 374/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 6.5354 - mean_absolute_error: 1.4870 - acc: 0.2751 - val_loss: 6.2910 - val_mean_absolute_error: 1.3441 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 6.23312\n",
      "Epoch 375/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 6.5340 - mean_absolute_error: 1.4869 - acc: 0.2756 - val_loss: 6.2899 - val_mean_absolute_error: 1.3441 - val_acc: 0.3301\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 6.23312\n",
      "Epoch 376/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 6.5286 - mean_absolute_error: 1.4856 - acc: 0.2736 - val_loss: 6.2868 - val_mean_absolute_error: 1.3435 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 6.23312\n",
      "Epoch 377/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 6.5329 - mean_absolute_error: 1.4871 - acc: 0.2746 - val_loss: 6.2911 - val_mean_absolute_error: 1.3450 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 6.23312\n",
      "Epoch 378/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 6.5262 - mean_absolute_error: 1.4856 - acc: 0.2765 - val_loss: 6.2829 - val_mean_absolute_error: 1.3431 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 6.23312\n",
      "Epoch 379/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 6.5258 - mean_absolute_error: 1.4852 - acc: 0.2751 - val_loss: 6.2788 - val_mean_absolute_error: 1.3423 - val_acc: 0.3282\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 6.23312\n",
      "Epoch 380/500\n",
      "2072/2072 [==============================] - 0s 64us/step - loss: 6.5294 - mean_absolute_error: 1.4866 - acc: 0.2746 - val_loss: 6.2769 - val_mean_absolute_error: 1.3424 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 6.23312\n",
      "Epoch 381/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 6.5270 - mean_absolute_error: 1.4865 - acc: 0.2756 - val_loss: 6.2777 - val_mean_absolute_error: 1.3428 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 6.23312\n",
      "Epoch 382/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 6.5252 - mean_absolute_error: 1.4864 - acc: 0.2732 - val_loss: 6.2785 - val_mean_absolute_error: 1.3434 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 6.23312\n",
      "Epoch 383/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 6.5171 - mean_absolute_error: 1.4848 - acc: 0.2741 - val_loss: 6.2782 - val_mean_absolute_error: 1.3433 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 6.23312\n",
      "Epoch 384/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 6.5135 - mean_absolute_error: 1.4837 - acc: 0.2732 - val_loss: 6.2707 - val_mean_absolute_error: 1.3420 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 6.23312\n",
      "Epoch 385/500\n",
      "2072/2072 [==============================] - 0s 104us/step - loss: 6.5150 - mean_absolute_error: 1.4835 - acc: 0.2761 - val_loss: 6.2603 - val_mean_absolute_error: 1.3401 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 6.23312\n",
      "Epoch 386/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 6.5150 - mean_absolute_error: 1.4854 - acc: 0.2717 - val_loss: 6.2782 - val_mean_absolute_error: 1.3440 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 6.23312\n",
      "Epoch 387/500\n",
      "2072/2072 [==============================] - 0s 67us/step - loss: 6.5072 - mean_absolute_error: 1.4832 - acc: 0.2722 - val_loss: 6.2695 - val_mean_absolute_error: 1.3426 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 6.23312\n",
      "Epoch 388/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 6.5059 - mean_absolute_error: 1.4831 - acc: 0.2727 - val_loss: 6.2679 - val_mean_absolute_error: 1.3424 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 6.23312\n",
      "Epoch 389/500\n",
      "2072/2072 [==============================] - 0s 80us/step - loss: 6.5027 - mean_absolute_error: 1.4828 - acc: 0.2717 - val_loss: 6.2666 - val_mean_absolute_error: 1.3423 - val_acc: 0.3263\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 6.23312\n",
      "Epoch 390/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 6.5003 - mean_absolute_error: 1.4826 - acc: 0.2712 - val_loss: 6.2654 - val_mean_absolute_error: 1.3423 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 6.23312\n",
      "Epoch 391/500\n",
      "2072/2072 [==============================] - 0s 95us/step - loss: 6.4976 - mean_absolute_error: 1.4823 - acc: 0.2712 - val_loss: 6.2647 - val_mean_absolute_error: 1.3424 - val_acc: 0.3243\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 6.23312\n",
      "Epoch 392/500\n",
      "2072/2072 [==============================] - 0s 66us/step - loss: 6.4963 - mean_absolute_error: 1.4824 - acc: 0.2708 - val_loss: 6.2645 - val_mean_absolute_error: 1.3427 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 6.23312\n",
      "Epoch 393/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 6.4933 - mean_absolute_error: 1.4818 - acc: 0.2732 - val_loss: 6.2632 - val_mean_absolute_error: 1.3426 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 6.23312\n",
      "Epoch 394/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2072/2072 [==============================] - 0s 75us/step - loss: 6.4905 - mean_absolute_error: 1.4816 - acc: 0.2712 - val_loss: 6.2632 - val_mean_absolute_error: 1.3429 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 6.23312\n",
      "Epoch 395/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 6.4872 - mean_absolute_error: 1.4813 - acc: 0.2708 - val_loss: 6.2631 - val_mean_absolute_error: 1.3431 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 6.23312\n",
      "Epoch 396/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 6.4850 - mean_absolute_error: 1.4809 - acc: 0.2703 - val_loss: 6.2599 - val_mean_absolute_error: 1.3426 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 6.23312\n",
      "Epoch 397/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 6.4807 - mean_absolute_error: 1.4800 - acc: 0.2688 - val_loss: 6.2587 - val_mean_absolute_error: 1.3427 - val_acc: 0.3185\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 6.23312\n",
      "Epoch 398/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 6.4808 - mean_absolute_error: 1.4811 - acc: 0.2679 - val_loss: 6.2638 - val_mean_absolute_error: 1.3442 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 6.23312\n",
      "Epoch 399/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 6.4755 - mean_absolute_error: 1.4796 - acc: 0.2693 - val_loss: 6.2594 - val_mean_absolute_error: 1.3433 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 6.23312\n",
      "Epoch 400/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 6.4766 - mean_absolute_error: 1.4810 - acc: 0.2669 - val_loss: 6.2650 - val_mean_absolute_error: 1.3448 - val_acc: 0.3205\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 6.23312\n",
      "Epoch 401/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 6.4734 - mean_absolute_error: 1.4799 - acc: 0.2674 - val_loss: 6.2578 - val_mean_absolute_error: 1.3436 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 6.23312\n",
      "Epoch 00401: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1a2bffa668>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN_baseline(X, y_GCA, 'GCIPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2072 samples, validate on 518 samples\n",
      "Epoch 1/500\n",
      "2072/2072 [==============================] - 1s 605us/step - loss: 5518.9074 - mean_absolute_error: 65.8502 - acc: 0.0024 - val_loss: 507.3938 - val_mean_absolute_error: 20.8903 - val_acc: 0.0039\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 507.39380, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 2/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 213.1286 - mean_absolute_error: 10.4330 - acc: 0.0352 - val_loss: 173.1726 - val_mean_absolute_error: 8.7913 - val_acc: 0.0425\n",
      "\n",
      "Epoch 00002: val_loss improved from 507.39380 to 173.17256, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 3/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 161.0600 - mean_absolute_error: 8.5020 - acc: 0.0439 - val_loss: 167.9980 - val_mean_absolute_error: 8.8270 - val_acc: 0.0309\n",
      "\n",
      "Epoch 00003: val_loss improved from 173.17256 to 167.99804, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 4/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 150.8535 - mean_absolute_error: 8.2237 - acc: 0.0463 - val_loss: 156.7221 - val_mean_absolute_error: 8.4240 - val_acc: 0.0405\n",
      "\n",
      "Epoch 00004: val_loss improved from 167.99804 to 156.72210, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 5/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 140.3954 - mean_absolute_error: 7.9196 - acc: 0.0502 - val_loss: 145.5826 - val_mean_absolute_error: 8.0262 - val_acc: 0.0579\n",
      "\n",
      "Epoch 00005: val_loss improved from 156.72210 to 145.58262, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 6/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 130.3039 - mean_absolute_error: 7.6203 - acc: 0.0512 - val_loss: 136.1444 - val_mean_absolute_error: 7.7411 - val_acc: 0.0444\n",
      "\n",
      "Epoch 00006: val_loss improved from 145.58262 to 136.14442, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 7/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 120.4474 - mean_absolute_error: 7.3212 - acc: 0.0550 - val_loss: 128.0893 - val_mean_absolute_error: 7.5223 - val_acc: 0.0444\n",
      "\n",
      "Epoch 00007: val_loss improved from 136.14442 to 128.08930, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 8/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 110.6661 - mean_absolute_error: 7.0174 - acc: 0.0642 - val_loss: 120.8173 - val_mean_absolute_error: 7.3413 - val_acc: 0.0598\n",
      "\n",
      "Epoch 00008: val_loss improved from 128.08930 to 120.81734, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 9/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 100.9189 - mean_absolute_error: 6.7145 - acc: 0.0574 - val_loss: 113.1285 - val_mean_absolute_error: 7.1605 - val_acc: 0.0695\n",
      "\n",
      "Epoch 00009: val_loss improved from 120.81734 to 113.12855, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 10/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 89.5689 - mean_absolute_error: 6.3692 - acc: 0.0598 - val_loss: 95.1006 - val_mean_absolute_error: 6.5998 - val_acc: 0.0560\n",
      "\n",
      "Epoch 00010: val_loss improved from 113.12855 to 95.10059, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 11/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 70.0410 - mean_absolute_error: 5.7355 - acc: 0.0632 - val_loss: 71.7923 - val_mean_absolute_error: 5.3297 - val_acc: 0.0772\n",
      "\n",
      "Epoch 00011: val_loss improved from 95.10059 to 71.79227, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 12/500\n",
      "2072/2072 [==============================] - 0s 94us/step - loss: 55.3619 - mean_absolute_error: 5.0089 - acc: 0.0772 - val_loss: 58.3631 - val_mean_absolute_error: 4.6071 - val_acc: 0.0869\n",
      "\n",
      "Epoch 00012: val_loss improved from 71.79227 to 58.36313, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 13/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 44.2966 - mean_absolute_error: 4.3326 - acc: 0.1018 - val_loss: 47.9206 - val_mean_absolute_error: 4.0277 - val_acc: 0.1139\n",
      "\n",
      "Epoch 00013: val_loss improved from 58.36313 to 47.92063, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 14/500\n",
      "2072/2072 [==============================] - 0s 68us/step - loss: 36.7989 - mean_absolute_error: 3.8172 - acc: 0.1149 - val_loss: 42.0963 - val_mean_absolute_error: 3.8264 - val_acc: 0.0985\n",
      "\n",
      "Epoch 00014: val_loss improved from 47.92063 to 42.09629, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 15/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 32.7263 - mean_absolute_error: 3.4940 - acc: 0.1303 - val_loss: 37.8929 - val_mean_absolute_error: 3.5302 - val_acc: 0.1236\n",
      "\n",
      "Epoch 00015: val_loss improved from 42.09629 to 37.89285, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 16/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 30.7866 - mean_absolute_error: 3.3001 - acc: 0.1429 - val_loss: 35.3407 - val_mean_absolute_error: 3.3141 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00016: val_loss improved from 37.89285 to 35.34071, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 17/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 30.1321 - mean_absolute_error: 3.2454 - acc: 0.1269 - val_loss: 34.1900 - val_mean_absolute_error: 3.1728 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00017: val_loss improved from 35.34071 to 34.18998, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 18/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 29.9377 - mean_absolute_error: 3.2305 - acc: 0.1178 - val_loss: 34.0316 - val_mean_absolute_error: 3.1885 - val_acc: 0.1274\n",
      "\n",
      "Epoch 00018: val_loss improved from 34.18998 to 34.03159, saving model to ANN_Interval_best_VFI.hdf5\n",
      "Epoch 19/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 29.9315 - mean_absolute_error: 3.2442 - acc: 0.1182 - val_loss: 34.1567 - val_mean_absolute_error: 3.1909 - val_acc: 0.1332\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 34.03159\n",
      "Epoch 20/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 29.7531 - mean_absolute_error: 3.2209 - acc: 0.1255 - val_loss: 34.4988 - val_mean_absolute_error: 3.2932 - val_acc: 0.0985\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 34.03159\n",
      "Epoch 21/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 29.7888 - mean_absolute_error: 3.2348 - acc: 0.1245 - val_loss: 35.1420 - val_mean_absolute_error: 3.4288 - val_acc: 0.0849\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 34.03159\n",
      "Epoch 22/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 29.8265 - mean_absolute_error: 3.2487 - acc: 0.1240 - val_loss: 35.6139 - val_mean_absolute_error: 3.5265 - val_acc: 0.0753\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 34.03159\n",
      "Epoch 23/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 29.8302 - mean_absolute_error: 3.2588 - acc: 0.1178 - val_loss: 36.0781 - val_mean_absolute_error: 3.6049 - val_acc: 0.0618\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 34.03159\n",
      "Epoch 24/500\n",
      "2072/2072 [==============================] - 0s 63us/step - loss: 29.7843 - mean_absolute_error: 3.2604 - acc: 0.1173 - val_loss: 36.4955 - val_mean_absolute_error: 3.6866 - val_acc: 0.0579\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 34.03159\n",
      "Epoch 25/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 29.7775 - mean_absolute_error: 3.2653 - acc: 0.1158 - val_loss: 36.9013 - val_mean_absolute_error: 3.7567 - val_acc: 0.0541\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 34.03159\n",
      "Epoch 26/500\n",
      "2072/2072 [==============================] - 0s 76us/step - loss: 29.7440 - mean_absolute_error: 3.2657 - acc: 0.1129 - val_loss: 37.2402 - val_mean_absolute_error: 3.8183 - val_acc: 0.0560\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 34.03159\n",
      "Epoch 27/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 29.7069 - mean_absolute_error: 3.2647 - acc: 0.1105 - val_loss: 37.5360 - val_mean_absolute_error: 3.8716 - val_acc: 0.0560\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 34.03159\n",
      "Epoch 28/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 29.6573 - mean_absolute_error: 3.2610 - acc: 0.1129 - val_loss: 37.8237 - val_mean_absolute_error: 3.9217 - val_acc: 0.0483\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 34.03159\n",
      "Epoch 29/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 29.6045 - mean_absolute_error: 3.2562 - acc: 0.1134 - val_loss: 38.0796 - val_mean_absolute_error: 3.9653 - val_acc: 0.0463\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 34.03159\n",
      "Epoch 30/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 29.5442 - mean_absolute_error: 3.2505 - acc: 0.1149 - val_loss: 38.3138 - val_mean_absolute_error: 4.0040 - val_acc: 0.0444\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 34.03159\n",
      "Epoch 31/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 29.4752 - mean_absolute_error: 3.2433 - acc: 0.1187 - val_loss: 38.5083 - val_mean_absolute_error: 4.0358 - val_acc: 0.0463\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 34.03159\n",
      "Epoch 32/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 29.4015 - mean_absolute_error: 3.2358 - acc: 0.1216 - val_loss: 38.6716 - val_mean_absolute_error: 4.0623 - val_acc: 0.0483\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 34.03159\n",
      "Epoch 33/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 29.3225 - mean_absolute_error: 3.2274 - acc: 0.1274 - val_loss: 38.7960 - val_mean_absolute_error: 4.0826 - val_acc: 0.0502\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 34.03159\n",
      "Epoch 34/500\n",
      "2072/2072 [==============================] - 0s 81us/step - loss: 29.2404 - mean_absolute_error: 3.2176 - acc: 0.1289 - val_loss: 38.8842 - val_mean_absolute_error: 4.0969 - val_acc: 0.0502\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 34.03159\n",
      "Epoch 35/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 29.1631 - mean_absolute_error: 3.2088 - acc: 0.1240 - val_loss: 38.9885 - val_mean_absolute_error: 4.1080 - val_acc: 0.0463\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 34.03159\n",
      "Epoch 36/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 29.0775 - mean_absolute_error: 3.1989 - acc: 0.1211 - val_loss: 39.0008 - val_mean_absolute_error: 4.1129 - val_acc: 0.0483\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 34.03159\n",
      "Epoch 37/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 28.9899 - mean_absolute_error: 3.1884 - acc: 0.1269 - val_loss: 38.9727 - val_mean_absolute_error: 4.1116 - val_acc: 0.0483\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 34.03159\n",
      "Epoch 38/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 28.9031 - mean_absolute_error: 3.1773 - acc: 0.1221 - val_loss: 38.9264 - val_mean_absolute_error: 4.1076 - val_acc: 0.0463\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 34.03159\n",
      "Epoch 39/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 28.8321 - mean_absolute_error: 3.1677 - acc: 0.1250 - val_loss: 38.8760 - val_mean_absolute_error: 4.1027 - val_acc: 0.0502\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 34.03159\n",
      "Epoch 40/500\n",
      "2072/2072 [==============================] - 0s 69us/step - loss: 28.7683 - mean_absolute_error: 3.1588 - acc: 0.1245 - val_loss: 38.8171 - val_mean_absolute_error: 4.0960 - val_acc: 0.0502\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 34.03159\n",
      "Epoch 41/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 28.7140 - mean_absolute_error: 3.1511 - acc: 0.1264 - val_loss: 38.7573 - val_mean_absolute_error: 4.0894 - val_acc: 0.0502\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 34.03159\n",
      "Epoch 42/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 28.6694 - mean_absolute_error: 3.1449 - acc: 0.1293 - val_loss: 38.6899 - val_mean_absolute_error: 4.0818 - val_acc: 0.0502\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 34.03159\n",
      "Epoch 43/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 28.6339 - mean_absolute_error: 3.1392 - acc: 0.1303 - val_loss: 38.6236 - val_mean_absolute_error: 4.0740 - val_acc: 0.0502\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 34.03159\n",
      "Epoch 44/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 28.6049 - mean_absolute_error: 3.1346 - acc: 0.1332 - val_loss: 38.5577 - val_mean_absolute_error: 4.0663 - val_acc: 0.0502\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 34.03159\n",
      "Epoch 45/500\n",
      "2072/2072 [==============================] - 0s 84us/step - loss: 28.5844 - mean_absolute_error: 3.1311 - acc: 0.1356 - val_loss: 38.4905 - val_mean_absolute_error: 4.0584 - val_acc: 0.0521\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 34.03159\n",
      "Epoch 46/500\n",
      "2072/2072 [==============================] - 0s 82us/step - loss: 28.5701 - mean_absolute_error: 3.1284 - acc: 0.1361 - val_loss: 38.4259 - val_mean_absolute_error: 4.0504 - val_acc: 0.0521\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 34.03159\n",
      "Epoch 47/500\n",
      "2072/2072 [==============================] - 0s 94us/step - loss: 28.5595 - mean_absolute_error: 3.1268 - acc: 0.1361 - val_loss: 38.3523 - val_mean_absolute_error: 4.0412 - val_acc: 0.0521\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 34.03159\n",
      "Epoch 48/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 28.5526 - mean_absolute_error: 3.1256 - acc: 0.1380 - val_loss: 38.2854 - val_mean_absolute_error: 4.0329 - val_acc: 0.0521\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 34.03159\n",
      "Epoch 49/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 28.5492 - mean_absolute_error: 3.1253 - acc: 0.1385 - val_loss: 38.2206 - val_mean_absolute_error: 4.0247 - val_acc: 0.0521\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 34.03159\n",
      "Epoch 50/500\n",
      "2072/2072 [==============================] - 0s 71us/step - loss: 28.5484 - mean_absolute_error: 3.1262 - acc: 0.1361 - val_loss: 38.1534 - val_mean_absolute_error: 4.0166 - val_acc: 0.0502\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 34.03159\n",
      "Epoch 51/500\n",
      "2072/2072 [==============================] - 0s 86us/step - loss: 28.5427 - mean_absolute_error: 3.1252 - acc: 0.1347 - val_loss: 38.0660 - val_mean_absolute_error: 4.0045 - val_acc: 0.0521\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 34.03159\n",
      "Epoch 52/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 28.5541 - mean_absolute_error: 3.1275 - acc: 0.1356 - val_loss: 38.0524 - val_mean_absolute_error: 4.0029 - val_acc: 0.0521\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 34.03159\n",
      "Epoch 53/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 28.5492 - mean_absolute_error: 3.1289 - acc: 0.1342 - val_loss: 37.9725 - val_mean_absolute_error: 3.9925 - val_acc: 0.0521\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 34.03159\n",
      "Epoch 54/500\n",
      "2072/2072 [==============================] - 0s 74us/step - loss: 28.5435 - mean_absolute_error: 3.1296 - acc: 0.1327 - val_loss: 37.8897 - val_mean_absolute_error: 3.9817 - val_acc: 0.0521\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 34.03159\n",
      "Epoch 55/500\n",
      "2072/2072 [==============================] - 0s 70us/step - loss: 28.5359 - mean_absolute_error: 3.1286 - acc: 0.1298 - val_loss: 37.8239 - val_mean_absolute_error: 3.9725 - val_acc: 0.0560\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 34.03159\n",
      "Epoch 56/500\n",
      "2072/2072 [==============================] - 0s 95us/step - loss: 28.5479 - mean_absolute_error: 3.1311 - acc: 0.1308 - val_loss: 37.8123 - val_mean_absolute_error: 3.9718 - val_acc: 0.0541\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 34.03159\n",
      "Epoch 57/500\n",
      "2072/2072 [==============================] - 0s 79us/step - loss: 28.5397 - mean_absolute_error: 3.1322 - acc: 0.1303 - val_loss: 37.7196 - val_mean_absolute_error: 3.9596 - val_acc: 0.0521\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 34.03159\n",
      "Epoch 58/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 28.5288 - mean_absolute_error: 3.1323 - acc: 0.1332 - val_loss: 37.6407 - val_mean_absolute_error: 3.9495 - val_acc: 0.0521\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 34.03159\n",
      "Epoch 59/500\n",
      "2072/2072 [==============================] - 0s 75us/step - loss: 28.5209 - mean_absolute_error: 3.1332 - acc: 0.1327 - val_loss: 37.5668 - val_mean_absolute_error: 3.9407 - val_acc: 0.0541\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 34.03159\n",
      "Epoch 60/500\n",
      "2072/2072 [==============================] - 0s 88us/step - loss: 28.5079 - mean_absolute_error: 3.1312 - acc: 0.1361 - val_loss: 37.4753 - val_mean_absolute_error: 3.9276 - val_acc: 0.0541\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 34.03159\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2072/2072 [==============================] - 0s 82us/step - loss: 28.5116 - mean_absolute_error: 3.1331 - acc: 0.1332 - val_loss: 37.4791 - val_mean_absolute_error: 3.9294 - val_acc: 0.0521\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 34.03159\n",
      "Epoch 62/500\n",
      "2072/2072 [==============================] - 0s 73us/step - loss: 28.5001 - mean_absolute_error: 3.1338 - acc: 0.1308 - val_loss: 37.4260 - val_mean_absolute_error: 3.9230 - val_acc: 0.0521\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 34.03159\n",
      "Epoch 63/500\n",
      "2072/2072 [==============================] - 0s 77us/step - loss: 28.4894 - mean_absolute_error: 3.1341 - acc: 0.1313 - val_loss: 37.3696 - val_mean_absolute_error: 3.9164 - val_acc: 0.0521\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 34.03159\n",
      "Epoch 64/500\n",
      "2072/2072 [==============================] - 0s 72us/step - loss: 28.4746 - mean_absolute_error: 3.1322 - acc: 0.1337 - val_loss: 37.3252 - val_mean_absolute_error: 3.9105 - val_acc: 0.0541\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 34.03159\n",
      "Epoch 65/500\n",
      "2072/2072 [==============================] - 0s 78us/step - loss: 28.4801 - mean_absolute_error: 3.1338 - acc: 0.1313 - val_loss: 37.3360 - val_mean_absolute_error: 3.9133 - val_acc: 0.0541\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 34.03159\n",
      "Epoch 66/500\n",
      "2072/2072 [==============================] - 0s 87us/step - loss: 28.4654 - mean_absolute_error: 3.1342 - acc: 0.1322 - val_loss: 37.2849 - val_mean_absolute_error: 3.9076 - val_acc: 0.0541\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 34.03159\n",
      "Epoch 67/500\n",
      "2072/2072 [==============================] - 0s 83us/step - loss: 28.4520 - mean_absolute_error: 3.1342 - acc: 0.1318 - val_loss: 37.2230 - val_mean_absolute_error: 3.9003 - val_acc: 0.0541\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 34.03159\n",
      "Epoch 68/500\n",
      "2072/2072 [==============================] - 0s 90us/step - loss: 28.4315 - mean_absolute_error: 3.1317 - acc: 0.1327 - val_loss: 37.1835 - val_mean_absolute_error: 3.8954 - val_acc: 0.0521\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 34.03159\n",
      "Epoch 00068: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1a2d99d4a8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN_baseline(X, y_VFI, 'VFI')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
